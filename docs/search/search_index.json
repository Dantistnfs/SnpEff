{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SnpEff&SnpSift Genomic variant annotations and functional effect prediction toolbox. Download SnpEff Important: This version implements the VCF annotation standard 'ANN' field . Latest version 4.3T (2017-11-24) Requires Java 1.8 ClinEff Professional version of SnpEff & SnpSift suites. ClinEff is considered more stable thus suitable for Clinical and Production operations, whereas SnpEff/SnpSfit is designed for Research and Academic usage. Features: Compliance support (CLIA and CAP) Long Term Support Prioritized bug fixes and feature development Customized databases and annotation pipelines Integration with open, private and proprietary databases Privacy: Tickets, issues, pipeline-specific analysis SnpEff Genetic variant annotation and functional effect prediction toolbox. It annotates and predicts the effects of genetic variants on genes and proteins (such as amino acid changes). Features: Supports over 38,000 genomes . Standard ANN annotation format Cancer variants analysis GATK compatible ( -o gatk ) HGVS notation Sequence Ontology standardized terms SnpSift SnpSift annotates genomic variants using databases, filters, and manipulates genomic annotated variants. Once you annotated your files using SnpEff, you can use SnpSift to help you filter large genomic datasets in order to find the most significant variants for your experiment. View details Version 4.3 Features: Significant improvements in translocations annotations Improvements in large structural variant annotations Protein-Protein interaction loci annotations (from PDB) View details Paper & Citing If you are using SnpEff or SnpSift in an research or academic environment, please cite our papers . View details Who uses SnpEff? Users of SnpEff include most major research an academic institutions, as well as pharmaceutical companies and clinical sequencing projects. View details Galaxy & GATK SnpEff is integrated with other tools commonly used in sequencing data analysis pipelines. Most notably Galaxy and GATK projects support SnpEff. View details In memory of Dr. Xiangyi Lu: Please donate On October 22, 2017, Xiangyi Lu, a co-author on the SnpEff and SnpSift papers, died of ovarian cancer after a three year struggle. Douglas Ruden, Xiangyi's husband and senior author on the papers, has requested that a non-mandatory gift of at least $10 for using SnpEff or SnpSift be donated to WSU to honor Xiangyi Lu. All gifts will go to a newly named fund, the \"Xiangyi Lu Graduate Student Fellowship in Bioinformatics Fund.\" with the goal of raising $1 million, in order to permanently endow one graduate student research position in bioinformatics every year.","title":"Home"},{"location":"#snpeffsnpsift","text":"Genomic variant annotations and functional effect prediction toolbox. Download SnpEff Important: This version implements the VCF annotation standard 'ANN' field . Latest version 4.3T (2017-11-24) Requires Java 1.8","title":"SnpEff&amp;SnpSift"},{"location":"#clineff","text":"Professional version of SnpEff & SnpSift suites. ClinEff is considered more stable thus suitable for Clinical and Production operations, whereas SnpEff/SnpSfit is designed for Research and Academic usage. Features: Compliance support (CLIA and CAP) Long Term Support Prioritized bug fixes and feature development Customized databases and annotation pipelines Integration with open, private and proprietary databases Privacy: Tickets, issues, pipeline-specific analysis","title":"ClinEff"},{"location":"#snpeff","text":"Genetic variant annotation and functional effect prediction toolbox. It annotates and predicts the effects of genetic variants on genes and proteins (such as amino acid changes). Features: Supports over 38,000 genomes . Standard ANN annotation format Cancer variants analysis GATK compatible ( -o gatk ) HGVS notation Sequence Ontology standardized terms","title":"SnpEff"},{"location":"#snpsift","text":"SnpSift annotates genomic variants using databases, filters, and manipulates genomic annotated variants. Once you annotated your files using SnpEff, you can use SnpSift to help you filter large genomic datasets in order to find the most significant variants for your experiment. View details","title":"SnpSift"},{"location":"#version-43","text":"Features: Significant improvements in translocations annotations Improvements in large structural variant annotations Protein-Protein interaction loci annotations (from PDB) View details","title":"Version 4.3"},{"location":"#paper-citing","text":"If you are using SnpEff or SnpSift in an research or academic environment, please cite our papers . View details","title":"Paper &amp; Citing"},{"location":"#who-uses-snpeff","text":"Users of SnpEff include most major research an academic institutions, as well as pharmaceutical companies and clinical sequencing projects. View details","title":"Who uses SnpEff?"},{"location":"#galaxy-gatk","text":"SnpEff is integrated with other tools commonly used in sequencing data analysis pipelines. Most notably Galaxy and GATK projects support SnpEff. View details","title":"Galaxy &amp; GATK"},{"location":"#in-memory-of-dr-xiangyi-lu-please-donate","text":"On October 22, 2017, Xiangyi Lu, a co-author on the SnpEff and SnpSift papers, died of ovarian cancer after a three year struggle. Douglas Ruden, Xiangyi's husband and senior author on the papers, has requested that a non-mandatory gift of at least $10 for using SnpEff or SnpSift be donated to WSU to honor Xiangyi Lu. All gifts will go to a newly named fund, the \"Xiangyi Lu Graduate Student Fellowship in Bioinformatics Fund.\" with the goal of raising $1 million, in order to permanently endow one graduate student research position in bioinformatics every year.","title":"In memory of Dr. Xiangyi Lu: Please donate"},{"location":"about/","text":"About About This project is maintained by Pablo Cingolani Acknowledgements Acknowledgements and special thanks to (in order of appearance): Adrian Platts (McGill): tons of feedback, feature suggestions, test cases, etc. Doug Ruden (WSU): feedback, features request, debugging. Louis Letourneau (McGill / Genome Quebec): bug fixes, features suggestions, etc. Dave OConnor (UW-Madison): feature suggestions, HIV genome. Denis Reshetov (Rogaev lab): VCF output support and debugging on GTF parsing. Louis Letourneau (McGill / Genome Quebec): Maven project. Mark DePristo, Eric Banks & David Rozen (Broad): VCF parsing and VCF output. Jonathan Fresnedo (University of California, Davis): P.Persica genome support. GATK: integration was performed by Broad's Genome Analysis Team: David Rozen, Eric Banks and Mark DePristo Arno Velds (NKI: Netherlands Cancer Institute): Annomalities in ENSEMBL annotation files that led to '-onlyCoding = auto' development, as well as \"rogue transcript filters\". Giulio Genovese: ENSEMBL annotation problems, fixing and improving \"rogue transcript\" problem. Louis Letourneau (McGill / Genome Quebec): dbNSFP implementation Peter Briggs (Manchester University) : Improved Galaxy interface and wrappers. Jim Johnson (Minnesota Supercomputing Institute, University of Minnesota): SnpSift improvements and bugfixes. Davide Cittaro (Center for Translational Genomics and Bioinformatics, Ospedale San Raffaele): Debugging and beta-testing for both SnpEff & SnpSift. Helped to debug many interoperability, compatibility and format specification issues. Louis Letourneau (McGill / Genome Quebec): Cancer effects, HSGV notation, etc. Sarmady, Mahdi (Children's hospital of Philadelphia): hg19 using transcript version from UCSC. Leipzig, Jeremy & Sarmady, Mahdi (Children's hospital of Philadelphia): HGVS notation Jinghua (Frank) Feng (University of Adelaide) : Losts of feedback, debugging and improvements in SnpSift annotations. Andrea Mafficini (University of Verona, Italy) : Support for dbNSFP 2.1 Jim Johnson (Minnesota Supercomputing Institute, University of Minnesota): SnpSift 'rmFilter' bugfix. Brad Chapman (Harvad): HomeBrew (HomeBrew-Science) support and bash wrapper. Marco Cusumano-Towner & Eugene Brevdo (SVBio): Insertions in reverse strand bug report and bugfix. Uma Devi (U. Virginia), Karen Eilbeck (U. Utah) & Nicole Marie Ruiz (U. Utah): Sequence Ontology, made right. Ryan Calhoun (Apistry): SnpSift annotate, tabix index bug. Contact information Pablo Cingolani .","title":"About"},{"location":"about/#about","text":"","title":"About"},{"location":"about/#about_1","text":"This project is maintained by Pablo Cingolani","title":"About"},{"location":"about/#acknowledgements","text":"Acknowledgements and special thanks to (in order of appearance): Adrian Platts (McGill): tons of feedback, feature suggestions, test cases, etc. Doug Ruden (WSU): feedback, features request, debugging. Louis Letourneau (McGill / Genome Quebec): bug fixes, features suggestions, etc. Dave OConnor (UW-Madison): feature suggestions, HIV genome. Denis Reshetov (Rogaev lab): VCF output support and debugging on GTF parsing. Louis Letourneau (McGill / Genome Quebec): Maven project. Mark DePristo, Eric Banks & David Rozen (Broad): VCF parsing and VCF output. Jonathan Fresnedo (University of California, Davis): P.Persica genome support. GATK: integration was performed by Broad's Genome Analysis Team: David Rozen, Eric Banks and Mark DePristo Arno Velds (NKI: Netherlands Cancer Institute): Annomalities in ENSEMBL annotation files that led to '-onlyCoding = auto' development, as well as \"rogue transcript filters\". Giulio Genovese: ENSEMBL annotation problems, fixing and improving \"rogue transcript\" problem. Louis Letourneau (McGill / Genome Quebec): dbNSFP implementation Peter Briggs (Manchester University) : Improved Galaxy interface and wrappers. Jim Johnson (Minnesota Supercomputing Institute, University of Minnesota): SnpSift improvements and bugfixes. Davide Cittaro (Center for Translational Genomics and Bioinformatics, Ospedale San Raffaele): Debugging and beta-testing for both SnpEff & SnpSift. Helped to debug many interoperability, compatibility and format specification issues. Louis Letourneau (McGill / Genome Quebec): Cancer effects, HSGV notation, etc. Sarmady, Mahdi (Children's hospital of Philadelphia): hg19 using transcript version from UCSC. Leipzig, Jeremy & Sarmady, Mahdi (Children's hospital of Philadelphia): HGVS notation Jinghua (Frank) Feng (University of Adelaide) : Losts of feedback, debugging and improvements in SnpSift annotations. Andrea Mafficini (University of Verona, Italy) : Support for dbNSFP 2.1 Jim Johnson (Minnesota Supercomputing Institute, University of Minnesota): SnpSift 'rmFilter' bugfix. Brad Chapman (Harvad): HomeBrew (HomeBrew-Science) support and bash wrapper. Marco Cusumano-Towner & Eugene Brevdo (SVBio): Insertions in reverse strand bug report and bugfix. Uma Devi (U. Virginia), Karen Eilbeck (U. Utah) & Nicole Marie Ruiz (U. Utah): Sequence Ontology, made right. Ryan Calhoun (Apistry): SnpSift annotate, tabix index bug.","title":"Acknowledgements"},{"location":"about/#contact-information","text":"Pablo Cingolani .","title":"Contact information"},{"location":"citing/","text":"If you are using SnpEff or SnpSift, please cite our work. Citing SnpEff You can find the paper here . In order to cite SnpSift, please use the following reference: Quote \"A program for annotating and predicting the effects of single nucleotide polymorphisms, SnpEff: SNPs in the genome of Drosophila melanogaster strain w1118; iso-2; iso-3.\", Cingolani P, Platts A, Wang le L, Coon M, Nguyen T, Wang L, Land SJ, Lu X, Ruden DM. Fly (Austin). 2012 Apr-Jun;6(2):80-92. PMID: 22728672 BibTex entry: @article{cingolani2012program, title={A program for annotating and predicting the effects of single nucleotide polymorphisms, SnpEff: SNPs in the genome of Drosophila melanogaster strain w1118; iso-2; iso-3}, author={Cingolani, P. and Platts, A. and Coon, M. and Nguyen, T. and Wang, L. and Land, S.J. and Lu, X. and Ruden, D.M.}, journal={Fly}, volume={6}, number={2}, pages={80-92}, year={2012} } Citing SnpSift You can find the paper here . In order to cite SnpSift, please use the following reference: Quote \"Using Drosophila melanogaster as a model for genotoxic chemical mutational studies with a new program, SnpSift\", Cingolani, P., et. al., Frontiers in Genetics, 3, 2012. BibTex entry: @article{cingolani2012using, title={Using Drosophila melanogaster as a model for genotoxic chemical mutational studies with a new program, SnpSift}, author={Cingolani, P. and Patel, V.M. and Coon, M. and Nguyen, T. and Land, S.J. and Ruden, D.M. and Lu, X.}, journal={Frontiers in Genetics}, volume={3}, year={2012}, publisher={Frontiers Media SA} }","title":"Paper & Citations"},{"location":"citing/#citing-snpeff","text":"You can find the paper here . In order to cite SnpSift, please use the following reference: Quote \"A program for annotating and predicting the effects of single nucleotide polymorphisms, SnpEff: SNPs in the genome of Drosophila melanogaster strain w1118; iso-2; iso-3.\", Cingolani P, Platts A, Wang le L, Coon M, Nguyen T, Wang L, Land SJ, Lu X, Ruden DM. Fly (Austin). 2012 Apr-Jun;6(2):80-92. PMID: 22728672 BibTex entry: @article{cingolani2012program, title={A program for annotating and predicting the effects of single nucleotide polymorphisms, SnpEff: SNPs in the genome of Drosophila melanogaster strain w1118; iso-2; iso-3}, author={Cingolani, P. and Platts, A. and Coon, M. and Nguyen, T. and Wang, L. and Land, S.J. and Lu, X. and Ruden, D.M.}, journal={Fly}, volume={6}, number={2}, pages={80-92}, year={2012} }","title":"Citing SnpEff"},{"location":"citing/#citing-snpsift","text":"You can find the paper here . In order to cite SnpSift, please use the following reference: Quote \"Using Drosophila melanogaster as a model for genotoxic chemical mutational studies with a new program, SnpSift\", Cingolani, P., et. al., Frontiers in Genetics, 3, 2012. BibTex entry: @article{cingolani2012using, title={Using Drosophila melanogaster as a model for genotoxic chemical mutational studies with a new program, SnpSift}, author={Cingolani, P. and Patel, V.M. and Coon, M. and Nguyen, T. and Land, S.J. and Ruden, D.M. and Lu, X.}, journal={Frontiers in Genetics}, volume={3}, year={2012}, publisher={Frontiers Media SA} }","title":"Citing SnpSift"},{"location":"download/","text":"Downloading SnpEff & SnpSift SnpEff and SnpSift are bundled together. Download SnpEff Old versions here . License SnpEff is open source, released as \"LGPLv3\". System requirements SnpEff requires that you have Java v1.8 or later installed (any modern operating system has it). The amount of memory used can vary significantly depending on genome size and data analysis type you are doing. For large genomes, such as the human genome, you'll probably need at least 4Gb of memory. Installing SnpEff Installing SnpEff is very easy, you just have to uncompress the ZIP file. How to install using command line (unix systems) It is better if you install SnpEff in snpEff directory in your home directory ( $HOME/snpEff in unix systems). # Go to home dir cd # Download latest version wget https://snpeff.blob.core.windows.net/versions/snpEff_latest_core.zip # Unzip file unzip snpEff_latest_core.zip Configuration In most cases you DO NOT need to configure anything. The only configuration file is snpEff.config . Most configuration parameters, are explained in the comments in the same config file, so I won't repeat the explanation here :-) Usually you do NOT need to change the configuration. Some peoeple may need to change the location of the databases ( data.dir parameter). By default, this parameter points to the data directory where you installed the tool (i.e. in unix systems, this is ./data ). If you want to change this, you can edit the snpEff.config file and change the data_dir entry: #--- # Databases are stored here # E.g.: Information for 'hg19' is stored in data_dir/hg19/ # # You can use tilde ('~') as first character to refer to your home directory. # Also, a non-absolute path will be relative to config's file dir # #--- data.dir = ./data/ Downloading SnpEff databases In order to perform annotations, SnpEff automatically downloads and installs genomic database. Info By default SnpEff automatically downloads and installs the database for you, so you don't need to do it manually. Databases can be downloaded in three different ways: The easiest way is to let SnpEff download and install databases automatically You can pre-install databases manually using the SnpEff download command (once SnpEff is installed). E.g. to download the human genome database: java -jar snpEff.jar download GRCh38.76 Note: Current human genome version at the time of writing is GRCh38.76. Available databases There are over 20,000 databases available. A list of databases is available in snpEff.config file. You can also see all available databases by running the following command (once SnpEff has been installed): java -jar snpEff.jar databases Source code Getting the source The source code is in GitHub (although we keep the binary distribution is at SourceForge). Here is the git command to check out the development version of the code: # Get SnpEff git clone https://github.com/pcingola/SnpEff.git # Get SnpSift as well git clone https://github.com/pcingola/SnpSift.git Building from the source Most libraries should be install using Maven, so you just need to run mvn command. Java (JDK) ANT Maven Some libraries are not available through maven, so you have to install them into via Maven manually (these libraries are in SnpEff/lib ) # Go to 'lib' dir cd SnpEff/lib # Antlr mvn install:install-file \\ -Dfile=antlr-4.5.1-complete.jar \\ -DgroupId=org.antlr \\ -DartifactId=antlr \\ -Dversion=4.5.1 \\ -Dpackaging=jar # BioJava core mvn install:install-file \\ -Dfile=biojava3-core-3.0.7.jar \\ -DgroupId=org.biojava \\ -DartifactId=biojava3-core \\ -Dversion=3.0.7 \\ -Dpackaging=jar # BioJava structure mvn install:install-file \\ -Dfile=biojava3-structure-3.0.7.jar \\ -DgroupId=org.biojava \\ -DartifactId=biojava3-structure \\ -Dversion=3.0.7 \\ -Dpackaging=jar Once the libraries are installed, you can use make.sh to build the code cd $HOME/snpEff # Create link to scripts_build directory if it doesn't exist ln -s $HOME/workspace/SnpEff/scripts_build # Invoke the build script ./scripts_build/make.sh Installing test cases Test cases require special \"test cases databases and genome\", you can find them here: # Install test databases in SnpEff's development directory (not the soruce code dir!) cd $HOME/snpEff # Download databases and genome for test cases wget https://snpeff.blob.core.windows.net/databases/test_cases.tgz # Uncompress tar -xvzf test_cases.tgz # Go to Eclipse's workspace directory (where the source code is) cd $HOME/workspace/SnpEff # Create a link to the 'data' dir, so that we can run test cases within Eclipse ln -s $HOME/snpEff/data # Add data dir to 'gitignore' echo \"/data\" >> .gitignore","title":"Download and install"},{"location":"download/#downloading-snpeff-snpsift","text":"SnpEff and SnpSift are bundled together. Download SnpEff Old versions here .","title":"Downloading SnpEff &amp; SnpSift"},{"location":"download/#license","text":"SnpEff is open source, released as \"LGPLv3\".","title":"License"},{"location":"download/#system-requirements","text":"SnpEff requires that you have Java v1.8 or later installed (any modern operating system has it). The amount of memory used can vary significantly depending on genome size and data analysis type you are doing. For large genomes, such as the human genome, you'll probably need at least 4Gb of memory.","title":"System requirements"},{"location":"download/#installing-snpeff","text":"Installing SnpEff is very easy, you just have to uncompress the ZIP file. How to install using command line (unix systems) It is better if you install SnpEff in snpEff directory in your home directory ( $HOME/snpEff in unix systems). # Go to home dir cd # Download latest version wget https://snpeff.blob.core.windows.net/versions/snpEff_latest_core.zip # Unzip file unzip snpEff_latest_core.zip","title":"Installing SnpEff"},{"location":"download/#configuration","text":"In most cases you DO NOT need to configure anything. The only configuration file is snpEff.config . Most configuration parameters, are explained in the comments in the same config file, so I won't repeat the explanation here :-) Usually you do NOT need to change the configuration. Some peoeple may need to change the location of the databases ( data.dir parameter). By default, this parameter points to the data directory where you installed the tool (i.e. in unix systems, this is ./data ). If you want to change this, you can edit the snpEff.config file and change the data_dir entry: #--- # Databases are stored here # E.g.: Information for 'hg19' is stored in data_dir/hg19/ # # You can use tilde ('~') as first character to refer to your home directory. # Also, a non-absolute path will be relative to config's file dir # #--- data.dir = ./data/","title":"Configuration"},{"location":"download/#downloading-snpeff-databases","text":"In order to perform annotations, SnpEff automatically downloads and installs genomic database. Info By default SnpEff automatically downloads and installs the database for you, so you don't need to do it manually. Databases can be downloaded in three different ways: The easiest way is to let SnpEff download and install databases automatically You can pre-install databases manually using the SnpEff download command (once SnpEff is installed). E.g. to download the human genome database: java -jar snpEff.jar download GRCh38.76 Note: Current human genome version at the time of writing is GRCh38.76.","title":"Downloading SnpEff databases"},{"location":"download/#available-databases","text":"There are over 20,000 databases available. A list of databases is available in snpEff.config file. You can also see all available databases by running the following command (once SnpEff has been installed): java -jar snpEff.jar databases","title":"Available databases"},{"location":"download/#source-code","text":"","title":"Source code"},{"location":"download/#getting-the-source","text":"The source code is in GitHub (although we keep the binary distribution is at SourceForge). Here is the git command to check out the development version of the code: # Get SnpEff git clone https://github.com/pcingola/SnpEff.git # Get SnpSift as well git clone https://github.com/pcingola/SnpSift.git","title":"Getting the source"},{"location":"download/#building-from-the-source","text":"Most libraries should be install using Maven, so you just need to run mvn command. Java (JDK) ANT Maven Some libraries are not available through maven, so you have to install them into via Maven manually (these libraries are in SnpEff/lib ) # Go to 'lib' dir cd SnpEff/lib # Antlr mvn install:install-file \\ -Dfile=antlr-4.5.1-complete.jar \\ -DgroupId=org.antlr \\ -DartifactId=antlr \\ -Dversion=4.5.1 \\ -Dpackaging=jar # BioJava core mvn install:install-file \\ -Dfile=biojava3-core-3.0.7.jar \\ -DgroupId=org.biojava \\ -DartifactId=biojava3-core \\ -Dversion=3.0.7 \\ -Dpackaging=jar # BioJava structure mvn install:install-file \\ -Dfile=biojava3-structure-3.0.7.jar \\ -DgroupId=org.biojava \\ -DartifactId=biojava3-structure \\ -Dversion=3.0.7 \\ -Dpackaging=jar Once the libraries are installed, you can use make.sh to build the code cd $HOME/snpEff # Create link to scripts_build directory if it doesn't exist ln -s $HOME/workspace/SnpEff/scripts_build # Invoke the build script ./scripts_build/make.sh","title":"Building from the source"},{"location":"download/#installing-test-cases","text":"Test cases require special \"test cases databases and genome\", you can find them here: # Install test databases in SnpEff's development directory (not the soruce code dir!) cd $HOME/snpEff # Download databases and genome for test cases wget https://snpeff.blob.core.windows.net/databases/test_cases.tgz # Uncompress tar -xvzf test_cases.tgz # Go to Eclipse's workspace directory (where the source code is) cd $HOME/workspace/SnpEff # Create a link to the 'data' dir, so that we can run test cases within Eclipse ln -s $HOME/snpEff/data # Add data dir to 'gitignore' echo \"/data\" >> .gitignore","title":"Installing test cases"},{"location":"examples/","text":"Usage examples Materials In this protocol we show how to analyze genomic variants using the SnpEff pipeline. Computer hardware: The materials required for this protocol are: a computer running a Unix operating system (Linux, OS.X), at least 16GB of RAM at least 8Gb of free disk space, Java a reasonably fast internet connection Users of Windows computers can install CygWin, a free Linux-like environment for Windows, although the precise commands listed in the protocol may need to adapted. Software: We use the SnpEff annotation program and its companion tool SnpSift. These programs can perform annotation, primary impact assessment and variants filtering, as well as many other tasks beyond the scope of this protocol. We highly recommend reading their comprehensive documentation available here . Before starting the protocol, it is necessary to download and install SnpEff. To do this, open a Unix, Linux or Cygwin shell and execute the following commands: # Move to home directory cd # Download and install SnpEff curl -v -L 'https://snpeff.blob.core.windows.net/versions/snpEff_latest_core.zip' > snpEff_latest_core.zip unzip snpEff_latest_core.zip Notes: SnpEff & SnpSift annotation software used in this protocol are under very active development and some command line option may change in the future. The standard installation is to add the package in the \"$HOME/snpEff\" directory (where $HOME is your home directory). To install SnpEff elsewhere, update the \"data_dir\" parameter in your \"snpEff.config\" file, as described in the SnpEff documentation. Once SnpEff is installed, we will enter the following commands to download the pre-built human database (GRCh37.75) that will be used to annotate our data. cd snpEff java -jar snpEff.jar download -v GRCh37.75 A list of pre-built databases for all other species is available by running the following command: java -jar snpEff.jar databases Example 1: Coding variants We show how to use SnpEff & SnpSift to annotate, prioritize and filter coding variants. Dataset: In this genomic annotation example, we use a simulated dataset to show how to find genetic variants of a Mendelian recessive disease, Cystic fibrosis, caused by a high impact coding variant, a nonsense mutation in CFTR gene (G542*). The data files come from the publicly available \"CEPH_1463\" dataset, sequenced by Complete Genomics , and contains sequencing information for a family consisting of 4 grandparents, 2 parents and 11 siblings. Although these are healthy individuals, we artificially introduced a known Cystic fibrosis mutation on three siblings (cases) in a manner that was consistent with the underlying haplotype structure. We now download and un-compress the example data used in this protocol, which, for reasons of space and time, is limited to only chromosome 7 and 17: # Go to SnpEff's dir cd ~/snpEff # Download sample data curl -v -L `https://datasetsnpeff.blob.core.windows.net/dataset/protocols.zip?sv=2019-10-10&st=2020-09-01T00%3A00%3A00Z&se=2050-09-01T00%3A00%3A00Z&si=prod&sr=c&sig=isafOa9tGnYBAvsXFUMDGMTbsG2z%2FShaihzp7JE5dHw%3D` > protocols.zip unzip protocols.zip The goal in this example is to use SnpEff to find a mutation causing a Mendelian recessive trait. This will be done using a dataset of variant calls for chromosome 7 from a pedigree of 17 healthy individuals, sequenced by Complete Genomics, in which a coding variant causing cystic fibrosis was artificially introduced in three siblings (see Materials). For the purpose of this example, we assume that we do not know the causative variant, but that we know that we are dealing with a Mendelian recessive disorder, where the three siblings are affected (cases), but the 14 parents and grandparents are not (controls). Genomic variants are usually provided in a VCF file containing variant information of all the samples; storing the variant data in a single VCF file is the standard practice, not only because variant calling algorithms have better accuracy when run on all samples simultaneously, but also because it is much easier to annotate, manipulate and compare individuals when the data is stored and transferred together. A caveat of this approach is that VCF files can become very large when performing experiments with thousands of samples (from several Gigabytes to Terabytes in size). In the following protocol, SnpEff will add annotation fields to each variant record in the input VCF file. We will then use SnpSift, a filtering program to extract the most significant variants having annotations meeting certain criteria. Step 1: Primary variant annotation and quality control. Our first step is to annotate each of the ~500,000 variants contained in the VCF file. By default, SnpEff adds primary annotations and basic impact assessment for coding and non-coding variants as described above. SnpEff has several command line options that can be used in this annotation stage and which are described in detail in the online manual . In this example, we annotate (all these annotations are activated by default when using SnpEff): loss of function and nonsense mediated decay predictions; protein domain annotations from the curated NextProt database; putative transcription factor binding sites from the ENSEMBL 'Regulatory Build' and Jaspar database; use HGVS notation for amino acid changes; and to create a web page summarizing the annotation results in \"ex1.html\" (option -stats ): java -Xmx8g -jar snpEff.jar -v -stats ex1.html GRCh37.75 protocols/ex1.vcf > protocols/ex1.ann.vcf SnpEff produces three output files : the HTML file containing summary statistics about the variants and their annotations; an annotated VCF file; and a text file summarizing the number of variant types per gene. Creation of the summary files can be de-activated to speed up the program (for example, when the application is used together with Galaxy). By default, the statistics file \"ex1.html\" is a standard HTML file that can be opened in any web browser to view quality control (QC) metrics. It can also be created in comma-separated values format (CSV) to be used by downstream processing programs as part of an automated pipeline. In our example, the summary file contains basic quality control statistics calculated from the variant file: for our data, the Ts/Ts ratio is close to 2.0 (Figure 1c) and missense / silent ratio is around 1.0 (Figure 1d), both of which are expected for human data (but these numbers may differ for other species). Large deviations from the expected values for the organism being sequenced might indicate problems with either the sequencing or variant calling pipelines. The summary file also contains QC information for the gene annotation used as input. In this example, 829 warnings (Figure 1a) were identified as a result of possible genomic annotation errors or small inconsistencies identified in the reference genome so we have to be careful analyzing those genes/transcripts. Other summary statistics are available, such as variant types (Figure 1e), variants effects (Figure 1d and 1g), and primary impacts (Figure 1b and 1g). Step 2: Counting variants in case and control subjects. In the first step of our protocol, SnpEff created a VCF file with half million annotated variants. Rather than scanning each annotation manually, we will use the SnpSift program to create a filter that will identify a small subset of variants with interesting functional properties. Since the VCF files used in most sequencing studies are even larger than the one in this example, our overall approach is to start by creating a filter using a very restrictive set of criteria. If no relevant variant is found using this stringent filter, we will relax the criteria to include variants with lower predicted impact. In our example, since the pedigree is consistent with a Mendelian recessive disease, so we will first use SnpEff to find high impact variants that are homozygous in cases and either absent or heterozygous in controls. This provides a very strong genetic argument to select the promising variants and will be used as the first step in our filter. To do this, we will identify the case and control samples by providing SnpEff with pedigree information using a \"TFAM\" file (a standard file format used to describe pedigrees). In our example, the TFAM file (\"pedigree.tfam\") identifies the three cases (NA12879, NA12885, NA12886), and lists the other family members as controls. The \"caseControl\" command instructs the SnpSift program to count the number homozygous non-reference, heterozygous and allele count (number of non-reference alleles in each DNA sample) for both cases and controls groups (running time: ~60 minutes): java -Xmx1g -jar SnpSift.jar \\ caseControl \\ -v \\ -tfam protocols/pedigree.tfam \\ protocols/ex1.ann.vcf \\ > protocols/ex1.ann.cc.vcf This analysis creates an output VCF file (\"ex1.ann.cc.vcf\") by adding new information to the INFO field for each variant: this includes information such as Cases=1,1,3 and Controls=8,6,22 which correspond to the number of homozygous non-reference, heterozygous and total allele counts in cases and controls for each variant. The program also calculates basic statistics for each variant based on the allele frequencies in the two groups using different models, which can be useful as a starting point for more in-depth statistical analysis. Step 3: Filtering variants. We can use the SnpSift filter command to reduce the number of candidate loci base on alleles in cases and controls. SnpSift filter allows users to create powerful filters that select variants using Boolean expressions containing data from the VCF fields. The expression we use to filter the VCF file \"ex1.ann.vcf\" is developed as follows. We expect all the three cases and none of the controls to be homozygous for the mutation. This is expressed using the following filter: (Cases[0] = 3) & (Controls[0] = 0) The full command line is: cat protocols/ex1.ann.cc.vcf | java -jar SnpSift.jar filter \\ \"(Cases[0] = 3) & (Controls[0] = 0)\" \\ > protocols/ex1.filtered.hom.vcf The filtered output file, filtered.hom_cases.vcf, contains over 400 variants satisfying our criteria. This is still too large to analyze by hand, so can we can add another filter to see if any of these variants is expected to have a high impact. To identify variants where any of these impacts is classified as either HIGH or MODERATE we add the condition (ANN[*].IMPACT = 'HIGH') | (ANN[*].IMPACT = 'MODERATE') . The new filtering commands become: cat protocols/ex1.ann.cc.vcf \\ | java -jar SnpSift.jar filter \\ \"(Cases[0] = 3) & (Controls[0] = 0) & ((ANN[*].IMPACT = 'HIGH') | (ANN[*].IMPACT = 'MODERATE'))\" \\ > protocols/ex1.filtered.vcf After filtering, only two variants satisfy our criteria, one of them is a stop_gained loss of function variant, whereas the other one is a missense_variant amino acid change. The first one is a known Cystic fibrosis variant. $ cat protocols/ex1.filtered.vcf | ./scripts/vcfInfoOnePerLine.pl 7 117227832 . G T . . AC 14 AN 22 ANN T|stop_gained|HIGH|CFTR|ENSG00000001626|transcript|ENST00000003084|protein_coding|12/27|c.1624G>T|p.Gly542*|1756/6128|1624/4443|542/1480|| ANN T|stop_gained|HIGH|CFTR|ENSG00000001626|transcript|ENST00000454343|protein_coding|11/26|c.1441G>T|p.Gly481*|1573/5949|1441/4260|481/1419|| ANN T|stop_gained|HIGH|CFTR|ENSG00000001626|transcript|ENST00000426809|protein_coding|11/26|c.1534G>T|p.Gly512*|1534/4316|1534/4316|512/1437||WARNING_TRANSCRIPT_INCOMPLETE ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|topological_domain:Cytoplasmic|ENST00000003084|protein_coding||c.1624G>T|||||| ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|domain:ABC_transporter_1|ENST00000003084|protein_coding||c.1624G>T|||||| ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|beta_strand|ENST00000003084|protein_coding|12/27|c.1624G>T|||||| ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|beta_strand|ENST00000454343|protein_coding|11/26|c.1441G>T|||||| ANN T|upstream_gene_variant|MODIFIER|AC000111.5|ENSG00000234001|transcript|ENST00000448200|processed_pseudogene||n.-1C>A|||||1362| ANN T|downstream_gene_variant|MODIFIER|CFTR|ENSG00000001626|transcript|ENST00000472848|processed_transcript||n.*148G>T|||||29| LOF (CFTR|ENSG00000001626|11|0.27) NMD (CFTR|ENSG00000001626|11|0.27) Cases 3 Cases 0 Cases 6 Controls 0 Controls 8 Controls 8 CC_TREND 9.111e-04 CC_GENO NaN CC_ALL 4.025e-02 CC_DOM 6.061e-03 CC_REC 1.000e+00 17 39135205 . ACA GCA,GCG . . AC 16 AC 8 AN 31 ANN GCG|missense_variant|MODERATE|KRT40|ENSG00000204889|transcript|ENST00000377755|protein_coding||c.1045_1047delTGTinsCGC|p.Cys349Arg|1082/1812|1045/1296|349/431|| ANN GCG|missense_variant|MODERATE|KRT40|ENSG00000204889|transcript|ENST00000398486|protein_coding||c.1045_1047delTGTinsCGC|p.Cys349Arg|1208/1772|1045/1296|349/431|| ANN GCA|synonymous_variant|LOW|KRT40|ENSG00000204889|transcript|ENST00000377755|protein_coding|6/7|c.1047T>C|p.Cys349Cys|1082/1812|1047/1296|349/431|| ANN GCA|synonymous_variant|LOW|KRT40|ENSG00000204889|transcript|ENST00000398486|protein_coding|8/9|c.1047T>C|p.Cys349Cys|1208/1772|1047/1296|349/431|| ANN GCA|sequence_feature|LOW|KRT40|ENSG00000204889|region_of_interest:Coil_2|ENST00000398486|protein_coding|6/9|c.1047T>C|||||| ANN GCG|sequence_feature|LOW|KRT40|ENSG00000204889|region_of_interest:Coil_2|ENST00000398486|protein_coding|7/9|c.1045_1047delTGTinsCGC|||||| ANN GCA|sequence_feature|LOW|KRT40|ENSG00000204889|region_of_interest:Rod|ENST00000398486|protein_coding|3/9|c.1047T>C|||||| ANN GCG|sequence_feature|LOW|KRT40|ENSG00000204889|region_of_interest:Rod|ENST00000398486|protein_coding|3/9|c.1045_1047delTGTinsCGC|||||| ANN GCA|3_prime_UTR_variant|MODIFIER|KRT40|ENSG00000204889|transcript|ENST00000461923|nonsense_mediated_decay|8/9|n.*509T>C|||||2348| ANN GCG|3_prime_UTR_variant|MODIFIER|KRT40|ENSG00000204889|transcript|ENST00000461923|nonsense_mediated_decay|8/9|n.*507_*509delTGTinsCGC|||||2346| ANN GCA|downstream_gene_variant|MODIFIER|AC004231.2|ENSG00000234477|transcript|ENST00000418393|antisense||n.*815A>G|||||3027| ANN GCG|downstream_gene_variant|MODIFIER|AC004231.2|ENSG00000234477|transcript|ENST00000418393|antisense||n.*815_*815delACAinsGCG|||||3027| ANN GCA|non_coding_exon_variant|MODIFIER|KRT40|ENSG00000204889|transcript|ENST00000461923|nonsense_mediated_decay|8/9|n.*509T>C|||||| ANN GCG|non_coding_exon_variant|MODIFIER|KRT40|ENSG00000204889|transcript|ENST00000461923|nonsense_mediated_decay|8/9|n.*507_*509delTGTinsCGC|||||| Cases 3 Cases 0 Cases 6 Controls 0 Controls 12 Controls 18 CC_TREND 7.008e-02 CC_GENO NaN CC_ALL 1.700e-01 CC_DOM 1.231e-01 CC_REC 1.000e+00 A chart showing how the variant propagates across the pedigree structure can be created as follows: java -jar SnpSift.jar pedShow \\ protocols/pedigree.tfam \\ protocols/ex1.filtered.vcf \\ protocols/chart Step 4. Using clinical databases. So far, since the purpose of the example was to show how annotations and filtering are performed to uncover new variants, we assumed that the causative variant was not known. In reality the variant is known and databases, such as ClinVar, have this information in convenient VCF format that can be used for annotations. We can annotate using ClinVar by using the following command: java -Xmx1g -jar SnpSift.jar \\ annotate \\ -v \\ protocols/db/clinvar_00-latest.vcf \\ protocols/ex1.ann.cc.vcf \\ > protocols/ex1.ann.cc.clinvar.vcf Our variant of interest is then annotated as \"Cystic Fibrosis\" (to find the variant, we filter for variants having ClinVar annotation \"CLNDBN\" that are in CFTR gene and have a stop_gained annotation): $ cat protocols/ex1.ann.cc.clinvar.vcf \\ | java -jar SnpSift.jar filter \\ \"(exists CLNDBN) & (ANN[*].EFFECT has 'stop_gained') & (ANN[*].GENE = 'CFTR')\" \\ > protocols/ex1.ann.cc.clinvar.filtered.vcf $ cat protocols/ex1.ann.cc.clinvar.filtered.vcf | ./scripts/vcfInfoOnePerLine.pl 7 117227832 rs113993959 G T . . AC 14 AN 22 ANN T|stop_gained|HIGH|CFTR|ENSG00000001626|transcript|ENST00000003084|protein_coding|12/27|c.1624G>T|p.Gly542*|1756/6128|1624/4443|542/1480|| ANN T|stop_gained|HIGH|CFTR|ENSG00000001626|transcript|ENST00000454343|protein_coding|11/26|c.1441G>T|p.Gly481*|1573/5949|1441/4260|481/1419|| ANN T|stop_gained|HIGH|CFTR|ENSG00000001626|transcript|ENST00000426809|protein_coding|11/26|c.1534G>T|p.Gly512*|1534/4316|1534/4316|512/1437||WARNING_TRANSCRIPT_INCOMPLETE ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|topological_domain:Cytoplasmic|ENST00000003084|protein_coding||c.1624G>T|||||| ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|domain:ABC_transporter_1|ENST00000003084|protein_coding||c.1624G>T|||||| ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|beta_strand|ENST00000003084|protein_coding||c.1624G>T|||||| ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|beta_strand|ENST00000454343|protein_coding||c.1441G>T|||||| ANN T|upstream_gene_variant|MODIFIER|AC000111.5|ENSG00000234001|transcript|ENST00000448200|processed_pseudogene||n.-1C>A|||||1362| ANN T|downstream_gene_variant|MODIFIER|CFTR|ENSG00000001626|transcript|ENST00000472848|processed_transcript||n.*148G>T|||||29| LOF (CFTR|ENSG00000001626|11|0.27) NMD (CFTR|ENSG00000001626|11|0.27) Cases 3 Cases 0 Cases 6 Controls 0 Controls 8 Controls 8 CC_TREND 9.111e-04 CC_GENO NaN CC_ALL 4.025e-02 CC_DOM 6.061e-03 CC_REC 1.000e+00 ASP true CLNACC RCV000007535.6|RCV000058931.3|RCV000119041.1 CLNALLE 1 CLNDBN Cystic_fibrosis|not_provided|Hereditary_pancreatitis CLNDSDB GeneReviews:MedGen:OMIM:Orphanet:SNOMED_CT|MedGen|GeneReviews:MedGen:OMIM:Orphanet:SNOMED_CT CLNDSDBID NBK1250:C0010674:219700:ORPHA586:190905008|CN221809|NBK84399:C0238339:167800:ORPHA676:68072000 CLNHGVS NC_000007.13:g.117227832G>T CLNORIGIN 1 CLNREVSTAT prof|single|single CLNSIG 5|5|5 CLNSRC CFTR2|HGMD|OMIM_Allelic_Variant|OMIM_Allelic_Variant CLNSRCID G542X|CM900049|602421.0009|602421.0095 GENEINFO CFTR:1080 LSD true NSN true OM true PM true PMC true REF true RS 113993959 RSPOS 117227832 S3D true SAO 1 SSR 0 VC SNV VLD true VP 0x050268000605040002110100 WGT 1 dbSNPBuildID 132 Example 2: Software Integration (GATK & Galaxy) Software Integration (Optional): Sequence analysis software is often run in high performance computers combining several programs into processing pipelines. Annotations and impact assessment software needs to provide integration points with other analysis steps of the pipeline. In the following paragraphs we describe how to integrate SnpEff with two programs commonly used in sequencing analysis pipelines: Genome Analysis toolkit (GATK 2), a command-line driven software; Galaxy 3, a web based software. GATK The Genome Analysis Toolkit 2 is one of the most popular programs for bioinformatics pipelines. Annotations can be easily integrated into GATK using SnpEff and GATK's VariantAnnotator module. Here we show how to annotate a file using SnpEff and GATK, as an alternative way of performing step 1. You should perform this step only if your processing pipeline is based on GATK: compared to running SnpEff from the command line, the results obtained when using GATK will only contain the highest impact annotation for each variant. This was a conscious trade-off made by the designers of GATK, partly because most biologists do this implicitly when reading a list of variants, but also to improve the readability and reduce the size of the annotation results. The method requires two steps: Annotating a VCF file using SnpEff Using GATK's VariantAnnotator to incorporate those annotations into the final VCF file. When using SnpEff for GATK compatibility, we must use the -o gatk command line option: java -Xmx8g -jar snpEff.jar \\ -v \\ -o gatk \\ GRCh37.75 \\ protocols/ex1.vcf \\ > protocols/ex1.ann.gatk.vcf Next, we process these variants using GATK. For this step to work correctly, we need to make sure that our data files are compatible with the requirements GATK places on reference genomes (see GATK's documentation for more details): in the fasta file, chromosomes are expected to be sorted in karyotypic order; a genome fasta-index file must be available; and a dictionary file must be pre-computed. Assuming these requirements are satisfied, we can run the following command, which will produce a GATK annotated file (\"ex1.gatk.vcf\"): java -Xmx8g -jar $HOME/tools/gatk/GenomeAnalysisTK.jar \\ -T VariantAnnotator \\ -R $HOME/genomes/GRCh37.75.fa \\ -A SnpEff \\ --variant protocols/ex1.vcf \\ --snpEffFile protocols/ex1.ann.gatk.vcf \\ -L protocols/ex1.vcf \\ -o protocols/ex1.gatk.vcf Note: We assumed GATK is installed in \"$HOME/tools/gatk/\" and the reference genome is contained in \"$HOME/genomes/GRCh37.75.fa\" These file locations should be adapted to the actual path in your computer. Galaxy Anther popular tool in bioinformatics is Galaxy 3, which allows pipelines to be created in a web environment using graphical interface, making it flexible and straightforward to use. SnpEff provides Galaxy modules . Once these modules are installed, we can run our sample annotation pipeline in Galaxy. Example 3: Non-Coding variants We show how to use SnpEff & SnpSift to annotate, prioritize and filter non-coding variants. Dataset: This example shows how to perform basic annotation of non-coding variants. It is based on a short list of 20 non-coding that were identified by sequencing a 700 kb region surrounding the gene T-box transcription factor (TBX5) in 260 patients with congenital heart disease 67. TBX5 is a transcription factor that plays a well-established dosage-dependent role in heart and limb development. Coding mutations in TBX5 have been frequently identified in patients with Holt-Oram syndrome, which is associated with abnormal hand, forearm and cardiac development. Data source : Regulatory variation in a TBX5 enhancer leads to isolated congenital heart disease . Step 1. Annotating variants. We will perform non-coding variant annotation using SnpEff following a similar approach to Procedure I. In this case, we construct a command line that instructs SnpEff to include motif information (\"-motif\") and putative transcription factor binding sites (TFBS) identified in the ENSEMBL Regulatory Build and the Jaspar database: java -Xmx8g -jar snpEff.jar \\ -v \\ -motif \\ GRCh37.75 \\ protocols/ex2.vcf \\ > protocols/ex2.ann.basic.vcf Step 2. Adding custom regulatory information. A quick scan through the results shows that most variants are catalogued as \"INTERGENIC\", and none of them is associated with a known TFBS. This is not surprising since TFBS are small and also because regulatory elements involved in cardiac or limb development may not be widely active in commonly studied adult tissues. In this case, basic annotations did not provide additional information that can be used to narrow down the list of candidate SNVs. To solve this, the authors examined data from other sources, including ChIP-seq data for H3K4me1 (a post-translationally modified histone protein found in transcriptionally active genome regions, including enhancers and promoters). Data produced from ChIP-Seq analysis are frequently published in BED, BigBed or similar formats, which can be used directly by SnpEff by adding the -interval command line option. This command line option can be used to add annotations using ChIP-Seq experiments from the ENCODE and Epigenome Roadmap projects: since multiple -interval options are allowed in each command line, it is a simple way to combine several annotations: java -Xmx8g -jar snpEff.jar \\ -v \\ -motif \\ -interval protocols/ex2_regulatory.bed \\ GRCh37.75 \\ protocols/ex2.vcf \\ > protocols/ex2.ann.vcf In the output VCF file, variants intersecting genomic regions from the -interval command line option are annotated as \"CUSTOM[ex2_regulatory]\" : the name in brackets identifies the file name provided to distinguish multiple annotation files. Step 3. Adding conservation information. In order to refine our search, we can also look for variants in highly conserved non-coding bases. SnpEff natively supports PhastCons scores, but can also add annotations based on any other user-defined score provided as a Wig or VCF file. The command line for annotating using the PhastCons score is: java -Xmx1g -jar SnpSift.jar \\ phastCons \\ -v \\ protocols/phastcons \\ protocols/ex2.ann.vcf \\ > protocols/ex2.ann.cons.vcf Now we can filter our results looking for a highly conserved SNP in the regulatory region. We do this by using a \"SnpSift filter\" command and the appropriate Boolean expression: cat protocols/ex2.ann.cons.vcf \\ | java -jar SnpSift.jar filter \\ \"(ANN[*].EFFECT = 'CUSTOM[ex2_regulatory]') & (exists PhastCons) & (PhastCons > 0.9)\" \\ > protocols/ex2.filtered.vcf SnpSift filter supports a flexible syntax to create Boolean expressions using the annotation data that provides a versatile way to prioritize shorter lists of SNPs for subsequent validation. This syntax is described in detail in the online manual . In this example, our filter results in only two candidate SNPs, one of which was extensively validated in the original study and is assumed to be causative. The principles illustrated in our example for a small set of SNVs can be applied to millions of variants from whole genome sequencing experiments. Similarly, although we filtered the SNVs using \"custom\" ChIP-seq data that provided in the original study, regulatory information from public Encode or Epigenome Roadmap datasets could be used in a first line investigation before generating our own Chip-seq or RNA-seq data using disease-relevant cells and tissues. Example 4: Sequencing data analysis Here we show an example on how to get from Sequencing data to an annotated variants file. Sequencing data example Warning This is an extremely simplified version on how to analyze the data from scratch. This is not meant to be a tutorial on sequencing analysis as it would be way beyond the scope of this handbook. Let's assume you have sequence data in FASTQ format (file \"s.fastq\") and your reference genome is dm5.34 (fly genome) # Download the genome, uncompress and rename file wget ftp://ftp.flybase.net/genomes/Drosophila_melanogaster/dmel_r5.34_FB2011_02/fasta/dmel-all-chromosome-r5.34.fasta.gz gunzip dmel-all-chromosome-r5.34.fasta.gz mv dmel-all-chromosome-r5.34.fasta dm5.34.fasta # Create a genome index (we assume you installed BWA) bwa index -bwtsw dm5.34.fasta # Map sequences to the genome: Create SAI file bwa aln -bwtsw dm5.34.fasta s.fastq > s.sai # Map sequences to the genome: Create SAM file bwa samse dm5.34.fasta s.sai s.fastq > s.sam # Create BAM file (we assume you installed SamTools) samtools view -S -b s.sam > s.bam # Sort BAM file (will create s_sort.bam) samtools sort s.bam s_sort # Create VCF file (BcfTools is part of samtools distribution) samtools mpileup -uf dm5.34.fasta s_sort.bam | bcftools view -vcg - > s.vcf # Analyze variants using snpEff java -Xmx8g -jar snpEff.jar dm5.34 s.vcf > s.ann.vcf This highly simplified sequencing data analysis pipeline, has these basic steps: Index the reference genome (bwa) Map reads to reference genome (bwa) Call variants (bcftools) Annotate variants (SnpEff) Example 5: Filter out variants (dbSnp) Here we show an example on how to get from Sequencing data to an annotated variants file. These are slightly more advanced examples. Here we'll try to show how to perform specific tasks. If you want to filter out SNPs from dbSnp, you can do it using SnpSift. You can download SnpSift from the \"Downloads\" page. You can download the file for this example here . Here is how to do it: Annotate ID fields using SnpSift annotate and DbSnp. # Annotate ID field using dbSnp # Note: SnpSift will automatically download and uncompress dbSnp database if not locally available. java -jar SnpSift.jar annotate -dbsnp file.vcf > file.dbSnp.vcf Info We annotate using dbSnp before using SnpEff in order to have 'known' and 'unknown' statistics in SnpEff's summary page. Those stats are based on the presence of an ID field. If the ID is non-empty, then it is assumed to be a 'known variant'. Annotate using SnpEff: java -Xmx8g -jar snpEff.jar eff -v GRCh37.75 file.dbSnp.vcf > file.ann.vcf Filter out variants that have a non-empty ID field. These variants are the ones that are NOT in dbSnp, since we annotated the ID field using rs-numbers from dbSnp in step 1. java -jar SnpSift.jar filter -f file.ann.vcf \"! exists ID\" > file.ann.not_in_dbSnp.vcf Info The expression using to filter the file is \"! exists ID\". This means that the ID field does not exists (i.e. the value is empty) which is represented as a dot (\".\") in a VCF file. Pipes Obviously you can perform the three previous commands, pipeling the out from one command to the next, thus avoiding the creation of intermediate files (for very large projects, this can be a significant amount of time). Info In SnpEff & SnpSift the STDIN is denoted by file name \"-\" So the previous commands would be: java -jar SnpSif.jar annotate -dbsnp file.vcf \\ | java -Xmx8g -jar snpEff.jar eff -v GRCh37.75 - \\ | java -jar SnpSift.jar filter \"! exists ID\" \\ > file.ann.not_in_dbSnp.vcf Here is an example of some entries in the annotated output file. You can see the 'ANN' field was added, predicting STOP_GAINED protein changes: $ cat demo.1kg.snpeff.vcf | grep stop_gained 1 889455 . G A 100.0 PASS ...;ANN=A|stop_gained|HIGH|... 1 897062 . C T 100.0 PASS ...;ANN=T|stop_gained|HIGH|... 1 900375 . G A 100.0 PASS ...;ANN=A|stop_gained|HIGH|... Note: The real output was edited for readability reasons. Example 6: Custom annotations SnpEff can annotate using user specified (custom) genomic intervals, allowing you to add any kind of annotations you want. In this example, we are analyzing using a specific version of the Yeast genome (we will assume that the database is not available, just to show a more complete example). We also want to add annotations of genomic regions known as 'ARS', which are defined in a GFF file. This turns out to be quite easy, thanks to SnpEff's \"custom intervals\" feature. SnpEff allows you to add \"custom\" annotations from intervals in several formats: TXT, BED, BigBed, VCF, GFF. So, for this example, we need to: Build the database: For the sake of this example, we are assuming that SnpEff doesn't have this database (which is not true in most real life situations). Create a file with the features we want to analyze (ARS) Annotate using the ARS features Step 1: Build database. Once more, this is done for the sake of the example, in real life Yeast databases are available and you don't need to build the database yourself. #--- # Download data #--- $ cd ~/snpEff $ mkdir data/sacCer $ cd data/sacCer $ wget http://downloads.yeastgenome.org/curation/chromosomal_feature/saccharomyces_cerevisiae.gff $ mv saccharomyces_cerevisiae.gff genes.gff Now that we've downloaded the reference genome, we can build the database: #--- # Build #--- $ cd ../.. # Add entry to config file $ echo \"sacCer.genome : Yeast\" >> snpEff.config # Build database $ java -Xmx1G -jar snpEff.jar build -gff3 sacCer Step 2: Create custom annotations file. We need a file that has our features of interest (in this case, the \"ARS\" features). Since those features ara available in the original GFF (saccharomyces_cerevisiae.gff) file, we can filter the file to create our \"custom\" annotations file. #--- # Create a features file #--- # GFF files have both genomic records and sequences, we need to know # where the 'records' section ends (it is delimited by a \"##FASTA\" line) $ grep -n \"^#\" data/sacCer/genes.gff | tail -n 1 22994:##FASTA # Note that I'm cutting the INFO column (only for readability reasons) $ head -n 22994 data/sacCer/genes.gff \\ | grep -v \"^#\" \\ | grep ARS \\ | cut -f 1 -d \";\" \\ > sacCer_ARS_features.gff So now we have a custom file ready to be used. Step 3: Annotate. We built the database and we have the ARS features file, so we are ready to annotate: #--- # Features annotations example #--- # Create a fake VCF file (one line), this is just an example to show that it works $ echo -e \"chrI\\t700\\t.\\tA\\tT\\t.\\t.\\t.\" > my.vcf $ java -jar snpEff.jar -interval sacCer_features.gff sacCer my.vcf > my.ann.vcf If we take a look at the results, we can see that the \"ARS\" feature is annotates (see last line) $ cat my.ann.vcf | grep -v \"^#\" | cut -f 8 | tr \",;\" \"\\n\\n\" EFF=missense_variant(LOW|MISSENSE|Cca/Tca|p.Pro55Ser/c.163A>T|84|YAL068W-A|protein_coding|CODING|YAL068W-A_mRNA|1|1|WARNING_REF_DOES_NOT_MATCH_GENOME) upstream_gene_variant(MODIFIER||1780||75|YAL067W-A|protein_coding|CODING|YAL067W-A_mRNA||1) downstream_gene_variant(MODIFIER||1107||120|YAL068C|protein_coding|CODING|YAL068C_mRNA||1) downstream_gene_variant(MODIFIER||51||104|YAL069W|protein_coding|CODING|YAL069W_mRNA||1) custom[sacCer_features](MODIFIER||||||ARS102||||1)","title":"Examples"},{"location":"examples/#usage-examples","text":"","title":"Usage examples"},{"location":"examples/#materials","text":"In this protocol we show how to analyze genomic variants using the SnpEff pipeline. Computer hardware: The materials required for this protocol are: a computer running a Unix operating system (Linux, OS.X), at least 16GB of RAM at least 8Gb of free disk space, Java a reasonably fast internet connection Users of Windows computers can install CygWin, a free Linux-like environment for Windows, although the precise commands listed in the protocol may need to adapted. Software: We use the SnpEff annotation program and its companion tool SnpSift. These programs can perform annotation, primary impact assessment and variants filtering, as well as many other tasks beyond the scope of this protocol. We highly recommend reading their comprehensive documentation available here . Before starting the protocol, it is necessary to download and install SnpEff. To do this, open a Unix, Linux or Cygwin shell and execute the following commands: # Move to home directory cd # Download and install SnpEff curl -v -L 'https://snpeff.blob.core.windows.net/versions/snpEff_latest_core.zip' > snpEff_latest_core.zip unzip snpEff_latest_core.zip Notes: SnpEff & SnpSift annotation software used in this protocol are under very active development and some command line option may change in the future. The standard installation is to add the package in the \"$HOME/snpEff\" directory (where $HOME is your home directory). To install SnpEff elsewhere, update the \"data_dir\" parameter in your \"snpEff.config\" file, as described in the SnpEff documentation. Once SnpEff is installed, we will enter the following commands to download the pre-built human database (GRCh37.75) that will be used to annotate our data. cd snpEff java -jar snpEff.jar download -v GRCh37.75 A list of pre-built databases for all other species is available by running the following command: java -jar snpEff.jar databases","title":"Materials"},{"location":"examples/#example-1-coding-variants","text":"We show how to use SnpEff & SnpSift to annotate, prioritize and filter coding variants. Dataset: In this genomic annotation example, we use a simulated dataset to show how to find genetic variants of a Mendelian recessive disease, Cystic fibrosis, caused by a high impact coding variant, a nonsense mutation in CFTR gene (G542*). The data files come from the publicly available \"CEPH_1463\" dataset, sequenced by Complete Genomics , and contains sequencing information for a family consisting of 4 grandparents, 2 parents and 11 siblings. Although these are healthy individuals, we artificially introduced a known Cystic fibrosis mutation on three siblings (cases) in a manner that was consistent with the underlying haplotype structure. We now download and un-compress the example data used in this protocol, which, for reasons of space and time, is limited to only chromosome 7 and 17: # Go to SnpEff's dir cd ~/snpEff # Download sample data curl -v -L `https://datasetsnpeff.blob.core.windows.net/dataset/protocols.zip?sv=2019-10-10&st=2020-09-01T00%3A00%3A00Z&se=2050-09-01T00%3A00%3A00Z&si=prod&sr=c&sig=isafOa9tGnYBAvsXFUMDGMTbsG2z%2FShaihzp7JE5dHw%3D` > protocols.zip unzip protocols.zip The goal in this example is to use SnpEff to find a mutation causing a Mendelian recessive trait. This will be done using a dataset of variant calls for chromosome 7 from a pedigree of 17 healthy individuals, sequenced by Complete Genomics, in which a coding variant causing cystic fibrosis was artificially introduced in three siblings (see Materials). For the purpose of this example, we assume that we do not know the causative variant, but that we know that we are dealing with a Mendelian recessive disorder, where the three siblings are affected (cases), but the 14 parents and grandparents are not (controls). Genomic variants are usually provided in a VCF file containing variant information of all the samples; storing the variant data in a single VCF file is the standard practice, not only because variant calling algorithms have better accuracy when run on all samples simultaneously, but also because it is much easier to annotate, manipulate and compare individuals when the data is stored and transferred together. A caveat of this approach is that VCF files can become very large when performing experiments with thousands of samples (from several Gigabytes to Terabytes in size). In the following protocol, SnpEff will add annotation fields to each variant record in the input VCF file. We will then use SnpSift, a filtering program to extract the most significant variants having annotations meeting certain criteria.","title":"Example 1: Coding variants"},{"location":"examples/#step-1-primary-variant-annotation-and-quality-control","text":"Our first step is to annotate each of the ~500,000 variants contained in the VCF file. By default, SnpEff adds primary annotations and basic impact assessment for coding and non-coding variants as described above. SnpEff has several command line options that can be used in this annotation stage and which are described in detail in the online manual . In this example, we annotate (all these annotations are activated by default when using SnpEff): loss of function and nonsense mediated decay predictions; protein domain annotations from the curated NextProt database; putative transcription factor binding sites from the ENSEMBL 'Regulatory Build' and Jaspar database; use HGVS notation for amino acid changes; and to create a web page summarizing the annotation results in \"ex1.html\" (option -stats ): java -Xmx8g -jar snpEff.jar -v -stats ex1.html GRCh37.75 protocols/ex1.vcf > protocols/ex1.ann.vcf SnpEff produces three output files : the HTML file containing summary statistics about the variants and their annotations; an annotated VCF file; and a text file summarizing the number of variant types per gene. Creation of the summary files can be de-activated to speed up the program (for example, when the application is used together with Galaxy). By default, the statistics file \"ex1.html\" is a standard HTML file that can be opened in any web browser to view quality control (QC) metrics. It can also be created in comma-separated values format (CSV) to be used by downstream processing programs as part of an automated pipeline. In our example, the summary file contains basic quality control statistics calculated from the variant file: for our data, the Ts/Ts ratio is close to 2.0 (Figure 1c) and missense / silent ratio is around 1.0 (Figure 1d), both of which are expected for human data (but these numbers may differ for other species). Large deviations from the expected values for the organism being sequenced might indicate problems with either the sequencing or variant calling pipelines. The summary file also contains QC information for the gene annotation used as input. In this example, 829 warnings (Figure 1a) were identified as a result of possible genomic annotation errors or small inconsistencies identified in the reference genome so we have to be careful analyzing those genes/transcripts. Other summary statistics are available, such as variant types (Figure 1e), variants effects (Figure 1d and 1g), and primary impacts (Figure 1b and 1g).","title":"Step 1: Primary variant annotation and quality control."},{"location":"examples/#step-2-counting-variants-in-case-and-control-subjects","text":"In the first step of our protocol, SnpEff created a VCF file with half million annotated variants. Rather than scanning each annotation manually, we will use the SnpSift program to create a filter that will identify a small subset of variants with interesting functional properties. Since the VCF files used in most sequencing studies are even larger than the one in this example, our overall approach is to start by creating a filter using a very restrictive set of criteria. If no relevant variant is found using this stringent filter, we will relax the criteria to include variants with lower predicted impact. In our example, since the pedigree is consistent with a Mendelian recessive disease, so we will first use SnpEff to find high impact variants that are homozygous in cases and either absent or heterozygous in controls. This provides a very strong genetic argument to select the promising variants and will be used as the first step in our filter. To do this, we will identify the case and control samples by providing SnpEff with pedigree information using a \"TFAM\" file (a standard file format used to describe pedigrees). In our example, the TFAM file (\"pedigree.tfam\") identifies the three cases (NA12879, NA12885, NA12886), and lists the other family members as controls. The \"caseControl\" command instructs the SnpSift program to count the number homozygous non-reference, heterozygous and allele count (number of non-reference alleles in each DNA sample) for both cases and controls groups (running time: ~60 minutes): java -Xmx1g -jar SnpSift.jar \\ caseControl \\ -v \\ -tfam protocols/pedigree.tfam \\ protocols/ex1.ann.vcf \\ > protocols/ex1.ann.cc.vcf This analysis creates an output VCF file (\"ex1.ann.cc.vcf\") by adding new information to the INFO field for each variant: this includes information such as Cases=1,1,3 and Controls=8,6,22 which correspond to the number of homozygous non-reference, heterozygous and total allele counts in cases and controls for each variant. The program also calculates basic statistics for each variant based on the allele frequencies in the two groups using different models, which can be useful as a starting point for more in-depth statistical analysis.","title":"Step 2: Counting variants in case and control subjects."},{"location":"examples/#step-3-filtering-variants","text":"We can use the SnpSift filter command to reduce the number of candidate loci base on alleles in cases and controls. SnpSift filter allows users to create powerful filters that select variants using Boolean expressions containing data from the VCF fields. The expression we use to filter the VCF file \"ex1.ann.vcf\" is developed as follows. We expect all the three cases and none of the controls to be homozygous for the mutation. This is expressed using the following filter: (Cases[0] = 3) & (Controls[0] = 0) The full command line is: cat protocols/ex1.ann.cc.vcf | java -jar SnpSift.jar filter \\ \"(Cases[0] = 3) & (Controls[0] = 0)\" \\ > protocols/ex1.filtered.hom.vcf The filtered output file, filtered.hom_cases.vcf, contains over 400 variants satisfying our criteria. This is still too large to analyze by hand, so can we can add another filter to see if any of these variants is expected to have a high impact. To identify variants where any of these impacts is classified as either HIGH or MODERATE we add the condition (ANN[*].IMPACT = 'HIGH') | (ANN[*].IMPACT = 'MODERATE') . The new filtering commands become: cat protocols/ex1.ann.cc.vcf \\ | java -jar SnpSift.jar filter \\ \"(Cases[0] = 3) & (Controls[0] = 0) & ((ANN[*].IMPACT = 'HIGH') | (ANN[*].IMPACT = 'MODERATE'))\" \\ > protocols/ex1.filtered.vcf After filtering, only two variants satisfy our criteria, one of them is a stop_gained loss of function variant, whereas the other one is a missense_variant amino acid change. The first one is a known Cystic fibrosis variant. $ cat protocols/ex1.filtered.vcf | ./scripts/vcfInfoOnePerLine.pl 7 117227832 . G T . . AC 14 AN 22 ANN T|stop_gained|HIGH|CFTR|ENSG00000001626|transcript|ENST00000003084|protein_coding|12/27|c.1624G>T|p.Gly542*|1756/6128|1624/4443|542/1480|| ANN T|stop_gained|HIGH|CFTR|ENSG00000001626|transcript|ENST00000454343|protein_coding|11/26|c.1441G>T|p.Gly481*|1573/5949|1441/4260|481/1419|| ANN T|stop_gained|HIGH|CFTR|ENSG00000001626|transcript|ENST00000426809|protein_coding|11/26|c.1534G>T|p.Gly512*|1534/4316|1534/4316|512/1437||WARNING_TRANSCRIPT_INCOMPLETE ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|topological_domain:Cytoplasmic|ENST00000003084|protein_coding||c.1624G>T|||||| ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|domain:ABC_transporter_1|ENST00000003084|protein_coding||c.1624G>T|||||| ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|beta_strand|ENST00000003084|protein_coding|12/27|c.1624G>T|||||| ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|beta_strand|ENST00000454343|protein_coding|11/26|c.1441G>T|||||| ANN T|upstream_gene_variant|MODIFIER|AC000111.5|ENSG00000234001|transcript|ENST00000448200|processed_pseudogene||n.-1C>A|||||1362| ANN T|downstream_gene_variant|MODIFIER|CFTR|ENSG00000001626|transcript|ENST00000472848|processed_transcript||n.*148G>T|||||29| LOF (CFTR|ENSG00000001626|11|0.27) NMD (CFTR|ENSG00000001626|11|0.27) Cases 3 Cases 0 Cases 6 Controls 0 Controls 8 Controls 8 CC_TREND 9.111e-04 CC_GENO NaN CC_ALL 4.025e-02 CC_DOM 6.061e-03 CC_REC 1.000e+00 17 39135205 . ACA GCA,GCG . . AC 16 AC 8 AN 31 ANN GCG|missense_variant|MODERATE|KRT40|ENSG00000204889|transcript|ENST00000377755|protein_coding||c.1045_1047delTGTinsCGC|p.Cys349Arg|1082/1812|1045/1296|349/431|| ANN GCG|missense_variant|MODERATE|KRT40|ENSG00000204889|transcript|ENST00000398486|protein_coding||c.1045_1047delTGTinsCGC|p.Cys349Arg|1208/1772|1045/1296|349/431|| ANN GCA|synonymous_variant|LOW|KRT40|ENSG00000204889|transcript|ENST00000377755|protein_coding|6/7|c.1047T>C|p.Cys349Cys|1082/1812|1047/1296|349/431|| ANN GCA|synonymous_variant|LOW|KRT40|ENSG00000204889|transcript|ENST00000398486|protein_coding|8/9|c.1047T>C|p.Cys349Cys|1208/1772|1047/1296|349/431|| ANN GCA|sequence_feature|LOW|KRT40|ENSG00000204889|region_of_interest:Coil_2|ENST00000398486|protein_coding|6/9|c.1047T>C|||||| ANN GCG|sequence_feature|LOW|KRT40|ENSG00000204889|region_of_interest:Coil_2|ENST00000398486|protein_coding|7/9|c.1045_1047delTGTinsCGC|||||| ANN GCA|sequence_feature|LOW|KRT40|ENSG00000204889|region_of_interest:Rod|ENST00000398486|protein_coding|3/9|c.1047T>C|||||| ANN GCG|sequence_feature|LOW|KRT40|ENSG00000204889|region_of_interest:Rod|ENST00000398486|protein_coding|3/9|c.1045_1047delTGTinsCGC|||||| ANN GCA|3_prime_UTR_variant|MODIFIER|KRT40|ENSG00000204889|transcript|ENST00000461923|nonsense_mediated_decay|8/9|n.*509T>C|||||2348| ANN GCG|3_prime_UTR_variant|MODIFIER|KRT40|ENSG00000204889|transcript|ENST00000461923|nonsense_mediated_decay|8/9|n.*507_*509delTGTinsCGC|||||2346| ANN GCA|downstream_gene_variant|MODIFIER|AC004231.2|ENSG00000234477|transcript|ENST00000418393|antisense||n.*815A>G|||||3027| ANN GCG|downstream_gene_variant|MODIFIER|AC004231.2|ENSG00000234477|transcript|ENST00000418393|antisense||n.*815_*815delACAinsGCG|||||3027| ANN GCA|non_coding_exon_variant|MODIFIER|KRT40|ENSG00000204889|transcript|ENST00000461923|nonsense_mediated_decay|8/9|n.*509T>C|||||| ANN GCG|non_coding_exon_variant|MODIFIER|KRT40|ENSG00000204889|transcript|ENST00000461923|nonsense_mediated_decay|8/9|n.*507_*509delTGTinsCGC|||||| Cases 3 Cases 0 Cases 6 Controls 0 Controls 12 Controls 18 CC_TREND 7.008e-02 CC_GENO NaN CC_ALL 1.700e-01 CC_DOM 1.231e-01 CC_REC 1.000e+00 A chart showing how the variant propagates across the pedigree structure can be created as follows: java -jar SnpSift.jar pedShow \\ protocols/pedigree.tfam \\ protocols/ex1.filtered.vcf \\ protocols/chart","title":"Step 3: Filtering variants."},{"location":"examples/#step-4-using-clinical-databases","text":"So far, since the purpose of the example was to show how annotations and filtering are performed to uncover new variants, we assumed that the causative variant was not known. In reality the variant is known and databases, such as ClinVar, have this information in convenient VCF format that can be used for annotations. We can annotate using ClinVar by using the following command: java -Xmx1g -jar SnpSift.jar \\ annotate \\ -v \\ protocols/db/clinvar_00-latest.vcf \\ protocols/ex1.ann.cc.vcf \\ > protocols/ex1.ann.cc.clinvar.vcf Our variant of interest is then annotated as \"Cystic Fibrosis\" (to find the variant, we filter for variants having ClinVar annotation \"CLNDBN\" that are in CFTR gene and have a stop_gained annotation): $ cat protocols/ex1.ann.cc.clinvar.vcf \\ | java -jar SnpSift.jar filter \\ \"(exists CLNDBN) & (ANN[*].EFFECT has 'stop_gained') & (ANN[*].GENE = 'CFTR')\" \\ > protocols/ex1.ann.cc.clinvar.filtered.vcf $ cat protocols/ex1.ann.cc.clinvar.filtered.vcf | ./scripts/vcfInfoOnePerLine.pl 7 117227832 rs113993959 G T . . AC 14 AN 22 ANN T|stop_gained|HIGH|CFTR|ENSG00000001626|transcript|ENST00000003084|protein_coding|12/27|c.1624G>T|p.Gly542*|1756/6128|1624/4443|542/1480|| ANN T|stop_gained|HIGH|CFTR|ENSG00000001626|transcript|ENST00000454343|protein_coding|11/26|c.1441G>T|p.Gly481*|1573/5949|1441/4260|481/1419|| ANN T|stop_gained|HIGH|CFTR|ENSG00000001626|transcript|ENST00000426809|protein_coding|11/26|c.1534G>T|p.Gly512*|1534/4316|1534/4316|512/1437||WARNING_TRANSCRIPT_INCOMPLETE ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|topological_domain:Cytoplasmic|ENST00000003084|protein_coding||c.1624G>T|||||| ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|domain:ABC_transporter_1|ENST00000003084|protein_coding||c.1624G>T|||||| ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|beta_strand|ENST00000003084|protein_coding||c.1624G>T|||||| ANN T|sequence_feature|LOW|CFTR|ENSG00000001626|beta_strand|ENST00000454343|protein_coding||c.1441G>T|||||| ANN T|upstream_gene_variant|MODIFIER|AC000111.5|ENSG00000234001|transcript|ENST00000448200|processed_pseudogene||n.-1C>A|||||1362| ANN T|downstream_gene_variant|MODIFIER|CFTR|ENSG00000001626|transcript|ENST00000472848|processed_transcript||n.*148G>T|||||29| LOF (CFTR|ENSG00000001626|11|0.27) NMD (CFTR|ENSG00000001626|11|0.27) Cases 3 Cases 0 Cases 6 Controls 0 Controls 8 Controls 8 CC_TREND 9.111e-04 CC_GENO NaN CC_ALL 4.025e-02 CC_DOM 6.061e-03 CC_REC 1.000e+00 ASP true CLNACC RCV000007535.6|RCV000058931.3|RCV000119041.1 CLNALLE 1 CLNDBN Cystic_fibrosis|not_provided|Hereditary_pancreatitis CLNDSDB GeneReviews:MedGen:OMIM:Orphanet:SNOMED_CT|MedGen|GeneReviews:MedGen:OMIM:Orphanet:SNOMED_CT CLNDSDBID NBK1250:C0010674:219700:ORPHA586:190905008|CN221809|NBK84399:C0238339:167800:ORPHA676:68072000 CLNHGVS NC_000007.13:g.117227832G>T CLNORIGIN 1 CLNREVSTAT prof|single|single CLNSIG 5|5|5 CLNSRC CFTR2|HGMD|OMIM_Allelic_Variant|OMIM_Allelic_Variant CLNSRCID G542X|CM900049|602421.0009|602421.0095 GENEINFO CFTR:1080 LSD true NSN true OM true PM true PMC true REF true RS 113993959 RSPOS 117227832 S3D true SAO 1 SSR 0 VC SNV VLD true VP 0x050268000605040002110100 WGT 1 dbSNPBuildID 132","title":"Step 4. Using clinical databases."},{"location":"examples/#example-2-software-integration-gatk-galaxy","text":"Software Integration (Optional): Sequence analysis software is often run in high performance computers combining several programs into processing pipelines. Annotations and impact assessment software needs to provide integration points with other analysis steps of the pipeline. In the following paragraphs we describe how to integrate SnpEff with two programs commonly used in sequencing analysis pipelines: Genome Analysis toolkit (GATK 2), a command-line driven software; Galaxy 3, a web based software.","title":"Example 2: Software Integration (GATK &amp; Galaxy)"},{"location":"examples/#gatk","text":"The Genome Analysis Toolkit 2 is one of the most popular programs for bioinformatics pipelines. Annotations can be easily integrated into GATK using SnpEff and GATK's VariantAnnotator module. Here we show how to annotate a file using SnpEff and GATK, as an alternative way of performing step 1. You should perform this step only if your processing pipeline is based on GATK: compared to running SnpEff from the command line, the results obtained when using GATK will only contain the highest impact annotation for each variant. This was a conscious trade-off made by the designers of GATK, partly because most biologists do this implicitly when reading a list of variants, but also to improve the readability and reduce the size of the annotation results. The method requires two steps: Annotating a VCF file using SnpEff Using GATK's VariantAnnotator to incorporate those annotations into the final VCF file. When using SnpEff for GATK compatibility, we must use the -o gatk command line option: java -Xmx8g -jar snpEff.jar \\ -v \\ -o gatk \\ GRCh37.75 \\ protocols/ex1.vcf \\ > protocols/ex1.ann.gatk.vcf Next, we process these variants using GATK. For this step to work correctly, we need to make sure that our data files are compatible with the requirements GATK places on reference genomes (see GATK's documentation for more details): in the fasta file, chromosomes are expected to be sorted in karyotypic order; a genome fasta-index file must be available; and a dictionary file must be pre-computed. Assuming these requirements are satisfied, we can run the following command, which will produce a GATK annotated file (\"ex1.gatk.vcf\"): java -Xmx8g -jar $HOME/tools/gatk/GenomeAnalysisTK.jar \\ -T VariantAnnotator \\ -R $HOME/genomes/GRCh37.75.fa \\ -A SnpEff \\ --variant protocols/ex1.vcf \\ --snpEffFile protocols/ex1.ann.gatk.vcf \\ -L protocols/ex1.vcf \\ -o protocols/ex1.gatk.vcf Note: We assumed GATK is installed in \"$HOME/tools/gatk/\" and the reference genome is contained in \"$HOME/genomes/GRCh37.75.fa\" These file locations should be adapted to the actual path in your computer.","title":"GATK"},{"location":"examples/#galaxy","text":"Anther popular tool in bioinformatics is Galaxy 3, which allows pipelines to be created in a web environment using graphical interface, making it flexible and straightforward to use. SnpEff provides Galaxy modules . Once these modules are installed, we can run our sample annotation pipeline in Galaxy.","title":"Galaxy"},{"location":"examples/#example-3-non-coding-variants","text":"We show how to use SnpEff & SnpSift to annotate, prioritize and filter non-coding variants. Dataset: This example shows how to perform basic annotation of non-coding variants. It is based on a short list of 20 non-coding that were identified by sequencing a 700 kb region surrounding the gene T-box transcription factor (TBX5) in 260 patients with congenital heart disease 67. TBX5 is a transcription factor that plays a well-established dosage-dependent role in heart and limb development. Coding mutations in TBX5 have been frequently identified in patients with Holt-Oram syndrome, which is associated with abnormal hand, forearm and cardiac development. Data source : Regulatory variation in a TBX5 enhancer leads to isolated congenital heart disease .","title":"Example 3: Non-Coding variants"},{"location":"examples/#step-1-annotating-variants","text":"We will perform non-coding variant annotation using SnpEff following a similar approach to Procedure I. In this case, we construct a command line that instructs SnpEff to include motif information (\"-motif\") and putative transcription factor binding sites (TFBS) identified in the ENSEMBL Regulatory Build and the Jaspar database: java -Xmx8g -jar snpEff.jar \\ -v \\ -motif \\ GRCh37.75 \\ protocols/ex2.vcf \\ > protocols/ex2.ann.basic.vcf","title":"Step 1. Annotating variants."},{"location":"examples/#step-2-adding-custom-regulatory-information","text":"A quick scan through the results shows that most variants are catalogued as \"INTERGENIC\", and none of them is associated with a known TFBS. This is not surprising since TFBS are small and also because regulatory elements involved in cardiac or limb development may not be widely active in commonly studied adult tissues. In this case, basic annotations did not provide additional information that can be used to narrow down the list of candidate SNVs. To solve this, the authors examined data from other sources, including ChIP-seq data for H3K4me1 (a post-translationally modified histone protein found in transcriptionally active genome regions, including enhancers and promoters). Data produced from ChIP-Seq analysis are frequently published in BED, BigBed or similar formats, which can be used directly by SnpEff by adding the -interval command line option. This command line option can be used to add annotations using ChIP-Seq experiments from the ENCODE and Epigenome Roadmap projects: since multiple -interval options are allowed in each command line, it is a simple way to combine several annotations: java -Xmx8g -jar snpEff.jar \\ -v \\ -motif \\ -interval protocols/ex2_regulatory.bed \\ GRCh37.75 \\ protocols/ex2.vcf \\ > protocols/ex2.ann.vcf In the output VCF file, variants intersecting genomic regions from the -interval command line option are annotated as \"CUSTOM[ex2_regulatory]\" : the name in brackets identifies the file name provided to distinguish multiple annotation files.","title":"Step 2. Adding custom regulatory information."},{"location":"examples/#step-3-adding-conservation-information","text":"In order to refine our search, we can also look for variants in highly conserved non-coding bases. SnpEff natively supports PhastCons scores, but can also add annotations based on any other user-defined score provided as a Wig or VCF file. The command line for annotating using the PhastCons score is: java -Xmx1g -jar SnpSift.jar \\ phastCons \\ -v \\ protocols/phastcons \\ protocols/ex2.ann.vcf \\ > protocols/ex2.ann.cons.vcf Now we can filter our results looking for a highly conserved SNP in the regulatory region. We do this by using a \"SnpSift filter\" command and the appropriate Boolean expression: cat protocols/ex2.ann.cons.vcf \\ | java -jar SnpSift.jar filter \\ \"(ANN[*].EFFECT = 'CUSTOM[ex2_regulatory]') & (exists PhastCons) & (PhastCons > 0.9)\" \\ > protocols/ex2.filtered.vcf SnpSift filter supports a flexible syntax to create Boolean expressions using the annotation data that provides a versatile way to prioritize shorter lists of SNPs for subsequent validation. This syntax is described in detail in the online manual . In this example, our filter results in only two candidate SNPs, one of which was extensively validated in the original study and is assumed to be causative. The principles illustrated in our example for a small set of SNVs can be applied to millions of variants from whole genome sequencing experiments. Similarly, although we filtered the SNVs using \"custom\" ChIP-seq data that provided in the original study, regulatory information from public Encode or Epigenome Roadmap datasets could be used in a first line investigation before generating our own Chip-seq or RNA-seq data using disease-relevant cells and tissues.","title":"Step 3. Adding conservation information."},{"location":"examples/#example-4-sequencing-data-analysis","text":"Here we show an example on how to get from Sequencing data to an annotated variants file.","title":"Example 4: Sequencing data analysis"},{"location":"examples/#sequencing-data-example","text":"Warning This is an extremely simplified version on how to analyze the data from scratch. This is not meant to be a tutorial on sequencing analysis as it would be way beyond the scope of this handbook. Let's assume you have sequence data in FASTQ format (file \"s.fastq\") and your reference genome is dm5.34 (fly genome) # Download the genome, uncompress and rename file wget ftp://ftp.flybase.net/genomes/Drosophila_melanogaster/dmel_r5.34_FB2011_02/fasta/dmel-all-chromosome-r5.34.fasta.gz gunzip dmel-all-chromosome-r5.34.fasta.gz mv dmel-all-chromosome-r5.34.fasta dm5.34.fasta # Create a genome index (we assume you installed BWA) bwa index -bwtsw dm5.34.fasta # Map sequences to the genome: Create SAI file bwa aln -bwtsw dm5.34.fasta s.fastq > s.sai # Map sequences to the genome: Create SAM file bwa samse dm5.34.fasta s.sai s.fastq > s.sam # Create BAM file (we assume you installed SamTools) samtools view -S -b s.sam > s.bam # Sort BAM file (will create s_sort.bam) samtools sort s.bam s_sort # Create VCF file (BcfTools is part of samtools distribution) samtools mpileup -uf dm5.34.fasta s_sort.bam | bcftools view -vcg - > s.vcf # Analyze variants using snpEff java -Xmx8g -jar snpEff.jar dm5.34 s.vcf > s.ann.vcf This highly simplified sequencing data analysis pipeline, has these basic steps: Index the reference genome (bwa) Map reads to reference genome (bwa) Call variants (bcftools) Annotate variants (SnpEff)","title":"Sequencing data example"},{"location":"examples/#example-5-filter-out-variants-dbsnp","text":"Here we show an example on how to get from Sequencing data to an annotated variants file. These are slightly more advanced examples. Here we'll try to show how to perform specific tasks. If you want to filter out SNPs from dbSnp, you can do it using SnpSift. You can download SnpSift from the \"Downloads\" page. You can download the file for this example here . Here is how to do it: Annotate ID fields using SnpSift annotate and DbSnp. # Annotate ID field using dbSnp # Note: SnpSift will automatically download and uncompress dbSnp database if not locally available. java -jar SnpSift.jar annotate -dbsnp file.vcf > file.dbSnp.vcf Info We annotate using dbSnp before using SnpEff in order to have 'known' and 'unknown' statistics in SnpEff's summary page. Those stats are based on the presence of an ID field. If the ID is non-empty, then it is assumed to be a 'known variant'. Annotate using SnpEff: java -Xmx8g -jar snpEff.jar eff -v GRCh37.75 file.dbSnp.vcf > file.ann.vcf Filter out variants that have a non-empty ID field. These variants are the ones that are NOT in dbSnp, since we annotated the ID field using rs-numbers from dbSnp in step 1. java -jar SnpSift.jar filter -f file.ann.vcf \"! exists ID\" > file.ann.not_in_dbSnp.vcf Info The expression using to filter the file is \"! exists ID\". This means that the ID field does not exists (i.e. the value is empty) which is represented as a dot (\".\") in a VCF file. Pipes Obviously you can perform the three previous commands, pipeling the out from one command to the next, thus avoiding the creation of intermediate files (for very large projects, this can be a significant amount of time). Info In SnpEff & SnpSift the STDIN is denoted by file name \"-\" So the previous commands would be: java -jar SnpSif.jar annotate -dbsnp file.vcf \\ | java -Xmx8g -jar snpEff.jar eff -v GRCh37.75 - \\ | java -jar SnpSift.jar filter \"! exists ID\" \\ > file.ann.not_in_dbSnp.vcf Here is an example of some entries in the annotated output file. You can see the 'ANN' field was added, predicting STOP_GAINED protein changes: $ cat demo.1kg.snpeff.vcf | grep stop_gained 1 889455 . G A 100.0 PASS ...;ANN=A|stop_gained|HIGH|... 1 897062 . C T 100.0 PASS ...;ANN=T|stop_gained|HIGH|... 1 900375 . G A 100.0 PASS ...;ANN=A|stop_gained|HIGH|... Note: The real output was edited for readability reasons.","title":"Example 5: Filter out variants (dbSnp)"},{"location":"examples/#example-6-custom-annotations","text":"SnpEff can annotate using user specified (custom) genomic intervals, allowing you to add any kind of annotations you want. In this example, we are analyzing using a specific version of the Yeast genome (we will assume that the database is not available, just to show a more complete example). We also want to add annotations of genomic regions known as 'ARS', which are defined in a GFF file. This turns out to be quite easy, thanks to SnpEff's \"custom intervals\" feature. SnpEff allows you to add \"custom\" annotations from intervals in several formats: TXT, BED, BigBed, VCF, GFF. So, for this example, we need to: Build the database: For the sake of this example, we are assuming that SnpEff doesn't have this database (which is not true in most real life situations). Create a file with the features we want to analyze (ARS) Annotate using the ARS features","title":"Example 6: Custom annotations"},{"location":"examples/#step-1-build-database","text":"Once more, this is done for the sake of the example, in real life Yeast databases are available and you don't need to build the database yourself. #--- # Download data #--- $ cd ~/snpEff $ mkdir data/sacCer $ cd data/sacCer $ wget http://downloads.yeastgenome.org/curation/chromosomal_feature/saccharomyces_cerevisiae.gff $ mv saccharomyces_cerevisiae.gff genes.gff Now that we've downloaded the reference genome, we can build the database: #--- # Build #--- $ cd ../.. # Add entry to config file $ echo \"sacCer.genome : Yeast\" >> snpEff.config # Build database $ java -Xmx1G -jar snpEff.jar build -gff3 sacCer","title":"Step 1: Build database."},{"location":"examples/#step-2-create-custom-annotations-file","text":"We need a file that has our features of interest (in this case, the \"ARS\" features). Since those features ara available in the original GFF (saccharomyces_cerevisiae.gff) file, we can filter the file to create our \"custom\" annotations file. #--- # Create a features file #--- # GFF files have both genomic records and sequences, we need to know # where the 'records' section ends (it is delimited by a \"##FASTA\" line) $ grep -n \"^#\" data/sacCer/genes.gff | tail -n 1 22994:##FASTA # Note that I'm cutting the INFO column (only for readability reasons) $ head -n 22994 data/sacCer/genes.gff \\ | grep -v \"^#\" \\ | grep ARS \\ | cut -f 1 -d \";\" \\ > sacCer_ARS_features.gff So now we have a custom file ready to be used.","title":"Step 2: Create custom annotations file."},{"location":"examples/#step-3-annotate","text":"We built the database and we have the ARS features file, so we are ready to annotate: #--- # Features annotations example #--- # Create a fake VCF file (one line), this is just an example to show that it works $ echo -e \"chrI\\t700\\t.\\tA\\tT\\t.\\t.\\t.\" > my.vcf $ java -jar snpEff.jar -interval sacCer_features.gff sacCer my.vcf > my.ann.vcf If we take a look at the results, we can see that the \"ARS\" feature is annotates (see last line) $ cat my.ann.vcf | grep -v \"^#\" | cut -f 8 | tr \",;\" \"\\n\\n\" EFF=missense_variant(LOW|MISSENSE|Cca/Tca|p.Pro55Ser/c.163A>T|84|YAL068W-A|protein_coding|CODING|YAL068W-A_mRNA|1|1|WARNING_REF_DOES_NOT_MATCH_GENOME) upstream_gene_variant(MODIFIER||1780||75|YAL067W-A|protein_coding|CODING|YAL067W-A_mRNA||1) downstream_gene_variant(MODIFIER||1107||120|YAL068C|protein_coding|CODING|YAL068C_mRNA||1) downstream_gene_variant(MODIFIER||51||104|YAL069W|protein_coding|CODING|YAL069W_mRNA||1) custom[sacCer_features](MODIFIER||||||ARS102||||1)","title":"Step 3: Annotate."},{"location":"features/","text":"Features, versions and roadmap 1. Roadmap Major features planned: SnpEff : Improvements in loss of function analysis SnpSift : Switch to ANTLR 4.X, handle arbitrary expressions. 2. Features Features by version Version: 4.3 (2016-09). Improved support for gene fusions Annotation of large structural variants Version: 4.1 (2015-01). Standard annotation format: 'ANN' INFO field A better / more robust HGVS implementation Variants are re-aligned to the most 3'UTR (in agreement with HGVS). Version: 4.0 (2014-11). Consistent 'help' screen when using command line option -h Effects sorted canonical transcripts first (for same level of effect / impact) Corrected problem on LOF annotations for gene names having spaces. Version: 4.0 (2014-07). HGVS notations (now is default) Sequence Ontology terms (now by default) SnpEff downloads databases automatically Automatic third party databases downloads Support for new genome versions (such as GRCh38 / hg38) NextProt, Loss of function (LOF) and Nonsense mediated decay (MND) annotations by default Improved protein coding transcript detection (when building databases) Full support for MIXED variants: E.g. Some variants maybe a combination of Insertions, Deletions, SNPs or MNPs. Major code refactoring SnpSift annotate : Improved annotate support. SnpSift dbNsfp : Several improvements on annotation methods. Added support for gVCF files Version: 3.6 (2013-05-23). Improved support for MIXED variants: E.g. Some variants maybe a combination of Insertions, Deletions, SNPs or MNPs. Improved HGVS notation SnpSift: concordance : Calculate concordance statistics between two VCF files (e.g. a sequencing and a chip-genotyping experiment) SnpSift: vcfCheck command (check VCF for several \"common\" problems) Moved to Java 7. mostly due to several problems in Java 6 libraries when reading bgzip files. Version: 3.5 (2013-03-23). Improvements in cancer sample annotations Added SPLICE_REGION annotation SnpSift private : Annotate if a variant is \"private\" to a family (or cohort) SnpSift: ccs : Case / control summary statistics (of annotated files). SnpSift annotate : Added tabix indexed files support. Automatic detection. Version: 3.4 (2013-11-23). Automatic database download (\"-download\" option) Cancer samples: can be defined using a TXT file instead of VCF header. Improved GenBank Extended configuration options Better frame handling for GTF/GFF files Improvements in HGVS notation Galaxy support: Improvements and bug fixes SnpSift: Better support for dbNSFP (v2.1) Version: 3.3 (2013-06-12). Over 8,500 genomes supported. All ENSEMBL (version 18) : Bacteria, Fungi, Metazoa, Plants and Protist genomes added. NextProt annotations added Motif annotations support added SnpSift: GeneSet annotations SnpEff count: Genomic region statistics counting reads, variants, intervals, etc. Version: 3.2 (2013-14-01). Cancer variants analysis GATK compatible ( -o gatk ) HGVS notations support Version: 3.1 (2012-11-02). All NCBI bacterial genomes added: Over 2,500 genomes added! Loss of function effect and tag added (experimental command line option '-lof') Nonsense-mediated decay effect and tag added (experimental command line option '-lof') ENSEMBL version 68 genomes added SnpEff 'countReads' count number of reads and bases (form a BAM file) on each gene, transcript, exon, intron, etc. SnpEff Intron and Intergenic annotations improved. Version: 3.0, revision 'f' (2012-08-23). GATK output format compatibility option: '-o gatk' Fixed problem when parsing comment after GFF headers. Added GENCODE tags for GTF parsing Splice site analysis tools Analysis of U12 branch sites. Minor problems caused by empty VCF headers solved. Fixed bug in calculation of degenerate sites. Fixed problem in canonical transcripts. Plasmodium falciparum hand curated versions (by Daniel Park, Broad): Pf3D7v72 and Pf3D7v90 Maven project, created by Louis Letourneau. Project source code changed to SVN (Louis Letourneau). Databases will be 'backwards compatible' from now on. New format for VCF files: added CDS length in amino acid (AA_LEN field). Canonical transcript filter (command line option \"-canon\"). Improved GenBank parsing. SnpSift 'dbnsfp': Annotate using dbNSFP (Louis Letourneau). SnpSift 'gwasCat': Added GWA catalog annotations. SnpSift 'extractFields': extract fields to TXT files (tab separated) SnpSift 'sift': Annotate using SIFT database. SnpSift 'Annotate' and 'AnnMem': Now support to add all fields in a VCF file for annotations. Version: 2.1b (2012-04-26). Revision \"2.1c\" : Maven project (by Louis Letourneau) Revision \"2.1c\" : Improved Galaxy wrappers (by Peter briggs) Revision \"2.1b\" : Improved RefSeq parsing Revision \"2.1a\" : Multi-thread race condition solved. Note If you are using hg19 , it is recommended to download the latest database (due to improved RefSeq parsing in 2.1b). Added multi-threaded support (command line option '-t'). GenBank support for building databases. See details here . Config file simplified E.Coli database added Galaxy download database option added. Added all ENSEMBL version 66 genomes Database 'download' issue solved. Apparently SourceForge servers were choking on URL that had double slashes, this should not happen. Implemented a workaround. SnpSift GWAS catalog: Annotate using GWAS Catalog . SnpSift: Added 'varType' to annotate variant type (SNP/MNP/INS/DEL), as well as HOM/HET if possible. Faster VCF processing. Version: 2.0.5 (2011-11-25). Support for RARE amino acids (see details here ) Database for Soybean (Glycine max) added Version: 2.0.5 (2011-11-25). Database download command, e.g. \"java -jar snpEff.jar download GRCH37.64\" Added all ENSEMBL version 65 genomes RefSeq annotations support added. Rogue transcript filter: By default SnpEff filters out some suspicious transcripts from annotations databases. This should improve false positive rates. Amino acid changes in HGVS style (VCF output) Optimized parsing for VCF files with large number of samples (genotypes). Option to suppress summary calculation ('-noStats'), can speed up processing considerably in cases where VCF files have hundreds or thousands of genotype fields. Option '-onlyCoding' is set to 'auto' to reduce number of false positives (see next). Option '-onlyCoding' can be assigne a value: If value is 'true', report only 'protein_coding' transcripts as protein coding changes. If 'false', report all transcript as if they were conding. Default: Auto, i.e. if transcripts any marked as 'protein_coding' the set it to 'true', if no transcripts are marked as 'protein_coding' then set it to 'false'. Added BED output format. This is usefull to annotate the output of a Chip-Seq experiment (e.g. after performing peak calling with MACS, you want to know where the peaks hit). Added BED Annotation output format. This is usefull to get all annotation intervals that intersect a set of variants (or genomic regions). SnpSift filter : Added generic index ('*') for variables, genotypes and effects. E.g.: ( 'GEN[*].GT = '1|1' ) Added support for 'EFF' and subfields (from SnpEff processed files). E.g.: ( EFF[*].EFFECT = 'NON_SYNONYMOUS_CODING' ) SnpSift intidx : Designed to extract a small number of intervals from huge VCF files. Added indexing using memory mapped I/O files for retrieving intervals from huge VCF files. Works really fast! Version: 2.0.3 (2011-10-08) Functional classes added in VCF output (i.e. NONE, SILENT, MISSENSE, NONSENSE) Added MODIFIER effect 'impact'. Rice genome added. Added all ENSEMBL version 64 genomes. Several minor issues solved. Report usage statistics to server (can be disabled using '-noLog' options). Version: 2.0.2 (2011-09-09) VCF output format GATK integration. Now you can use SnpEff from GATK's VariantAnnotator . Default input file is STDIN. I.e. inputFile parameter can be ommited now. Gene list outputs to a TXT file (tab separated) instead of the summary (HTML) file. Command line format changed for various options Option '-sort' deprecated. Version: 1.9.6 (2011-08-08) Ensembl genomes v63 added. Warning! Genome names changed to agree with Ensembl naming convention, here are the names: Full name Short name Ailuropoda_melanoleuca ailMel1.63 Anolis_carolinensis AnoCar2.0.63 Bos_taurus Btau_4.0.63 Caenorhabditis_elegans WS220.63 Callithrix_jacchus C_jacchus3.2.1.63 Canis_familiaris BROADD2.63 Cavia_porcellus cavPor3.63 Choloepus_hoffmanni choHof1.63 Ciona_intestinalis JGI2.63 Ciona_savignyi CSAV2.0.63 Danio_rerio Zv9.63 Dasypus_novemcinctus dasNov2.63 Dipodomys_ordii dipOrd1.63 Drosophila_melanogaster BDGP5.25.63 Echinops_telfairi TENREC.63 Equus_caballus EquCab2.63 Erinaceus_europaeus HEDGEHOG.63 Felis_catus CAT.63 Gallus_gallus WASHUC2.63 Gasterosteus_aculeatus BROADS1.63 Gorilla_gorilla gorGor3.63 Homo_sapiens GRCh37.63 Loxodonta_africana loxAfr3.63 Macaca_mulatta MMUL_1.63 Macropus_eugenii Meug_1.0.63 Meleagris_gallopavo UMD2.63 Microcebus_murinus micMur1.63 Monodelphis_domestica BROADO5.63 Mus_musculus NCBIM37.63 Myotis_lucifugus Myoluc2.0.63 Nomascus_leucogenys Nleu1.0.63 Ochotona_princeps pika.63 Ornithorhynchus_anatinus OANA5.63 Oryctolagus_cuniculus oryCun2.63 Oryzias_latipes MEDAKA1.63 Otolemur_garnettii BUSHBABY1.63 Pan_troglodytes CHIMP2.1.63 Pongo_abelii PPYG2.63 Procavia_capensis proCap1.63 Pteropus_vampyrus pteVam1.63 Rattus_norvegicus RGSC3.4.63 Saccharomyces_cerevisiae EF3.63 Sorex_araneus COMMON_SHREW1.63 Spermophilus_tridecemlineatus SQUIRREL.63 Sus_scrofa Sscrofa9.63 Taeniopygia_guttata taeGut3.2.4.63 Takifugu_rubripes FUGU4.63 Tarsius_syrichta tarSyr1.63 Tetraodon_nigroviridis TETRAODON8.63 Tupaia_belangeri TREESHREW.63 Tursiops_truncatus turTru1.63 Vicugna_pacos vicPac1.63 Xenopus_tropicalis JGI_4.2.63 Problems with VCF heterozygous: Fixed Problems parsing some InDels: Fixed Error conditions on deletion at the border between UTR and Exon: Fixed Problems reporting some CDS relative positions: Fixed Some issues related to distance calculation on Downstream genes on negative strands: Fixed Version: 1.9.5 (2011-03-10) Variants per gene table. Improvements in summary report. Improved GFF3 parsing. Several genomes added. Version: 1.9 (2011-03-10) Features recently added: Improved command line Genomes added (Arabidopsis) : alyrata107, athaliana130 Genomes added (all ENSEMBL version 61): ailmel1.61, anoCar2.0.61, btau4.0.61, bushBaby1.61, calJac3.2.1.61, canFam2.61, cat1.61, cavPor3.61, ce.WS220.61, chimp2.1.61, choHof1.61, cInt2.61, cSav2.0.61, danRer9.61, dasNov2.61, dipOrd1.61, dm5.25.61, equCab2.61, eriEur1.61, fugu4.61, gacu1.61, ggallus2.61, gorGor3.61, hg37.61, loxAfr3.61, medaka1.61, meug1.0.61, micMur1.61, mm37.61, mmul1.61, monDom5.61, myoLuc1.61, oana5.61, ochPri2.61, oryCun2.61, ppyg2.61, proCap1.61, pteVam1.61, rat3.4.61, sacCer2.61, sorAra1.61, speTri1.61, sScrofa9.61, taeGut3.2.4.61, tarSyr1.61, tenrec1.61, tetraodon8.61, tupBel1.61, turkey.UMD2.61, turTru1.61, vicPac1.61, xtrop4.1.61 Genomes added (Flybase): dm5.34 Genomes added (legacy hg18): hg36.54 Improved summary and statistics Supports BED format: if you just need to check where an interval hits (e.g. exon, intron, genes, etc.) Added support for GTF 2.2 format Improved robustness of GFF3 and GFF2 parsing Improved splice site detection: SPLICE_SITE_DONOR and SPLICE_SITE_ACCEPTOR Improved support for insertions and deletions: CODON_INSERTION, CODON_CHANGE_PLUS_CODON_INSERTION, CODON_DELETION, CODON_CHANGE_PLUS_CODON_DELETION Improved support for large deletions: EXON_DELETED and UTR_DELETED Added suport for INTRON_CONSERVED and INTERGENIC_CONSERVED intervals (available in GTF 2.2 files) Added support for ambiguous sequences in exons (e.g. sequences that have \"N\") Database dump support: java -jar snpEff.jar dump genome_version CDS testing support: java -jar snpEff.jar cds genome_version cds.fasta Older features Show DNA and amino acid sequence before and after change: option \"-a, --around\", e.g. \"-a 5\" shows 5 codons around sequence change) WARNING : Since version 1.7 snpEff assumes one-based coordinates (i.e. option \"-1\" is the default instead of \"-0\") WARNING : Since version 1.7 snpEff does not sort sequence changes. You should use option \"-sort\" if you want that. Genomes added (Pseudomonas): Pseudomonas aeruginosa (paeru.PA01 and paeru.PA14) and Pseudomonas fluorescens (pfluo.SBW25.NC_009444 and pfluo.SBW25.NC_012660) Genomes supported (all ENSEMBL version 60): ailMel1.60, amel2, anoCar1.0.60, btau4.0.59, btau4.0.60, bushBaby1.60, calJac3.2.1.60, canFam2.59, canFam2.60, cat1.60, cavPor3.60, ce6, ce.WS210.60, chimp2.1.59, chimp2.1.60, choHof1.60, cInt2.60, cSav2.0.60, danRer6, danRer8.59, danRer9.60, dasNov2.60, dipOrd1.60, dm3, dm5.12, dm5.22, dm5.25.59, dm5.25.60, dm5.30, dm5.31, equCab2.60, eriEur1.60, fugu4.60, gacu1.60, ggallus2.59, ggallus2.60, gorGor3.60, hg37, hg37.59, hg37.60, loxAfr3.60, medaka1.60, meug1.0.60, micMur1.60, mm37, mm37.59, mm37.60, mmul1.60, monDom5.60, myoLuc1.60, oana5.60, ochPri2.60, oryCun2.60, ppyg2.60, proCap1.60, pteVam1.60, rat3.4.59, rat3.4.60, sacCer2, sacCer2.59, sacCer2.60, SIVmac239, sorAra1.60, speTri1.60, sScrofa9.60, taeGut3.2.4.60, tarSyr1.60, tenrec1.60, testCase, tetraodon8.60, tupBel1.60, turTru1.60, vicPac1.60, xtrop4.1.60 VCF4 input format is now supported Support new genome Apis Mellifera Statistics and plots Filter intervals (only analyze selected intervals) One-based and zero-based positions for input and output (as well arbitrary offsets) Support for heterozygous SNPs (e.g. A/W) Predicts insertions and deletions (FRAME_SHIFT) Supports GFF format when building databases. Added: Multiple nucleotide polymorphisms (MNPs) New format shows SNP quality and coverage. Can filter SNPs, InDels and MNPs based on quality, coverage and zygosity (Hom/Het).","title":"Features"},{"location":"features/#features-versions-and-roadmap","text":"","title":"Features, versions and roadmap"},{"location":"features/#1-roadmap","text":"Major features planned: SnpEff : Improvements in loss of function analysis SnpSift : Switch to ANTLR 4.X, handle arbitrary expressions.","title":"1. Roadmap"},{"location":"features/#2-features","text":"Features by version Version: 4.3 (2016-09). Improved support for gene fusions Annotation of large structural variants Version: 4.1 (2015-01). Standard annotation format: 'ANN' INFO field A better / more robust HGVS implementation Variants are re-aligned to the most 3'UTR (in agreement with HGVS). Version: 4.0 (2014-11). Consistent 'help' screen when using command line option -h Effects sorted canonical transcripts first (for same level of effect / impact) Corrected problem on LOF annotations for gene names having spaces. Version: 4.0 (2014-07). HGVS notations (now is default) Sequence Ontology terms (now by default) SnpEff downloads databases automatically Automatic third party databases downloads Support for new genome versions (such as GRCh38 / hg38) NextProt, Loss of function (LOF) and Nonsense mediated decay (MND) annotations by default Improved protein coding transcript detection (when building databases) Full support for MIXED variants: E.g. Some variants maybe a combination of Insertions, Deletions, SNPs or MNPs. Major code refactoring SnpSift annotate : Improved annotate support. SnpSift dbNsfp : Several improvements on annotation methods. Added support for gVCF files Version: 3.6 (2013-05-23). Improved support for MIXED variants: E.g. Some variants maybe a combination of Insertions, Deletions, SNPs or MNPs. Improved HGVS notation SnpSift: concordance : Calculate concordance statistics between two VCF files (e.g. a sequencing and a chip-genotyping experiment) SnpSift: vcfCheck command (check VCF for several \"common\" problems) Moved to Java 7. mostly due to several problems in Java 6 libraries when reading bgzip files. Version: 3.5 (2013-03-23). Improvements in cancer sample annotations Added SPLICE_REGION annotation SnpSift private : Annotate if a variant is \"private\" to a family (or cohort) SnpSift: ccs : Case / control summary statistics (of annotated files). SnpSift annotate : Added tabix indexed files support. Automatic detection. Version: 3.4 (2013-11-23). Automatic database download (\"-download\" option) Cancer samples: can be defined using a TXT file instead of VCF header. Improved GenBank Extended configuration options Better frame handling for GTF/GFF files Improvements in HGVS notation Galaxy support: Improvements and bug fixes SnpSift: Better support for dbNSFP (v2.1) Version: 3.3 (2013-06-12). Over 8,500 genomes supported. All ENSEMBL (version 18) : Bacteria, Fungi, Metazoa, Plants and Protist genomes added. NextProt annotations added Motif annotations support added SnpSift: GeneSet annotations SnpEff count: Genomic region statistics counting reads, variants, intervals, etc. Version: 3.2 (2013-14-01). Cancer variants analysis GATK compatible ( -o gatk ) HGVS notations support Version: 3.1 (2012-11-02). All NCBI bacterial genomes added: Over 2,500 genomes added! Loss of function effect and tag added (experimental command line option '-lof') Nonsense-mediated decay effect and tag added (experimental command line option '-lof') ENSEMBL version 68 genomes added SnpEff 'countReads' count number of reads and bases (form a BAM file) on each gene, transcript, exon, intron, etc. SnpEff Intron and Intergenic annotations improved. Version: 3.0, revision 'f' (2012-08-23). GATK output format compatibility option: '-o gatk' Fixed problem when parsing comment after GFF headers. Added GENCODE tags for GTF parsing Splice site analysis tools Analysis of U12 branch sites. Minor problems caused by empty VCF headers solved. Fixed bug in calculation of degenerate sites. Fixed problem in canonical transcripts. Plasmodium falciparum hand curated versions (by Daniel Park, Broad): Pf3D7v72 and Pf3D7v90 Maven project, created by Louis Letourneau. Project source code changed to SVN (Louis Letourneau). Databases will be 'backwards compatible' from now on. New format for VCF files: added CDS length in amino acid (AA_LEN field). Canonical transcript filter (command line option \"-canon\"). Improved GenBank parsing. SnpSift 'dbnsfp': Annotate using dbNSFP (Louis Letourneau). SnpSift 'gwasCat': Added GWA catalog annotations. SnpSift 'extractFields': extract fields to TXT files (tab separated) SnpSift 'sift': Annotate using SIFT database. SnpSift 'Annotate' and 'AnnMem': Now support to add all fields in a VCF file for annotations. Version: 2.1b (2012-04-26). Revision \"2.1c\" : Maven project (by Louis Letourneau) Revision \"2.1c\" : Improved Galaxy wrappers (by Peter briggs) Revision \"2.1b\" : Improved RefSeq parsing Revision \"2.1a\" : Multi-thread race condition solved. Note If you are using hg19 , it is recommended to download the latest database (due to improved RefSeq parsing in 2.1b). Added multi-threaded support (command line option '-t'). GenBank support for building databases. See details here . Config file simplified E.Coli database added Galaxy download database option added. Added all ENSEMBL version 66 genomes Database 'download' issue solved. Apparently SourceForge servers were choking on URL that had double slashes, this should not happen. Implemented a workaround. SnpSift GWAS catalog: Annotate using GWAS Catalog . SnpSift: Added 'varType' to annotate variant type (SNP/MNP/INS/DEL), as well as HOM/HET if possible. Faster VCF processing. Version: 2.0.5 (2011-11-25). Support for RARE amino acids (see details here ) Database for Soybean (Glycine max) added Version: 2.0.5 (2011-11-25). Database download command, e.g. \"java -jar snpEff.jar download GRCH37.64\" Added all ENSEMBL version 65 genomes RefSeq annotations support added. Rogue transcript filter: By default SnpEff filters out some suspicious transcripts from annotations databases. This should improve false positive rates. Amino acid changes in HGVS style (VCF output) Optimized parsing for VCF files with large number of samples (genotypes). Option to suppress summary calculation ('-noStats'), can speed up processing considerably in cases where VCF files have hundreds or thousands of genotype fields. Option '-onlyCoding' is set to 'auto' to reduce number of false positives (see next). Option '-onlyCoding' can be assigne a value: If value is 'true', report only 'protein_coding' transcripts as protein coding changes. If 'false', report all transcript as if they were conding. Default: Auto, i.e. if transcripts any marked as 'protein_coding' the set it to 'true', if no transcripts are marked as 'protein_coding' then set it to 'false'. Added BED output format. This is usefull to annotate the output of a Chip-Seq experiment (e.g. after performing peak calling with MACS, you want to know where the peaks hit). Added BED Annotation output format. This is usefull to get all annotation intervals that intersect a set of variants (or genomic regions). SnpSift filter : Added generic index ('*') for variables, genotypes and effects. E.g.: ( 'GEN[*].GT = '1|1' ) Added support for 'EFF' and subfields (from SnpEff processed files). E.g.: ( EFF[*].EFFECT = 'NON_SYNONYMOUS_CODING' ) SnpSift intidx : Designed to extract a small number of intervals from huge VCF files. Added indexing using memory mapped I/O files for retrieving intervals from huge VCF files. Works really fast! Version: 2.0.3 (2011-10-08) Functional classes added in VCF output (i.e. NONE, SILENT, MISSENSE, NONSENSE) Added MODIFIER effect 'impact'. Rice genome added. Added all ENSEMBL version 64 genomes. Several minor issues solved. Report usage statistics to server (can be disabled using '-noLog' options). Version: 2.0.2 (2011-09-09) VCF output format GATK integration. Now you can use SnpEff from GATK's VariantAnnotator . Default input file is STDIN. I.e. inputFile parameter can be ommited now. Gene list outputs to a TXT file (tab separated) instead of the summary (HTML) file. Command line format changed for various options Option '-sort' deprecated. Version: 1.9.6 (2011-08-08) Ensembl genomes v63 added. Warning! Genome names changed to agree with Ensembl naming convention, here are the names: Full name Short name Ailuropoda_melanoleuca ailMel1.63 Anolis_carolinensis AnoCar2.0.63 Bos_taurus Btau_4.0.63 Caenorhabditis_elegans WS220.63 Callithrix_jacchus C_jacchus3.2.1.63 Canis_familiaris BROADD2.63 Cavia_porcellus cavPor3.63 Choloepus_hoffmanni choHof1.63 Ciona_intestinalis JGI2.63 Ciona_savignyi CSAV2.0.63 Danio_rerio Zv9.63 Dasypus_novemcinctus dasNov2.63 Dipodomys_ordii dipOrd1.63 Drosophila_melanogaster BDGP5.25.63 Echinops_telfairi TENREC.63 Equus_caballus EquCab2.63 Erinaceus_europaeus HEDGEHOG.63 Felis_catus CAT.63 Gallus_gallus WASHUC2.63 Gasterosteus_aculeatus BROADS1.63 Gorilla_gorilla gorGor3.63 Homo_sapiens GRCh37.63 Loxodonta_africana loxAfr3.63 Macaca_mulatta MMUL_1.63 Macropus_eugenii Meug_1.0.63 Meleagris_gallopavo UMD2.63 Microcebus_murinus micMur1.63 Monodelphis_domestica BROADO5.63 Mus_musculus NCBIM37.63 Myotis_lucifugus Myoluc2.0.63 Nomascus_leucogenys Nleu1.0.63 Ochotona_princeps pika.63 Ornithorhynchus_anatinus OANA5.63 Oryctolagus_cuniculus oryCun2.63 Oryzias_latipes MEDAKA1.63 Otolemur_garnettii BUSHBABY1.63 Pan_troglodytes CHIMP2.1.63 Pongo_abelii PPYG2.63 Procavia_capensis proCap1.63 Pteropus_vampyrus pteVam1.63 Rattus_norvegicus RGSC3.4.63 Saccharomyces_cerevisiae EF3.63 Sorex_araneus COMMON_SHREW1.63 Spermophilus_tridecemlineatus SQUIRREL.63 Sus_scrofa Sscrofa9.63 Taeniopygia_guttata taeGut3.2.4.63 Takifugu_rubripes FUGU4.63 Tarsius_syrichta tarSyr1.63 Tetraodon_nigroviridis TETRAODON8.63 Tupaia_belangeri TREESHREW.63 Tursiops_truncatus turTru1.63 Vicugna_pacos vicPac1.63 Xenopus_tropicalis JGI_4.2.63 Problems with VCF heterozygous: Fixed Problems parsing some InDels: Fixed Error conditions on deletion at the border between UTR and Exon: Fixed Problems reporting some CDS relative positions: Fixed Some issues related to distance calculation on Downstream genes on negative strands: Fixed Version: 1.9.5 (2011-03-10) Variants per gene table. Improvements in summary report. Improved GFF3 parsing. Several genomes added. Version: 1.9 (2011-03-10) Features recently added: Improved command line Genomes added (Arabidopsis) : alyrata107, athaliana130 Genomes added (all ENSEMBL version 61): ailmel1.61, anoCar2.0.61, btau4.0.61, bushBaby1.61, calJac3.2.1.61, canFam2.61, cat1.61, cavPor3.61, ce.WS220.61, chimp2.1.61, choHof1.61, cInt2.61, cSav2.0.61, danRer9.61, dasNov2.61, dipOrd1.61, dm5.25.61, equCab2.61, eriEur1.61, fugu4.61, gacu1.61, ggallus2.61, gorGor3.61, hg37.61, loxAfr3.61, medaka1.61, meug1.0.61, micMur1.61, mm37.61, mmul1.61, monDom5.61, myoLuc1.61, oana5.61, ochPri2.61, oryCun2.61, ppyg2.61, proCap1.61, pteVam1.61, rat3.4.61, sacCer2.61, sorAra1.61, speTri1.61, sScrofa9.61, taeGut3.2.4.61, tarSyr1.61, tenrec1.61, tetraodon8.61, tupBel1.61, turkey.UMD2.61, turTru1.61, vicPac1.61, xtrop4.1.61 Genomes added (Flybase): dm5.34 Genomes added (legacy hg18): hg36.54 Improved summary and statistics Supports BED format: if you just need to check where an interval hits (e.g. exon, intron, genes, etc.) Added support for GTF 2.2 format Improved robustness of GFF3 and GFF2 parsing Improved splice site detection: SPLICE_SITE_DONOR and SPLICE_SITE_ACCEPTOR Improved support for insertions and deletions: CODON_INSERTION, CODON_CHANGE_PLUS_CODON_INSERTION, CODON_DELETION, CODON_CHANGE_PLUS_CODON_DELETION Improved support for large deletions: EXON_DELETED and UTR_DELETED Added suport for INTRON_CONSERVED and INTERGENIC_CONSERVED intervals (available in GTF 2.2 files) Added support for ambiguous sequences in exons (e.g. sequences that have \"N\") Database dump support: java -jar snpEff.jar dump genome_version CDS testing support: java -jar snpEff.jar cds genome_version cds.fasta Older features Show DNA and amino acid sequence before and after change: option \"-a, --around\", e.g. \"-a 5\" shows 5 codons around sequence change) WARNING : Since version 1.7 snpEff assumes one-based coordinates (i.e. option \"-1\" is the default instead of \"-0\") WARNING : Since version 1.7 snpEff does not sort sequence changes. You should use option \"-sort\" if you want that. Genomes added (Pseudomonas): Pseudomonas aeruginosa (paeru.PA01 and paeru.PA14) and Pseudomonas fluorescens (pfluo.SBW25.NC_009444 and pfluo.SBW25.NC_012660) Genomes supported (all ENSEMBL version 60): ailMel1.60, amel2, anoCar1.0.60, btau4.0.59, btau4.0.60, bushBaby1.60, calJac3.2.1.60, canFam2.59, canFam2.60, cat1.60, cavPor3.60, ce6, ce.WS210.60, chimp2.1.59, chimp2.1.60, choHof1.60, cInt2.60, cSav2.0.60, danRer6, danRer8.59, danRer9.60, dasNov2.60, dipOrd1.60, dm3, dm5.12, dm5.22, dm5.25.59, dm5.25.60, dm5.30, dm5.31, equCab2.60, eriEur1.60, fugu4.60, gacu1.60, ggallus2.59, ggallus2.60, gorGor3.60, hg37, hg37.59, hg37.60, loxAfr3.60, medaka1.60, meug1.0.60, micMur1.60, mm37, mm37.59, mm37.60, mmul1.60, monDom5.60, myoLuc1.60, oana5.60, ochPri2.60, oryCun2.60, ppyg2.60, proCap1.60, pteVam1.60, rat3.4.59, rat3.4.60, sacCer2, sacCer2.59, sacCer2.60, SIVmac239, sorAra1.60, speTri1.60, sScrofa9.60, taeGut3.2.4.60, tarSyr1.60, tenrec1.60, testCase, tetraodon8.60, tupBel1.60, turTru1.60, vicPac1.60, xtrop4.1.60 VCF4 input format is now supported Support new genome Apis Mellifera Statistics and plots Filter intervals (only analyze selected intervals) One-based and zero-based positions for input and output (as well arbitrary offsets) Support for heterozygous SNPs (e.g. A/W) Predicts insertions and deletions (FRAME_SHIFT) Supports GFF format when building databases. Added: Multiple nucleotide polymorphisms (MNPs) New format shows SNP quality and coverage. Can filter SNPs, InDels and MNPs based on quality, coverage and zygosity (Hom/Het).","title":"2. Features"},{"location":"help/","text":"Help, New databases and Bugs This project is maintained by Pablo Cingolani Asking for help Please send any questions by creating issues in repositories: * SnpEff: https://github.com/pcingola/SnpEff/issues * SnpSift: https://github.com/pcingola/SnpSift/issues Warning Important: In order to assess and your problem precisely, I must be able to reproduce your example. Any request for help should include at least the following items: Item Explanation Example What? A clear explanation of what you are trying to achieve \"I want to annotate variants... and then filter them to obtain...\" How? A minimal demonstration of how you are trying to do it \"we run the following command...\". Make sure you send the exact command lines you are using. Which? Which organism and genome version you are using \"we are analyzing human samples using GRCh37.72 reference genome\" Version Which SnpEFf version and sub-version you are using? Make sure to try the latest version since the issue might be already solved. \"we are using SnpEFf 3.3H\"). Hint: Running java -jar snpEff.jar shows version information. Command line The full command line that shows the issue. java -Xmx8g -jar snpEff.jar GRCh37.75 sample.vcf ... Data Sample data enough to reproduce the conditions Always attach the data files such as VCF lines (even if you added some snippets in the email's body) \"find attached a sample of the VCF file...\" Results What you expect to obtain \"we wanted to get information on variants that affect splcie regions...\" Note: A few guidelines when asking for help... Use the latest version. SnpEff is updated often, may be the issue has already been corrected (e.g you are using version 5.0A, but I've already fixed it in version 5.0B). Read the documentation first. Please make sure you've read the documentation before asking fo help. I know this is obvious, but a lot of people ask for questions in that are answered or shown as examples in the documentation. If the documentation did not help. I'm aware that the documentation is not always \"easy reading\". So let me know which part of the manual is confusing, outdated or plain wrong. I'll do my best to update and improve the docs. Be polite. This one should be obvious, but there is a reason it's in the list... I'm too busy. I always try to help people, but oftentimes I'm busy and I won't be able to answer your emails & requests in due time and manner. Apologies in advanced. If I don't get back to you... Do remind me if I don't get back to you within a few days. Sometimes I'm swamped with work or just out of town, a polite reminder helps. Ask for too much advice. I don't mind helping, I've been doing it forever. However I won't be able to help you with all the details (due to limited bamdwith), so most times, the best I can do is to provide some pointers and general advise you can follow up on. Bug reports Please send any bug reports by creating issues in repositories: SnpEff: https://github.com/pcingola/SnpEff/issues SnpSift: https://github.com/pcingola/SnpSift/issues Warning Important: In order to assess and fix the issue, I must be able to reproduce exactly your error condition. This means that I need the following information: Item Explanation Example What? A clear explanation of the bug condition. Please copy the full stack trace if one is available. \"a RuntimeException occurss when trying to annotate...\" How? A minimal bug-demonstrating test case \"when running the following command/s...\". Make sure you send the exact command lines you are using. Which? Which organism and genome version you are using (if applicable) \"we use GRCh37.72\" Version Which SnpEFf version and sub-version you are using? Make sure to try the latest version since the bug might be already fixed. \"we are using SnpEFf 3.3H\"). Hint: Running java -jar snpEff.jar shows version information. Command line The full command line that shows the issue. java -Xmx8g -jar snpEff.jar GRCh37.75 sample.vcf ... Data Sample data enough to reproduce the conditions Always attach the data files such as VCF lines (even if you added some snippets in the email's body) \"find attached a sample of the VCF file...\" Results What you expect to obtain (if applicable) \"we expected result X, but we obtained Y instead...\" Important tips: Make sure you attached a minimal dataset to reproduce the error condition. For instance, a few VCF lines showing the problem are enough (sometimes one VCF line is enough), most of the times I don't need the whole VCF file. Always send the data attached , even if it's only one VCF line. Many times the problem is a malformed line, which I can only asses if the data is attached, and If you have to send large files, as sometimes happens with genome references, try uploading them to a server (e.g. Google Drive) and sending me a link. Remember to always compress them. Try SnpEff's latest version. SnpEff is updated often, may be the bug has already been corrected (e.g you are using version 5.0A, but I've already fixed it in version 5.0B). Asking for new features I always take into account features request. So don't hesitate to send me your ideas by creating issues in repositories: * SnpEff: https://github.com/pcingola/SnpEff/issues * SnpSift: https://github.com/pcingola/SnpSift/issues Of course, it doesn't mean I'll get all suggestions implemented as soon as I get a request. But if a lot of people are asking for the same feature, it is a strong indicator that I should try to implement it. Please, don't be frustrated if I tell you I cannot implement your suggestion / idea. Keep in mind that some features are too difficult to implement for non-obvious reasons, e.g.: SnpEff uses some standard (e.g. VCF) and new features cannot break those standards. SnpEff is used by a LOT of people in MANY different pipelines. New features must be compatible with current infrastructure and cannot break operational production pipelines. Some feature requests are just too difficult to code, requiring large changes. Asking for new database / genome I'm willing to help you out if you need to build a new database (a.k.a. add a new reference genome). Building a new database (i.e. adding a new reference genome) is relatively easy and the procedure is described in detail in the documentation . If you are unable to build the database, I can try to help you out. Please, create issue in repository: https://github.com/pcingola/SnpEff . In order to do so, I need you to send me the following information: Name of the species Reference genome version A link to the reference genome sequence (i.e. a link to the FASTA file) A link to a gene and transcript definition file (either GTF, GFF, GenBank, etc.) At least one of the following (preferably, both): A link to the CDS sequences (FASTA file) A link to the protein sequences (FASTA files) Codon table information (take a look a the codon tables in snpEff.config file): Which codon table does the organism use? (e.g. codon.Standard or codon.Mycoplasma ). Specific codon tables used by some chromosomes (e.g. chromosome 'MT' uses codon.Vertebrate_Mitochondrial table) I'm well aware that I could try to google that information myself, but I need you to send the information because I want to be absolutely sure we are using exactly the reference genome version, sub-version, and data files you need. Contact information Pablo Cingolani .","title":"Help and Bugs"},{"location":"help/#help-new-databases-and-bugs","text":"This project is maintained by Pablo Cingolani","title":"Help, New databases and Bugs"},{"location":"help/#asking-for-help","text":"Please send any questions by creating issues in repositories: * SnpEff: https://github.com/pcingola/SnpEff/issues * SnpSift: https://github.com/pcingola/SnpSift/issues Warning Important: In order to assess and your problem precisely, I must be able to reproduce your example. Any request for help should include at least the following items: Item Explanation Example What? A clear explanation of what you are trying to achieve \"I want to annotate variants... and then filter them to obtain...\" How? A minimal demonstration of how you are trying to do it \"we run the following command...\". Make sure you send the exact command lines you are using. Which? Which organism and genome version you are using \"we are analyzing human samples using GRCh37.72 reference genome\" Version Which SnpEFf version and sub-version you are using? Make sure to try the latest version since the issue might be already solved. \"we are using SnpEFf 3.3H\"). Hint: Running java -jar snpEff.jar shows version information. Command line The full command line that shows the issue. java -Xmx8g -jar snpEff.jar GRCh37.75 sample.vcf ... Data Sample data enough to reproduce the conditions Always attach the data files such as VCF lines (even if you added some snippets in the email's body) \"find attached a sample of the VCF file...\" Results What you expect to obtain \"we wanted to get information on variants that affect splcie regions...\" Note: A few guidelines when asking for help... Use the latest version. SnpEff is updated often, may be the issue has already been corrected (e.g you are using version 5.0A, but I've already fixed it in version 5.0B). Read the documentation first. Please make sure you've read the documentation before asking fo help. I know this is obvious, but a lot of people ask for questions in that are answered or shown as examples in the documentation. If the documentation did not help. I'm aware that the documentation is not always \"easy reading\". So let me know which part of the manual is confusing, outdated or plain wrong. I'll do my best to update and improve the docs. Be polite. This one should be obvious, but there is a reason it's in the list... I'm too busy. I always try to help people, but oftentimes I'm busy and I won't be able to answer your emails & requests in due time and manner. Apologies in advanced. If I don't get back to you... Do remind me if I don't get back to you within a few days. Sometimes I'm swamped with work or just out of town, a polite reminder helps. Ask for too much advice. I don't mind helping, I've been doing it forever. However I won't be able to help you with all the details (due to limited bamdwith), so most times, the best I can do is to provide some pointers and general advise you can follow up on.","title":"Asking for help"},{"location":"help/#bug-reports","text":"Please send any bug reports by creating issues in repositories: SnpEff: https://github.com/pcingola/SnpEff/issues SnpSift: https://github.com/pcingola/SnpSift/issues Warning Important: In order to assess and fix the issue, I must be able to reproduce exactly your error condition. This means that I need the following information: Item Explanation Example What? A clear explanation of the bug condition. Please copy the full stack trace if one is available. \"a RuntimeException occurss when trying to annotate...\" How? A minimal bug-demonstrating test case \"when running the following command/s...\". Make sure you send the exact command lines you are using. Which? Which organism and genome version you are using (if applicable) \"we use GRCh37.72\" Version Which SnpEFf version and sub-version you are using? Make sure to try the latest version since the bug might be already fixed. \"we are using SnpEFf 3.3H\"). Hint: Running java -jar snpEff.jar shows version information. Command line The full command line that shows the issue. java -Xmx8g -jar snpEff.jar GRCh37.75 sample.vcf ... Data Sample data enough to reproduce the conditions Always attach the data files such as VCF lines (even if you added some snippets in the email's body) \"find attached a sample of the VCF file...\" Results What you expect to obtain (if applicable) \"we expected result X, but we obtained Y instead...\" Important tips: Make sure you attached a minimal dataset to reproduce the error condition. For instance, a few VCF lines showing the problem are enough (sometimes one VCF line is enough), most of the times I don't need the whole VCF file. Always send the data attached , even if it's only one VCF line. Many times the problem is a malformed line, which I can only asses if the data is attached, and If you have to send large files, as sometimes happens with genome references, try uploading them to a server (e.g. Google Drive) and sending me a link. Remember to always compress them. Try SnpEff's latest version. SnpEff is updated often, may be the bug has already been corrected (e.g you are using version 5.0A, but I've already fixed it in version 5.0B).","title":"Bug reports"},{"location":"help/#asking-for-new-features","text":"I always take into account features request. So don't hesitate to send me your ideas by creating issues in repositories: * SnpEff: https://github.com/pcingola/SnpEff/issues * SnpSift: https://github.com/pcingola/SnpSift/issues Of course, it doesn't mean I'll get all suggestions implemented as soon as I get a request. But if a lot of people are asking for the same feature, it is a strong indicator that I should try to implement it. Please, don't be frustrated if I tell you I cannot implement your suggestion / idea. Keep in mind that some features are too difficult to implement for non-obvious reasons, e.g.: SnpEff uses some standard (e.g. VCF) and new features cannot break those standards. SnpEff is used by a LOT of people in MANY different pipelines. New features must be compatible with current infrastructure and cannot break operational production pipelines. Some feature requests are just too difficult to code, requiring large changes.","title":"Asking for new features"},{"location":"help/#asking-for-new-database-genome","text":"I'm willing to help you out if you need to build a new database (a.k.a. add a new reference genome). Building a new database (i.e. adding a new reference genome) is relatively easy and the procedure is described in detail in the documentation . If you are unable to build the database, I can try to help you out. Please, create issue in repository: https://github.com/pcingola/SnpEff . In order to do so, I need you to send me the following information: Name of the species Reference genome version A link to the reference genome sequence (i.e. a link to the FASTA file) A link to a gene and transcript definition file (either GTF, GFF, GenBank, etc.) At least one of the following (preferably, both): A link to the CDS sequences (FASTA file) A link to the protein sequences (FASTA files) Codon table information (take a look a the codon tables in snpEff.config file): Which codon table does the organism use? (e.g. codon.Standard or codon.Mycoplasma ). Specific codon tables used by some chromosomes (e.g. chromosome 'MT' uses codon.Vertebrate_Mitochondrial table) I'm well aware that I could try to google that information myself, but I need you to send the information because I want to be absolutely sure we are using exactly the reference genome version, sub-version, and data files you need.","title":"Asking for new database / genome"},{"location":"help/#contact-information","text":"Pablo Cingolani .","title":"Contact information"},{"location":"integration/","text":"SnpEff is integrated with other tools commonly used in sequencing data analysis pipelines. Most notably Galaxy and Broad Institute's Genome Analysis Toolkit ( GATK projects support SnpEff. By using standards, such as VCF, SnpEff makes it easy to integrate with other programs. More details about integration here . This is a screen capture from a Galaxy server (click to enlarge):","title":"Integration"},{"location":"license/","text":"SnpEff is open source. It is released as MIT Copyright 2021, Pablo Cingolani Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"se_additionalann/","text":"Additional annotations SnpEff can also provide non-coding and regulatory annotations. Here we show how to annotate them. Regulatory annotations Warning Non-coding and regulatory annotations databases are available only for a few organisms (e.g. human, mouse, etc.). We intend to incorporate more non-coding annotations as soon as public databases are available, but your organism of choice might not have a non-coding/regulatory database available. First of all, you need to see if your organism has a regulatory database. You can just look into the database directory to see if regulation_*.bin files are there. For instance, for human genome: $ cd ~/snpEff $ cd data/GRCh37.75/ $ ls -al drwxrwxr-x 2 pcingola pcingola 4096 Aug 26 19:51 . drwxrwxr-x 3 pcingola pcingola 4096 Aug 26 19:51 .. -rw-rw-r-- 1 pcingola pcingola 5068097 Aug 26 19:51 motif.bin -rw-rw-r-- 1 pcingola pcingola 5469036 Aug 26 19:51 nextProt.bin -rw-rw-r-- 1 pcingola pcingola 38000 Aug 26 19:51 pwms.bin -rw-rw-r-- 1 pcingola pcingola 6399582 Aug 26 19:51 regulation_CD4.bin -rw-rw-r-- 1 pcingola pcingola 2516472 Aug 26 19:51 regulation_GM06990.bin -rw-rw-r-- 1 pcingola pcingola 8064939 Aug 26 19:51 regulation_GM12878.bin -rw-rw-r-- 1 pcingola pcingola 6309932 Aug 26 19:51 regulation_H1ESC.bin -rw-rw-r-- 1 pcingola pcingola 5247586 Aug 26 19:51 regulation_HeLa-S3.bin -rw-rw-r-- 1 pcingola pcingola 7506893 Aug 26 19:51 regulation_HepG2.bin -rw-rw-r-- 1 pcingola pcingola 4064952 Aug 26 19:51 regulation_HMEC.bin -rw-rw-r-- 1 pcingola pcingola 4644239 Aug 26 19:51 regulation_HSMM.bin -rw-rw-r-- 1 pcingola pcingola 5641615 Aug 26 19:51 regulation_HUVEC.bin -rw-rw-r-- 1 pcingola pcingola 5617233 Aug 26 19:51 regulation_IMR90.bin -rw-rw-r-- 1 pcingola pcingola 546871 Aug 26 19:51 regulation_K562b.bin -rw-rw-r-- 1 pcingola pcingola 8542718 Aug 26 19:51 regulation_K562.bin -rw-rw-r-- 1 pcingola pcingola 3119671 Aug 26 19:51 regulation_NH-A.bin -rw-rw-r-- 1 pcingola pcingola 5721741 Aug 26 19:51 regulation_NHEK.bin -rw-rw-r-- 1 pcingola pcingola 94345546 Aug 26 19:51 snpEffectPredictor.bin So we can annotate using any of those tracks. E.g. To use 'HeLa-S3' and 'NHEK' tracks, you can run: $ java -Xmx8g -jar snpEff.jar -v -reg HeLa-S3 -reg NHEK GRCh37.75 examples/test.1KG.vcf > test.1KG.ann_reg.vcf 00:00:00.000 Reading configuration file 'snpEff.config'. Genome: 'GRCh37.75' 00:00:00.377 done 00:00:00.377 Reading database for genome version 'GRCh37.75' from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/snpEffectPredictor.bin' (this might take a while) 00:00:25.845 done 00:00:25.878 Reading regulation track 'NHEK' 00:00:30.137 Reading regulation track 'HeLa-S3' ... # Show one example of \"regulatory_region\" (output edited for readability) $ grep -i regulatory_region test.1KG.ann_reg.vcf | head -n 1 | ./scripts/vcfInfoOnePerLine.pl 1 10291 . C T 2373.79 . ANN=T|regulatory_region_variant|MODIFIER|||REGULATION&H3K36me3:NHEK|NHEK_H3K36me3_5||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&H3K27me3:NHEK|NHEK_H3K27me3_4||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&Max:HeLa-S3|HeLa-S3_Max_26||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&Cfos:HeLa-S3|HeLa-S3_Cfos_30||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&FAIRE:HeLa-S3|HeLa-S3_FAIRE_49||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&H3K27ac:HeLa-S3|HeLa-S3_H3K27ac_88||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&PolII:NHEK|NHEK_PolII_59||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&CTCF:NHEK|NHEK_CTCF_42||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&Cmyc:HeLa-S3|HeLa-S3_Cmyc_16||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&H4K20me1:NHEK|NHEK_H4K20me1_122||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&H3K4me3:NHEK|NHEK_H3K4me3_133||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&DNase1:HeLa-S3|HeLa-S3_DNase1_108||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&DNase1:NHEK|NHEK_DNase1_63||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&FAIRE:NHEK|NHEK_FAIRE_149||||||||| ENCODE ENCODE project's goal is to find all functional elements in the human genome. You can perform annotations using ENCODE's data. ENCODE project has produced huge amounts of data (see also Nature's portal). This information is available for download and can be used to annotate genomic variants or regions. An overview of all the data available from ENCODE is shown as an experimental data matrix . The download site is here . Data is available in \"BigBed\" format, which can be feed into SnpEff using -interval command line option (you can add many -interval options). Here is a simple example: # Create a directory for ENCODE files mkdir -p db/encode # Download ENCODE experimental results (BigBed file) cd db/encode wget \"http://ftp.ebi.ac.uk/pub/databases/ensembl/encode/integration_data_jan2011/byDataType/openchrom/jan2011/fdrPeaks/wgEncodeDukeDnase8988T.fdr01peaks.hg19.bb\" # Annotate using ENCODE's data: java -Xmx8g -jar snpEff.jar -v -interval db/encode/wgEncodeDukeDnase8988T.fdr01peaks.hg19.bb GRCh37.75 examples/test.1KG.vcf > test.1KG.ann_encode.vcf # Annotations are added as \"CUSTOM\" intervals: $ grep CUSTOM test.1KG.ann_encode.vcf | head 1 564672 . A C 812.29 . ANN=|custom|MODIFIER|||CUSTOM&wgEncodeDukeDnase8988T|wgEncodeDukeDnase8988T:564666_564815||||||||| 1 564687 . C T 308.21 . ANN=T|custom|MODIFIER|||CUSTOM&wgEncodeDukeDnase8988T|wgEncodeDukeDnase8988T:564666_564815||||||||| ... 1 956676 . G A 120.88 . ANN=A|custom|MODIFIER|||CUSTOM&wgEncodeDukeDnase8988T|wgEncodeDukeDnase8988T:956646_956795||||||||| ... Epigenome Epigenome Roadmap Project has produced large amounts of information that can be used by SnpEff. Epigenome Roadmap Project goal is \"to map DNA methylation, histone modifications, chromatin accessibility and small RNA transcripts in stem cells and primary ex vivo tissues selected to represent the normal counterparts of tissues and organ systems frequently involved in human disease\". A data matrix shows the experimental set ups currently available. Unfortunately the project is not (currently) providing results files that can be used directly by annotation software, such as SnpEff. They will be available later in the project. So, for the time being, data has to be downloaded an pre-processed. We'll be processing these information and making it available (as SnpEff databases) as soon as we can. The latest Epigenome project processed information, can be found here . This includes genomic intervals for high confidence peaks in form of BED files. To annotate you can do: # Download Epigenome project database (pre-processed as BED files) wget https://snpeff.blob.core.windows.net/databases/epigenome_latest.tgz/download # Open tar file tar -xvzf epigenome_latest.tgz # Annotate using SnpEff and \"-interval\" command line java -Xmx8g -jar snpEff.jar -v -interval db/epigenome/BI_Pancreatic_Islets_H3K4me3.peaks.bed GRCh37.75 test.vcf > test.ann.vcf # See the data represented as \"CUSTOM\" EFF fields $ grep CUSTOM test.ann.vcf 1 894573 . G A . PASS AC=725;EFF=CUSTOM[BI_Pancreatic_Islets_H3K4me3](MODIFIER||||||MACS_peak_8||||1),INTRON(MODIFIER||||749|NOC2L|protein_coding|CODING|ENST00000327044|1|1),INTRON(MODIFIER|||||NOC2L|processed_transcript|CODING|ENST00000487214|1|1),INTRON(MODIFIER|||||NOC2L|retained_intron|CODING|ENST00000469563|1|1),UPSTREAM(MODIFIER||||642|KLHL17|protein_coding|CODING|ENST00000338591||1),UPSTREAM(MODIFIER|||||KLHL17|nonsense_mediated_decay|CODING|ENST00000466300||1),UPSTREAM(MODIFIER|||||KLHL17|retained_intron|CODING|ENST00000463212||1),UPSTREAM(MODIFIER|||||KLHL17|retained_intron|CODING|ENST00000481067||1),UPSTREAM(MODIFIER|||||NOC2L|retained_intron|CODING|ENST00000477976||1) 1 948692 . G A . PASS AC=896;EFF=CUSTOM[BI_Pancreatic_Islets_H3K4me3](MODIFIER||||||MACS_peak_9||||1),INTERGENIC(MODIFIER||||||||||1),UPSTREAM(MODIFIER||||165|ISG15|protein_coding|CODING|ENST00000379389||1),UPSTREAM(MODIFIER|||||RP11-54O7.11|antisense|NON_CODING|ENST00000458555||1) 1 948921 . T C . PASS AC=904;EFF=CUSTOM[BI_Pancreatic_Islets_H3K4me3](MODIFIER||||||MACS_peak_9||||1),UPSTREAM(MODIFIER|||||RP11-54O7.11|antisense|NON_CODING|ENST00000458555||1),UTR_5_PRIME(MODIFIER||||165|ISG15|protein_coding|CODING|ENST00000379389|1|1) 1 1099342 . A C . PASS AC=831;EFF=CUSTOM[BI_Pancreatic_Islets_H3K4me3](MODIFIER||||||MACS_peak_10||||1),INTERGENIC(MODIFIER||||||||||1),UPSTREAM(MODIFIER|||||MIR200A|miRNA|NON_CODING|ENST00000384875||1),UPSTREAM(MODIFIER|||||MIR200B|miRNA|NON_CODING|ENST00000384997||1) NextProt NextProt has useful proteomic annotations than can help to identify variants causing reduced protein functionality or even loss of function. Nextprot project provides proteomic information that can be used for genomic annotations. NextProt provides only human data. Starting from SnpEff version 4.0, these annotations are automatically added if the database is available for the genome version you are using (in older SnpEff versions the -nextprot command line option was used). NextProt databases are available by for in some GRCh37 genomes (e.g. file data/GRCh37.75/nextProt.bin ). Annotations example: $ java -Xmx8g -jar snpEff.jar -v GRCh37.75 examples/test.chr22.vcf > test.chr22.ann.vcf 00:00:00.000 Reading configuration file 'snpEff.config'. Genome: 'GRCh37.75' 00:00:00.374 done 00:00:00.374 Reading database for genome version 'GRCh37.75' from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/snpEffectPredictor.bin' (this might take a while) 00:00:25.880 done 00:00:25.913 Reading NextProt database from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/nextProt.bin' ... # Show some results (edited for readability) $ cat test.chr22.ann.vcf ... 22 17280941 . T C . . ANN=C|sequence_feature|LOW|XKR3|ENSG00000172967|transmembrane_region:Transmembrane_region|ENST00000331428|protein_coding|2/4|c.336-27A>G||||||,C|sequence_feature|LOW|XKR3|ENSG00000172967|transmembrane_region:Transmembrane_region|ENST00000331428|protein_coding|3/4|c.336-27A>G||||||,C|intron_variant|MODIFIER|XKR3|ENSG00000172967|transcript|ENST00000331428|protein_coding|2/3|c.336-27A>G|||||| ... 22 17472785 . G A . . ANN=A|sequence_feature|LOW|GAB4|ENSG00000215568|domain:PH|ENST00000400588|protein_coding|2/10|c.456C>T||||||,A|sequence_feature|LOW|GAB4|ENSG00000215568|domain:PH|ENST00000400588|protein_coding|1/10|c.456C>T||||||,A|non_coding_exon_variant|MODIFIER|GAB4|ENSG00000215568|transcript|ENST00000465611|nonsense_mediated_decay|2/9|n.339C>T||||||,A|non_coding_exon_variant|MODIFIER|GAB4|ENSG00000215568|transcript|ENST00000523144|processed_transcript|2/4|n.341C>T|||||| ... 22 50722408 . T C . . ANN=C|sequence_feature|MODERATE|PLXNB2|ENSG00000196576|glycosylation_site:N-linked__GlcNAc..._|ENST00000359337|protein_coding|14/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|22/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|8/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|21/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|16/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|15/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|17/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|11/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|14/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|19/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|18/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|9/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|20/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|6/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|3/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|12/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|7/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|10/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|4/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|5/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|13/37|c.2275A>G||||||,C|upstream_gene_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000479701|retained_intron||n.-1A>G|||||1417|,C|upstream_gene_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000463165|retained_intron||n.-1A>G|||||2045|,C|upstream_gene_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000492578|retained_intron||n.-1A>G|||||1973|,C|upstream_gene_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000427829|protein_coding||c.-3A>G|||||1099|WARNING_TRANSCRIPT_INCOMPLETE,C|downstream_gene_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000434732|protein_coding||c.*253A>G|||||188|WARNING_TRANSCRIPT_INCOMPLETE,C|downstream_gene_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000432455|protein_coding||c.*1620A>G|||||4008|WARNING_TRANSCRIPT_NO_STOP_CODON,C|intron_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000411680|protein_coding|2/5|c.202+5007A>G||||||WARNING_TRANSCRIPT_INCOMPLETE,C|non_coding_exon_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000496720|processed_transcript|6/8|n.510A>G|||||| The last line in the example shows a glycosylation_site marked as MODERATE impact, since a modification of such a site might impair protein function. Motif Motif annotations provided by ENSEMBL and Jaspar can be added to the standard annotations. ENSEMBL provides transcription factor binding sites prediction, for human and mouse genomes, using Jaspar motif database. As of SnpEff version 4.0, these annotations are added automatically, if the database is available for the genome version you are using (files motif.bin and pwms.bin ). Older versions requires using the -motif command line option. Example of transcription factor binding sites prediction predictions: $ java -Xmx8g -jar snpEff.jar -v GRCh37.75 examples/test.chr22.vcf > test.chr22.ann.vcf 00:00:00.000 Reading configuration file 'snpEff.config'. Genome: 'GRCh37.75' 00:00:00.393 done 00:00:00.394 Reading database for genome version 'GRCh37.75' from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/snpEffectPredictor.bin' (this might take a while) 00:00:26.214 done 00:00:26.248 Reading NextProt database from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/nextProt.bin' 00:00:27.386 NextProt database: 523361 markers loaded. 00:00:27.387 Adding transcript info to NextProt markers. 00:00:28.072 NextProt database: 706289 markers added. 00:00:28.072 Loading Motifs and PWMs 00:00:28.072 Loading PWMs from : /home/pcingola/snpEff_v4_0/./data/GRCh37.75/pwms.bin 00:00:28.103 Loading Motifs from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/motif.bin' 00:00:28.862 Motif database: 284122 markers loaded. ... # Show some examples (output edited for readability) $ cat test.chr22.ann.vcf ... 22 18301084 . G A . . ANN=A|TF_binding_site_variant|MODIFIER|||Nrsf|MA0138.2|||||||||,A|TF_binding_site_variant|MODIFIER|||Nrsf|MA0138.1|||||||||,... ... 22 23523309 . C T . . ANN=T|TF_binding_site_variant|LOW|||Gabp|MA0062.2|||||||||,... ... 22 36629223 . G C . . ANN=C|TF_binding_site_variant|LOW|||SP1|MA0079.1|||||||||,... ... So, for instance, the last annotation shown in the example is TF_binding_site_variant|LOW|||SP1|MA0079.1 corresponding to motif MA0079.1 , which you can look up in Jaspar.","title":"Additional annotations"},{"location":"se_additionalann/#additional-annotations","text":"SnpEff can also provide non-coding and regulatory annotations. Here we show how to annotate them.","title":"Additional annotations"},{"location":"se_additionalann/#regulatory-annotations","text":"Warning Non-coding and regulatory annotations databases are available only for a few organisms (e.g. human, mouse, etc.). We intend to incorporate more non-coding annotations as soon as public databases are available, but your organism of choice might not have a non-coding/regulatory database available. First of all, you need to see if your organism has a regulatory database. You can just look into the database directory to see if regulation_*.bin files are there. For instance, for human genome: $ cd ~/snpEff $ cd data/GRCh37.75/ $ ls -al drwxrwxr-x 2 pcingola pcingola 4096 Aug 26 19:51 . drwxrwxr-x 3 pcingola pcingola 4096 Aug 26 19:51 .. -rw-rw-r-- 1 pcingola pcingola 5068097 Aug 26 19:51 motif.bin -rw-rw-r-- 1 pcingola pcingola 5469036 Aug 26 19:51 nextProt.bin -rw-rw-r-- 1 pcingola pcingola 38000 Aug 26 19:51 pwms.bin -rw-rw-r-- 1 pcingola pcingola 6399582 Aug 26 19:51 regulation_CD4.bin -rw-rw-r-- 1 pcingola pcingola 2516472 Aug 26 19:51 regulation_GM06990.bin -rw-rw-r-- 1 pcingola pcingola 8064939 Aug 26 19:51 regulation_GM12878.bin -rw-rw-r-- 1 pcingola pcingola 6309932 Aug 26 19:51 regulation_H1ESC.bin -rw-rw-r-- 1 pcingola pcingola 5247586 Aug 26 19:51 regulation_HeLa-S3.bin -rw-rw-r-- 1 pcingola pcingola 7506893 Aug 26 19:51 regulation_HepG2.bin -rw-rw-r-- 1 pcingola pcingola 4064952 Aug 26 19:51 regulation_HMEC.bin -rw-rw-r-- 1 pcingola pcingola 4644239 Aug 26 19:51 regulation_HSMM.bin -rw-rw-r-- 1 pcingola pcingola 5641615 Aug 26 19:51 regulation_HUVEC.bin -rw-rw-r-- 1 pcingola pcingola 5617233 Aug 26 19:51 regulation_IMR90.bin -rw-rw-r-- 1 pcingola pcingola 546871 Aug 26 19:51 regulation_K562b.bin -rw-rw-r-- 1 pcingola pcingola 8542718 Aug 26 19:51 regulation_K562.bin -rw-rw-r-- 1 pcingola pcingola 3119671 Aug 26 19:51 regulation_NH-A.bin -rw-rw-r-- 1 pcingola pcingola 5721741 Aug 26 19:51 regulation_NHEK.bin -rw-rw-r-- 1 pcingola pcingola 94345546 Aug 26 19:51 snpEffectPredictor.bin So we can annotate using any of those tracks. E.g. To use 'HeLa-S3' and 'NHEK' tracks, you can run: $ java -Xmx8g -jar snpEff.jar -v -reg HeLa-S3 -reg NHEK GRCh37.75 examples/test.1KG.vcf > test.1KG.ann_reg.vcf 00:00:00.000 Reading configuration file 'snpEff.config'. Genome: 'GRCh37.75' 00:00:00.377 done 00:00:00.377 Reading database for genome version 'GRCh37.75' from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/snpEffectPredictor.bin' (this might take a while) 00:00:25.845 done 00:00:25.878 Reading regulation track 'NHEK' 00:00:30.137 Reading regulation track 'HeLa-S3' ... # Show one example of \"regulatory_region\" (output edited for readability) $ grep -i regulatory_region test.1KG.ann_reg.vcf | head -n 1 | ./scripts/vcfInfoOnePerLine.pl 1 10291 . C T 2373.79 . ANN=T|regulatory_region_variant|MODIFIER|||REGULATION&H3K36me3:NHEK|NHEK_H3K36me3_5||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&H3K27me3:NHEK|NHEK_H3K27me3_4||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&Max:HeLa-S3|HeLa-S3_Max_26||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&Cfos:HeLa-S3|HeLa-S3_Cfos_30||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&FAIRE:HeLa-S3|HeLa-S3_FAIRE_49||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&H3K27ac:HeLa-S3|HeLa-S3_H3K27ac_88||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&PolII:NHEK|NHEK_PolII_59||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&CTCF:NHEK|NHEK_CTCF_42||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&Cmyc:HeLa-S3|HeLa-S3_Cmyc_16||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&H4K20me1:NHEK|NHEK_H4K20me1_122||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&H3K4me3:NHEK|NHEK_H3K4me3_133||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&DNase1:HeLa-S3|HeLa-S3_DNase1_108||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&DNase1:NHEK|NHEK_DNase1_63||||||||| ,T|regulatory_region_variant|MODIFIER|||REGULATION&FAIRE:NHEK|NHEK_FAIRE_149|||||||||","title":"Regulatory annotations"},{"location":"se_additionalann/#encode","text":"ENCODE project's goal is to find all functional elements in the human genome. You can perform annotations using ENCODE's data. ENCODE project has produced huge amounts of data (see also Nature's portal). This information is available for download and can be used to annotate genomic variants or regions. An overview of all the data available from ENCODE is shown as an experimental data matrix . The download site is here . Data is available in \"BigBed\" format, which can be feed into SnpEff using -interval command line option (you can add many -interval options). Here is a simple example: # Create a directory for ENCODE files mkdir -p db/encode # Download ENCODE experimental results (BigBed file) cd db/encode wget \"http://ftp.ebi.ac.uk/pub/databases/ensembl/encode/integration_data_jan2011/byDataType/openchrom/jan2011/fdrPeaks/wgEncodeDukeDnase8988T.fdr01peaks.hg19.bb\" # Annotate using ENCODE's data: java -Xmx8g -jar snpEff.jar -v -interval db/encode/wgEncodeDukeDnase8988T.fdr01peaks.hg19.bb GRCh37.75 examples/test.1KG.vcf > test.1KG.ann_encode.vcf # Annotations are added as \"CUSTOM\" intervals: $ grep CUSTOM test.1KG.ann_encode.vcf | head 1 564672 . A C 812.29 . ANN=|custom|MODIFIER|||CUSTOM&wgEncodeDukeDnase8988T|wgEncodeDukeDnase8988T:564666_564815||||||||| 1 564687 . C T 308.21 . ANN=T|custom|MODIFIER|||CUSTOM&wgEncodeDukeDnase8988T|wgEncodeDukeDnase8988T:564666_564815||||||||| ... 1 956676 . G A 120.88 . ANN=A|custom|MODIFIER|||CUSTOM&wgEncodeDukeDnase8988T|wgEncodeDukeDnase8988T:956646_956795||||||||| ...","title":"ENCODE"},{"location":"se_additionalann/#epigenome","text":"Epigenome Roadmap Project has produced large amounts of information that can be used by SnpEff. Epigenome Roadmap Project goal is \"to map DNA methylation, histone modifications, chromatin accessibility and small RNA transcripts in stem cells and primary ex vivo tissues selected to represent the normal counterparts of tissues and organ systems frequently involved in human disease\". A data matrix shows the experimental set ups currently available. Unfortunately the project is not (currently) providing results files that can be used directly by annotation software, such as SnpEff. They will be available later in the project. So, for the time being, data has to be downloaded an pre-processed. We'll be processing these information and making it available (as SnpEff databases) as soon as we can. The latest Epigenome project processed information, can be found here . This includes genomic intervals for high confidence peaks in form of BED files. To annotate you can do: # Download Epigenome project database (pre-processed as BED files) wget https://snpeff.blob.core.windows.net/databases/epigenome_latest.tgz/download # Open tar file tar -xvzf epigenome_latest.tgz # Annotate using SnpEff and \"-interval\" command line java -Xmx8g -jar snpEff.jar -v -interval db/epigenome/BI_Pancreatic_Islets_H3K4me3.peaks.bed GRCh37.75 test.vcf > test.ann.vcf # See the data represented as \"CUSTOM\" EFF fields $ grep CUSTOM test.ann.vcf 1 894573 . G A . PASS AC=725;EFF=CUSTOM[BI_Pancreatic_Islets_H3K4me3](MODIFIER||||||MACS_peak_8||||1),INTRON(MODIFIER||||749|NOC2L|protein_coding|CODING|ENST00000327044|1|1),INTRON(MODIFIER|||||NOC2L|processed_transcript|CODING|ENST00000487214|1|1),INTRON(MODIFIER|||||NOC2L|retained_intron|CODING|ENST00000469563|1|1),UPSTREAM(MODIFIER||||642|KLHL17|protein_coding|CODING|ENST00000338591||1),UPSTREAM(MODIFIER|||||KLHL17|nonsense_mediated_decay|CODING|ENST00000466300||1),UPSTREAM(MODIFIER|||||KLHL17|retained_intron|CODING|ENST00000463212||1),UPSTREAM(MODIFIER|||||KLHL17|retained_intron|CODING|ENST00000481067||1),UPSTREAM(MODIFIER|||||NOC2L|retained_intron|CODING|ENST00000477976||1) 1 948692 . G A . PASS AC=896;EFF=CUSTOM[BI_Pancreatic_Islets_H3K4me3](MODIFIER||||||MACS_peak_9||||1),INTERGENIC(MODIFIER||||||||||1),UPSTREAM(MODIFIER||||165|ISG15|protein_coding|CODING|ENST00000379389||1),UPSTREAM(MODIFIER|||||RP11-54O7.11|antisense|NON_CODING|ENST00000458555||1) 1 948921 . T C . PASS AC=904;EFF=CUSTOM[BI_Pancreatic_Islets_H3K4me3](MODIFIER||||||MACS_peak_9||||1),UPSTREAM(MODIFIER|||||RP11-54O7.11|antisense|NON_CODING|ENST00000458555||1),UTR_5_PRIME(MODIFIER||||165|ISG15|protein_coding|CODING|ENST00000379389|1|1) 1 1099342 . A C . PASS AC=831;EFF=CUSTOM[BI_Pancreatic_Islets_H3K4me3](MODIFIER||||||MACS_peak_10||||1),INTERGENIC(MODIFIER||||||||||1),UPSTREAM(MODIFIER|||||MIR200A|miRNA|NON_CODING|ENST00000384875||1),UPSTREAM(MODIFIER|||||MIR200B|miRNA|NON_CODING|ENST00000384997||1)","title":"Epigenome"},{"location":"se_additionalann/#nextprot","text":"NextProt has useful proteomic annotations than can help to identify variants causing reduced protein functionality or even loss of function. Nextprot project provides proteomic information that can be used for genomic annotations. NextProt provides only human data. Starting from SnpEff version 4.0, these annotations are automatically added if the database is available for the genome version you are using (in older SnpEff versions the -nextprot command line option was used). NextProt databases are available by for in some GRCh37 genomes (e.g. file data/GRCh37.75/nextProt.bin ). Annotations example: $ java -Xmx8g -jar snpEff.jar -v GRCh37.75 examples/test.chr22.vcf > test.chr22.ann.vcf 00:00:00.000 Reading configuration file 'snpEff.config'. Genome: 'GRCh37.75' 00:00:00.374 done 00:00:00.374 Reading database for genome version 'GRCh37.75' from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/snpEffectPredictor.bin' (this might take a while) 00:00:25.880 done 00:00:25.913 Reading NextProt database from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/nextProt.bin' ... # Show some results (edited for readability) $ cat test.chr22.ann.vcf ... 22 17280941 . T C . . ANN=C|sequence_feature|LOW|XKR3|ENSG00000172967|transmembrane_region:Transmembrane_region|ENST00000331428|protein_coding|2/4|c.336-27A>G||||||,C|sequence_feature|LOW|XKR3|ENSG00000172967|transmembrane_region:Transmembrane_region|ENST00000331428|protein_coding|3/4|c.336-27A>G||||||,C|intron_variant|MODIFIER|XKR3|ENSG00000172967|transcript|ENST00000331428|protein_coding|2/3|c.336-27A>G|||||| ... 22 17472785 . G A . . ANN=A|sequence_feature|LOW|GAB4|ENSG00000215568|domain:PH|ENST00000400588|protein_coding|2/10|c.456C>T||||||,A|sequence_feature|LOW|GAB4|ENSG00000215568|domain:PH|ENST00000400588|protein_coding|1/10|c.456C>T||||||,A|non_coding_exon_variant|MODIFIER|GAB4|ENSG00000215568|transcript|ENST00000465611|nonsense_mediated_decay|2/9|n.339C>T||||||,A|non_coding_exon_variant|MODIFIER|GAB4|ENSG00000215568|transcript|ENST00000523144|processed_transcript|2/4|n.341C>T|||||| ... 22 50722408 . T C . . ANN=C|sequence_feature|MODERATE|PLXNB2|ENSG00000196576|glycosylation_site:N-linked__GlcNAc..._|ENST00000359337|protein_coding|14/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|22/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|8/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|21/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|16/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|15/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|17/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|11/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|14/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|19/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|18/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|9/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|20/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|6/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|3/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|12/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|7/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|10/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|4/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|5/37|c.2275A>G||||||,C|sequence_feature|LOW|PLXNB2|ENSG00000196576|topological_domain:Extracellular|ENST00000359337|protein_coding|13/37|c.2275A>G||||||,C|upstream_gene_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000479701|retained_intron||n.-1A>G|||||1417|,C|upstream_gene_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000463165|retained_intron||n.-1A>G|||||2045|,C|upstream_gene_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000492578|retained_intron||n.-1A>G|||||1973|,C|upstream_gene_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000427829|protein_coding||c.-3A>G|||||1099|WARNING_TRANSCRIPT_INCOMPLETE,C|downstream_gene_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000434732|protein_coding||c.*253A>G|||||188|WARNING_TRANSCRIPT_INCOMPLETE,C|downstream_gene_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000432455|protein_coding||c.*1620A>G|||||4008|WARNING_TRANSCRIPT_NO_STOP_CODON,C|intron_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000411680|protein_coding|2/5|c.202+5007A>G||||||WARNING_TRANSCRIPT_INCOMPLETE,C|non_coding_exon_variant|MODIFIER|PLXNB2|ENSG00000196576|transcript|ENST00000496720|processed_transcript|6/8|n.510A>G|||||| The last line in the example shows a glycosylation_site marked as MODERATE impact, since a modification of such a site might impair protein function.","title":"NextProt"},{"location":"se_additionalann/#motif","text":"Motif annotations provided by ENSEMBL and Jaspar can be added to the standard annotations. ENSEMBL provides transcription factor binding sites prediction, for human and mouse genomes, using Jaspar motif database. As of SnpEff version 4.0, these annotations are added automatically, if the database is available for the genome version you are using (files motif.bin and pwms.bin ). Older versions requires using the -motif command line option. Example of transcription factor binding sites prediction predictions: $ java -Xmx8g -jar snpEff.jar -v GRCh37.75 examples/test.chr22.vcf > test.chr22.ann.vcf 00:00:00.000 Reading configuration file 'snpEff.config'. Genome: 'GRCh37.75' 00:00:00.393 done 00:00:00.394 Reading database for genome version 'GRCh37.75' from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/snpEffectPredictor.bin' (this might take a while) 00:00:26.214 done 00:00:26.248 Reading NextProt database from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/nextProt.bin' 00:00:27.386 NextProt database: 523361 markers loaded. 00:00:27.387 Adding transcript info to NextProt markers. 00:00:28.072 NextProt database: 706289 markers added. 00:00:28.072 Loading Motifs and PWMs 00:00:28.072 Loading PWMs from : /home/pcingola/snpEff_v4_0/./data/GRCh37.75/pwms.bin 00:00:28.103 Loading Motifs from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/motif.bin' 00:00:28.862 Motif database: 284122 markers loaded. ... # Show some examples (output edited for readability) $ cat test.chr22.ann.vcf ... 22 18301084 . G A . . ANN=A|TF_binding_site_variant|MODIFIER|||Nrsf|MA0138.2|||||||||,A|TF_binding_site_variant|MODIFIER|||Nrsf|MA0138.1|||||||||,... ... 22 23523309 . C T . . ANN=T|TF_binding_site_variant|LOW|||Gabp|MA0062.2|||||||||,... ... 22 36629223 . G C . . ANN=C|TF_binding_site_variant|LOW|||SP1|MA0079.1|||||||||,... ... So, for instance, the last annotation shown in the example is TF_binding_site_variant|LOW|||SP1|MA0079.1 corresponding to motif MA0079.1 , which you can look up in Jaspar.","title":"Motif"},{"location":"se_buildingdb/","text":"Building databases SnpEff needs a database to perform genomic annotations. There are pre-built databases for thousands of genomes, so chances are that your organism of choice already has a SnpEff database available. In the (unlikely?) event that you need to build one yourself, here we describe how to it. Info You can know which genomes are supported by running the following command: $ java -jar snpEff.jar databases Warning Most people do NOT need to build a database, and can safely use a pre-built one. So unless you are working with an rare genome you most likely don't need to do it either. Managing SnpEff databases manually SnpEff databases for the most popular genomes are already pre-built and available for you to download. So, chances are that you don't need to build a database yourself (this will save you a LOT of work). Warning By default SnpEff automatically downloads and installs the database for you, so you don't need to do it manually. The following instructions are for people that want to pre-install databases manually (again, most people don't need to do this). The easiest way to download and install a pre-built SnpEff database manually, is using the download command. E.g. if you want to install the SnpEff database for the human genome, you can run the following command: $ java -jar snpEff.jar download -v GRCh37.75 Info If you are running SnpEff from a directory different than the one it was installed, you will have to specify where the config file is. This is done using the -c command line option: $ java -Xmx8g -jar snpEff.jar download -c path/to/snpEff/snpEff.config -v GRCh37.75 Building a database In order to build a database for a new genome, you need to: Warning Most people do NOT need to build a database, and can safely use a pre-built one. So unless you are working with a rare genome you most likely don't need to do it either. Configure a new genome in SnpEff's config file snpEff.config . Add genome entry to snpEff's configuration If the genome uses a non-standard codon table: Add codon table parameter Get the reference genome sequence (e.g. in FASTA format). Get genome annotations. There are four different ways you can do this: Option 1: Building a database from GTF files (the easiest way) Option 2: Building a database from GFF files Option 3: Building a database from RefSeq table from UCSC Option 4: Building a database from GenBank files Run a command to create the database (i.e. java -jar snpEff.jar build ... ) Checking the database: SnpEff will attempt to check the database by comparing predicted protein sequences and CDS sequences with ones provided by the user. Checking CDS sequences Checking Protein sequences Note: All files can be compressed using gzip. E.g. the reference file 'hg19.fa' can be compressed to 'hg19.fa.gz', snpEff will automatically decompress the file. Warning Some files claimed to be compressed using GZIP are actually not or even use a block compression variant not supported by Java's gzip library. If you notice that your build process finishes abruptly for no apparent reason, try uncompressing the files. This sometimes happens with ENSEMBL files. Configuring a new genome In order to tell SnpEff that there is a new genome available, you must update SnpEff's configuration file snpEff.config . You must add a new genome entry to snpEff.config . If your genome, or a chromosome, uses non-standard codon tables you must update snpEff.config accordingly. A typical case is when you use mitochondrial DNA. Then you specify that chromosome 'MT' uses codon.Invertebrate_Mitochondrial codon table. Another common case is when you are adding a bacterial genome, then you specify that the codon table is Bacterial_and_Plant_Plastid . Add a genome to the configuration file This example shows how to add a new genome to the config files. For this example we'll use the mouse genome (mm37.61): Edit the config file to create the new genome: vi snpEff.config Add the following lines (you are editing snpEff.config): # Mouse genome, version mm37.61 mm37.61.genome : Mouse Warning You may need to add codon table information for the genome or some parts of it (e.g. mitochondrial \"chromosome\"). See next section for details. Optional: Add genome to Galaxy's menu: cd /path/to/galaxy cd tools/snpEffect/ vi snpEffect.xml Add the following lines to the file: <param name=\"genomeVersion\" type=\"select\" label=\"Genome\"> <option value=\"hg37\">Human (hg37)<option> <option value=\"mm37.61\">Mouse (mm37.61)<option> <param> Configuring codon tables (not always required) Codon tables are provided in the snpEff.config configuration file under the section codon.Name_of_your_codon_table . The format is a comma separated list of CODON/AMINO_ACID . E.g.: codon.Invertebrate_Mitochondrial: TTT/F, TTC/F, TAC/Y, TAA/*, ATG/M+, ATG/M+, ACT/T, ... Note that codons marked with '*' are STOP codons and codons marked with a '+' are START codons. In order for you to use them, you have to specify that a given \"chromosome\" uses one of the tables (otherwise the default codon table is used). E.g. Here we say the chromosome 'M' from fly genome (dm3) uses Invertebrate_Mitochondrial codon table: dm3.M.codonTable : Invertebrate_Mitochondrial ...of course, chromosome 'M' is not a real chromosome, it is just a way to mark the sequence as mitochondrial DNA in the reference genome. Reference genome: GTF, GFF, RefSeq or GenBank As we previously mentioned, reference genome information can be in different formats: GTF, GFF, RefSeq or GenBank. In the following sub-sections, we show how to build a database for each type of genomic information file. Warning You should always check the databases you build! See sections Checking CDS sequences and Checking Protein sequences Option 1: Building a database from GTF files GTF 2.2 files are supported by SnpEff (e.g. ENSEMBL releases genome annotations in this format). Get the genome and uncompress it: # Create directory for this new genome cd /path/to/snpEff/data/ mkdir mm37.61 cd mm37.61 # Get annotation files wget ftp://ftp.ensembl.org/pub/current/gtf/mus_musculus/Mus_musculus.NCBIM37.61.gtf.gz mv Mus_musculus.NCBIM37.61.gtf.gz genes.gtf.gz # Get the genome cd /path/to/snpEff/data/genomes wget ftp://ftp.ensembl.org/pub/current/fasta/mus_musculus/dna/Mus_musculus.NCBIM37.61.dna.toplevel.fa.gz mv Mus_musculus.NCBIM37.61.dna.toplevel.fa.gz mm37.61.fa.gz Note: The FASTA file can be either in /path/to/snpEff/data/genomes/mm37.61.fa or in /path/to/snpEff/data/mm37.61/sequences.fa Add the new genome to the config file (see Add a new genome to the configuration file for details) Create database: cd /path/to/snpEff java -jar snpEff.jar build -gtf22 -v mm37.61 Option 2: Building a database from GFF files Warning Using GFF is discouraged, we recommend you use GTF files instead (whenever possible). This example shows how to create a database for a new genome using GFF file ((e.g. FlyBase, WormBase, BeeBase release GFF files). For this example we'll use the Drosophila melanogaster genome (dm5.31): Get a GFF file (into path/to/snpEff/data/dm5.31/genes.gff): mkdir path/to/snpEff/data/dm5.31 cd path/to/snpEff/data/dm5.31 wget ftp://ftp.flybase.net/genomes/Drosophila_melanogaster/dmel_r5.31_FB2010_08/gff/dmel-all-r5.31.gff.gz mv dmel-all-r5.31.gff.gz genes.gff.gz Note: GFF3 files can include the reference sequence in the same file. This is done by dumping the fasta file after a '##FASTA' line. You can also add the sequence fasta file to the 'data/genomes/' directory, like it is done in when using GTF format. Add the new genome to the config file (see Add a new genome to the configuration file for details) Create database (note the \"-gff3\" flag): cd /path/to/snpEff java -jar snpEff.jar build -gff3 -v dm5.31 Option 3: Building a database from RefSeq table from UCSC This example shows how to create a database for a new genome. For this example we'll use the Human genome (hg19). Warning Using UCSC genome tables is highly discouraged, we recommend you use ENSEMBL versions instead. Warning UCSC tables sometimes change for different species. This means that even if these instructions work for human genome, it might not work for other genomes. Obviously creating a new parser for each genome is impractical, so working with UCSC genomes is highly discouraged. We recommend to use ENSEMBL genomes instead. Warning UCSC genomes provide only major release version, but NOT sub-versions. E.g. UCSC's \"hg19\" has major version 19 but there is no \"sub-version\", whereas ENSEMBL's GRCh37.70 clearly has major version 37 and minor version 70. Not providing a minor version means that they might change the database and two \"hg19\" genomes are actually be different. This creates all sorts of consistency problems (e.g. the annotations may not be the same that you see in the UCSC genome browser, even though both of them are 'hg19' version). Using UCSC genome tables is highly discouraged, we recommend you use ENSEMBL versions instead. In order to build a genome using UCSC tables, you can follow these instructions: Go to UCSC genome browser Click on \"Table\" menu Select parameters as shown here: Click on \"get output\" and save the data to file \"/path/to/snpEff/data/hg19/genes.refseq\". Add the fasta reference genome. The FASTA file can be either in: /path/to/snpEff/data/genomes/hg19.fa or in: /path/to/snpEff/data/hg19/sequences.fa Add the new genome to the config file (see Add a new genome to the configuration file for details) Create database (note the -refSeq flag): cd /path/to/snpEff java -jar snpEff.jar build -refSeq -v hg19 Option 4: Building a database from GenBank files This example shows how to create a database for a new genome. For this example we'll use \"Staphylococcus aureus\": Go to NIH page for CP000730 Download the features in geneBank format, by clicking as shown in the following images (red arrows): Make sure you click the \"Update\" button! Then you go to the \"Send\" menu: and then: Save the GenBank data to \"/path/to/snpEff/data/CP000730/genes.gbk\". Note: If there are more than one genbank file for an organism (e.g. multiple chromosomes), then you can download each file and concatenate them. E.g.: Vibrio Cholerae has two chromosomes with GenBank accessions: NC_002505.1 and NC_002506.1. You can download both files and save them as snpEff/data/vibrio/NC_002505.1.gbk and snpEff/data/vibrio/NC_002506.1.gbk respectively, and then concatenate both files: cat NC_002505.1.gbk NC_002506.1.gbk > genes.gbk Add the following entries in the config file: # Vibrio Cholerae vibrio.genome : Vibrio Cholerae vibrio.chromosomes : NC_002505.1, NC_002506.1 vibrio.NC_002505.1.codonTable : Bacterial_and_Plant_Plastid vibrio.NC_002506.1.codonTable : Bacterial_and_Plant_Plastid Create database (note the -genbank flag): cd /path/to/snpEff java -jar snpEff.jar build -genbank -v CP000730 Example: Building the Human Genome database This is a full example on how to build the human genome database (using GTF file from ENSEBML), it includes support for regulatory features, sanity check, rare amino acids, etc.. # Go to SnpEff's install dir cd ~/snpeff # Create database dir mkdir data/GRCh37.70 cd data/GRCh37.70 # Download annotated genes wget ftp://ftp.ensembl.org/pub/release-70/gtf/homo_sapiens/Homo_sapiens.GRCh37.70.gtf.gz mv Homo_sapiens.GRCh37.70.gtf.gz genes.gtf.gz # Download proteins # This is used for: # - \"Rare Amino Acid\" annotations # - Sanity check (checking protein predicted from DNA sequences match 'real' proteins) wget ftp://ftp.ensembl.org/pub/release-70/fasta/homo_sapiens/pep/Homo_sapiens.GRCh37.70.pep.all.fa.gz mv Homo_sapiens.GRCh37.70.pep.all.fa.gz protein.fa.gz # Download CDSs # Note: This is used as \"sanity check\" (checking that CDSs predicted from gene sequences match 'real' CDSs) wget ftp://ftp.ensembl.org/pub/release-70/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh37.70.cdna.all.fa.gz mv Homo_sapiens.GRCh37.70.cdna.all.fa.gz cds.fa.gz # Download regulatory annotations wget ftp://ftp.ensembl.org/pub/release-70/regulation/homo_sapiens/AnnotatedFeatures.gff.gz mv AnnotatedFeatures.gff.gz regulation.gff.gz # Uncompress gunzip *.gz # Download genome cd ../genomes/ wget ftp://ftp.ensembl.org/pub/release-70/fasta/homo_sapiens/dna/Homo_sapiens.GRCh37.70.dna.toplevel.fa.gz mv Homo_sapiens.GRCh37.70.dna.toplevel.fa.gz GRCh37.70.fa.gz # Uncompress: # Why do we need to uncompress? # Because ENSEMBL compresses files using a block compress gzip which is not compatible with Java's library Gunzip gunzip GRCh37.70.fa.gz # Edit snpEff.config file # # WARNING! You must do this yourself. Just copying and pasting this into a terminal won't work. # # Add lines: # GRCh37.70.genome : Homo_sapiens # GRCh37.70.reference : ftp://ftp.ensembl.org/pub/release-70/gtf/ # Now we are ready to build the database cd ~/snpeff java -Xmx20g -jar snpEff.jar build -v GRCh37.70 2>&1 | tee GRCh37.70.build Checking CDS sequences When building a database, SnpEff will try to check CDS sequences for all transcripts in the database when building via GFT/GFF/RefSeq: A CDS sequences FASTA file is available. building via GenBank file: CDS sequences are available within the GenBank file Info You can disable this check unsing command line option -noCheckCds FASTA cds file format: The file name should be cds.fa (or cds.fa.gz if compressed) Each transcript should have one CDS sequence Each FASTA header has the transcript ID either: The header contains only the transcript ID The header contains Transcript ID and maybe other IDs separated by either spaces, commas, colon, dots, equal sign, or some combination of these Some example sequences with valid header examples: >ENST00000448914 ACTGGGGGATACG >chromosome:GRCh38:14:22449113:22449125:1 transcript:ENST00000448914.1 cds gene:ENSG00000228985.1 gene_biotype:TR_D_gene transcript_biotype:TR_D_gene gene_symbol:TRDD3 description:T cell receptor delta diversity 3 ACTGGGGGATACG CSD checking output. When run using the -v (verbose) command line option, for each transcript in the FASTA file, SnpEff will output one character + : OK, the CDS sequence matches the one predicted by SnpEff . : Missing transcript. SnpEff could not find the transcript ID from the FASTA file. This might indicate a problem parsing the FASTA file header to find the * : Error. The CDS sequence from inferred from SnpEff's database and the one provided in the CDS file do not match. After these line a \"Summary statistics\" line shows the total number of FASTA entries checked, as well as the number of errors (and a percentage), e.g.: CDS check: GRCh38.86 OK: 94384 Warnings: 22766 Not found: 103618 Errors: 0 Error percentage: 0.0% Warning As a \"rule of the thumb\", you should not get more than 2% or 3% of errors. Info Debugging: You can run SnpEff using -d (debug) command line option to get detailed messages for each CDS sequence comparison. The message shows the transcript ID, CDS sequence inferred by SnpEff's, and the CDS sequence from the FASTA file, as well as the places where they differ. Checking Protein sequences This is very similar to the CDS checking in the previous sub-section. When building a database, SnpEff will also try to check Protein sequences for all transcripts when building via GFT/GFF/RefSeq: A protein sequences FASTA file is available. building via GenBank file: protein sequences are available within the GenBank file Info You can disable this check unsing command line option -noCheckProtein FASTA protein file: The file name should be protein.fa (or protein.fa.gz if compressed) Each transcript should have one protein sequence Each FASTA header has the transcript ID either: The header contains only the transcript ID The header contains Transcript ID and maybe other IDs separated by either spaces, commas, colon, dots, equal sign, or some combination of these Some example sequences with valid header examples (sequences have been cut for readability): >ENST00000382044 MPGEQMDPTGSQLDSDFSQQDTPCLIIEDSQPESQVLEDDSGSHFSMLSRHLPNLQTHKE NPVLDVVSNPEQTAGEERGDGNSGFNEHLKENKVADPVDSSNLDTCGSISQVIEQLPQPN RTSSVLGMSVESAPAVEEEKGEELEQKEKEKEEDTSGNTTHSLGAEDTASSQLGFGVLEL ... >ENSP00000371475 pep chromosome:GRCh38:15:43403061:43493171:-1 gene:ENSG00000067369 transcript:ENST00000382044 gene_biotype:protein_coding transcript_biotype:protein_coding gene_symbol:TP53BP1 description:tumor protein p53 binding protein MPGEQMDPTGSQLDSDFSQQDTPCLIIEDSQPESQVLEDDSGSHFSMLSRHLPNLQTHKE NPVLDVVSNPEQTAGEERGDGNSGFNEHLKENKVADPVDSSNLDTCGSISQVIEQLPQPN RTSSVLGMSVESAPAVEEEKGEELEQKEKEKEEDTSGNTTHSLGAEDTASSQLGFGVLEL ... Protein checking output: When run using the -v (verbose) command line option, for each transcript in the FASTA file, SnpEff will output one character: + : OK, the protein sequence matches the one predicted by SnpEff . : Missing transcript. SnpEff could not find the transcript ID from the FASTA file. This might indicate a problem parsing the FASTA file header to find the * : Error. The Protein sequence from inferred from SnpEff's database and the one provided in the protein file do not match. After these line a \"Summary statistics\" line shows the total number of FASTA entries checked, as well as the number of errors (and a percentage), e.g.: Protein check: GRCh38.86 OK: 94371 Not found: 0 Errors: 13 Error percentage: 0.01377352093575182% Warning As a \"rule of the thumb\", the errors should be below 2% or 3%. How exactly protein sequences are compared The rules used for protein sequence comparison are: Comparison is case-insensitive Trailing STOP codon ( '*' ) is removed Trailing incomplete codon ( '?' ) is removed Leading incomplete codons ( '?' ) are removed If these comparisons fails, further attempts are made: Replace \"unknown\" codon characters: Codons using old 'X' characters are replaced by newer '?' characters If any of the sequences only differ by the first codon, they are considered equal (the start codon is translates as 'Met' even when the codon code translates to another Amino acid) Replace rare amino acids, which often tranlate as stop codons in the middle of the sequence: E.g. replace '*' by 'U' Try replacing unknown aminco acids ( '?' ) by the ones at the same position in the protein sequence from the FASTA file If after all these attempts the protein sequence still do not match, they are considered \"not equal\". Info Debugging: You can run SnpEff using -d (debug) command line option to get detailed messages for each protein sequence comparison. The message shows the transcript ID, protein sequence inferred by SnpEff's, and the protein sequence from the FASTA file, as well as the places where they differ. Troubleshooting Database builds Warning By far the most common problem is that the FASTA file chromosome names are different than the GFF chromosome names. Make sure chromosome names are consistent in all the files you use. When I build the database using GFF 3 SnpEff reports that Exons don't have sequences GFF3 files can have sequence information either in the same file or in a separate fasta file. In order to add sequence information in the GFF file, you can do this: cat annotations.gff > genes.gff echo \"###\" >> genes.gff echo \"##FASTA\" >> genes.gff cat sequence.fa >> genes.gff When building a database, I get zero protein coding genes When building a database, snpEff tries to find which transcripts are protein coding. This is done using the 'bioType' information. The bioType information is not a standard GFF or GTF feature. So I follow ENSEMBL's convention of using the second column ('source') for bioType, as well as the gene_biotype attribute. If your file was not produced by ENSEMBL, it probably doesn't have this information. This means that snpEff doesn't know which genes are protein coding and which ones are not. Having no information, snpEff will treat all genes as protein coding (assuming you have -treatAllAsProteinCoding Auto option in the command line, which is the default). So you will get effects as if all genes were protein coding, then you can filter out the irrelevant genes. Unfortunately, this is the best I can do if there is no 'bioType' information When building a database, I get too many warnings There are plenty of GFF and GTF files that, unfortunately, do not follow the specification. SnpEff usually complains about this, but tries hard to correct the problems. So the database may be OK even after you see many warnings. You can check the database to see if the features (genes, exons, UTRs) have been correctly incorporated, by taking a look at the database: java -jar snpEff.jar dump myGenome | less","title":"Building databases"},{"location":"se_buildingdb/#building-databases","text":"SnpEff needs a database to perform genomic annotations. There are pre-built databases for thousands of genomes, so chances are that your organism of choice already has a SnpEff database available. In the (unlikely?) event that you need to build one yourself, here we describe how to it. Info You can know which genomes are supported by running the following command: $ java -jar snpEff.jar databases Warning Most people do NOT need to build a database, and can safely use a pre-built one. So unless you are working with an rare genome you most likely don't need to do it either.","title":"Building databases"},{"location":"se_buildingdb/#managing-snpeff-databases-manually","text":"SnpEff databases for the most popular genomes are already pre-built and available for you to download. So, chances are that you don't need to build a database yourself (this will save you a LOT of work). Warning By default SnpEff automatically downloads and installs the database for you, so you don't need to do it manually. The following instructions are for people that want to pre-install databases manually (again, most people don't need to do this). The easiest way to download and install a pre-built SnpEff database manually, is using the download command. E.g. if you want to install the SnpEff database for the human genome, you can run the following command: $ java -jar snpEff.jar download -v GRCh37.75 Info If you are running SnpEff from a directory different than the one it was installed, you will have to specify where the config file is. This is done using the -c command line option: $ java -Xmx8g -jar snpEff.jar download -c path/to/snpEff/snpEff.config -v GRCh37.75","title":"Managing SnpEff databases manually"},{"location":"se_buildingdb/#building-a-database","text":"In order to build a database for a new genome, you need to: Warning Most people do NOT need to build a database, and can safely use a pre-built one. So unless you are working with a rare genome you most likely don't need to do it either. Configure a new genome in SnpEff's config file snpEff.config . Add genome entry to snpEff's configuration If the genome uses a non-standard codon table: Add codon table parameter Get the reference genome sequence (e.g. in FASTA format). Get genome annotations. There are four different ways you can do this: Option 1: Building a database from GTF files (the easiest way) Option 2: Building a database from GFF files Option 3: Building a database from RefSeq table from UCSC Option 4: Building a database from GenBank files Run a command to create the database (i.e. java -jar snpEff.jar build ... ) Checking the database: SnpEff will attempt to check the database by comparing predicted protein sequences and CDS sequences with ones provided by the user. Checking CDS sequences Checking Protein sequences Note: All files can be compressed using gzip. E.g. the reference file 'hg19.fa' can be compressed to 'hg19.fa.gz', snpEff will automatically decompress the file. Warning Some files claimed to be compressed using GZIP are actually not or even use a block compression variant not supported by Java's gzip library. If you notice that your build process finishes abruptly for no apparent reason, try uncompressing the files. This sometimes happens with ENSEMBL files.","title":"Building a database"},{"location":"se_buildingdb/#configuring-a-new-genome","text":"In order to tell SnpEff that there is a new genome available, you must update SnpEff's configuration file snpEff.config . You must add a new genome entry to snpEff.config . If your genome, or a chromosome, uses non-standard codon tables you must update snpEff.config accordingly. A typical case is when you use mitochondrial DNA. Then you specify that chromosome 'MT' uses codon.Invertebrate_Mitochondrial codon table. Another common case is when you are adding a bacterial genome, then you specify that the codon table is Bacterial_and_Plant_Plastid .","title":"Configuring a new genome"},{"location":"se_buildingdb/#add-a-genome-to-the-configuration-file","text":"This example shows how to add a new genome to the config files. For this example we'll use the mouse genome (mm37.61): Edit the config file to create the new genome: vi snpEff.config Add the following lines (you are editing snpEff.config): # Mouse genome, version mm37.61 mm37.61.genome : Mouse Warning You may need to add codon table information for the genome or some parts of it (e.g. mitochondrial \"chromosome\"). See next section for details. Optional: Add genome to Galaxy's menu: cd /path/to/galaxy cd tools/snpEffect/ vi snpEffect.xml Add the following lines to the file: <param name=\"genomeVersion\" type=\"select\" label=\"Genome\"> <option value=\"hg37\">Human (hg37)<option> <option value=\"mm37.61\">Mouse (mm37.61)<option> <param>","title":"Add a genome to the configuration file"},{"location":"se_buildingdb/#configuring-codon-tables-not-always-required","text":"Codon tables are provided in the snpEff.config configuration file under the section codon.Name_of_your_codon_table . The format is a comma separated list of CODON/AMINO_ACID . E.g.: codon.Invertebrate_Mitochondrial: TTT/F, TTC/F, TAC/Y, TAA/*, ATG/M+, ATG/M+, ACT/T, ... Note that codons marked with '*' are STOP codons and codons marked with a '+' are START codons. In order for you to use them, you have to specify that a given \"chromosome\" uses one of the tables (otherwise the default codon table is used). E.g. Here we say the chromosome 'M' from fly genome (dm3) uses Invertebrate_Mitochondrial codon table: dm3.M.codonTable : Invertebrate_Mitochondrial ...of course, chromosome 'M' is not a real chromosome, it is just a way to mark the sequence as mitochondrial DNA in the reference genome.","title":"Configuring codon tables (not always required)"},{"location":"se_buildingdb/#reference-genome-gtf-gff-refseq-or-genbank","text":"As we previously mentioned, reference genome information can be in different formats: GTF, GFF, RefSeq or GenBank. In the following sub-sections, we show how to build a database for each type of genomic information file. Warning You should always check the databases you build! See sections Checking CDS sequences and Checking Protein sequences","title":"Reference genome: GTF, GFF, RefSeq or GenBank"},{"location":"se_buildingdb/#option-1-building-a-database-from-gtf-files","text":"GTF 2.2 files are supported by SnpEff (e.g. ENSEMBL releases genome annotations in this format). Get the genome and uncompress it: # Create directory for this new genome cd /path/to/snpEff/data/ mkdir mm37.61 cd mm37.61 # Get annotation files wget ftp://ftp.ensembl.org/pub/current/gtf/mus_musculus/Mus_musculus.NCBIM37.61.gtf.gz mv Mus_musculus.NCBIM37.61.gtf.gz genes.gtf.gz # Get the genome cd /path/to/snpEff/data/genomes wget ftp://ftp.ensembl.org/pub/current/fasta/mus_musculus/dna/Mus_musculus.NCBIM37.61.dna.toplevel.fa.gz mv Mus_musculus.NCBIM37.61.dna.toplevel.fa.gz mm37.61.fa.gz Note: The FASTA file can be either in /path/to/snpEff/data/genomes/mm37.61.fa or in /path/to/snpEff/data/mm37.61/sequences.fa Add the new genome to the config file (see Add a new genome to the configuration file for details) Create database: cd /path/to/snpEff java -jar snpEff.jar build -gtf22 -v mm37.61","title":"Option 1: Building a database from GTF files"},{"location":"se_buildingdb/#option-2-building-a-database-from-gff-files","text":"Warning Using GFF is discouraged, we recommend you use GTF files instead (whenever possible). This example shows how to create a database for a new genome using GFF file ((e.g. FlyBase, WormBase, BeeBase release GFF files). For this example we'll use the Drosophila melanogaster genome (dm5.31): Get a GFF file (into path/to/snpEff/data/dm5.31/genes.gff): mkdir path/to/snpEff/data/dm5.31 cd path/to/snpEff/data/dm5.31 wget ftp://ftp.flybase.net/genomes/Drosophila_melanogaster/dmel_r5.31_FB2010_08/gff/dmel-all-r5.31.gff.gz mv dmel-all-r5.31.gff.gz genes.gff.gz Note: GFF3 files can include the reference sequence in the same file. This is done by dumping the fasta file after a '##FASTA' line. You can also add the sequence fasta file to the 'data/genomes/' directory, like it is done in when using GTF format. Add the new genome to the config file (see Add a new genome to the configuration file for details) Create database (note the \"-gff3\" flag): cd /path/to/snpEff java -jar snpEff.jar build -gff3 -v dm5.31","title":"Option 2: Building a database from GFF files"},{"location":"se_buildingdb/#option-3-building-a-database-from-refseq-table-from-ucsc","text":"This example shows how to create a database for a new genome. For this example we'll use the Human genome (hg19). Warning Using UCSC genome tables is highly discouraged, we recommend you use ENSEMBL versions instead. Warning UCSC tables sometimes change for different species. This means that even if these instructions work for human genome, it might not work for other genomes. Obviously creating a new parser for each genome is impractical, so working with UCSC genomes is highly discouraged. We recommend to use ENSEMBL genomes instead. Warning UCSC genomes provide only major release version, but NOT sub-versions. E.g. UCSC's \"hg19\" has major version 19 but there is no \"sub-version\", whereas ENSEMBL's GRCh37.70 clearly has major version 37 and minor version 70. Not providing a minor version means that they might change the database and two \"hg19\" genomes are actually be different. This creates all sorts of consistency problems (e.g. the annotations may not be the same that you see in the UCSC genome browser, even though both of them are 'hg19' version). Using UCSC genome tables is highly discouraged, we recommend you use ENSEMBL versions instead. In order to build a genome using UCSC tables, you can follow these instructions: Go to UCSC genome browser Click on \"Table\" menu Select parameters as shown here: Click on \"get output\" and save the data to file \"/path/to/snpEff/data/hg19/genes.refseq\". Add the fasta reference genome. The FASTA file can be either in: /path/to/snpEff/data/genomes/hg19.fa or in: /path/to/snpEff/data/hg19/sequences.fa Add the new genome to the config file (see Add a new genome to the configuration file for details) Create database (note the -refSeq flag): cd /path/to/snpEff java -jar snpEff.jar build -refSeq -v hg19","title":"Option 3: Building a database from RefSeq table from UCSC"},{"location":"se_buildingdb/#option-4-building-a-database-from-genbank-files","text":"This example shows how to create a database for a new genome. For this example we'll use \"Staphylococcus aureus\": Go to NIH page for CP000730 Download the features in geneBank format, by clicking as shown in the following images (red arrows): Make sure you click the \"Update\" button! Then you go to the \"Send\" menu: and then: Save the GenBank data to \"/path/to/snpEff/data/CP000730/genes.gbk\". Note: If there are more than one genbank file for an organism (e.g. multiple chromosomes), then you can download each file and concatenate them. E.g.: Vibrio Cholerae has two chromosomes with GenBank accessions: NC_002505.1 and NC_002506.1. You can download both files and save them as snpEff/data/vibrio/NC_002505.1.gbk and snpEff/data/vibrio/NC_002506.1.gbk respectively, and then concatenate both files: cat NC_002505.1.gbk NC_002506.1.gbk > genes.gbk Add the following entries in the config file: # Vibrio Cholerae vibrio.genome : Vibrio Cholerae vibrio.chromosomes : NC_002505.1, NC_002506.1 vibrio.NC_002505.1.codonTable : Bacterial_and_Plant_Plastid vibrio.NC_002506.1.codonTable : Bacterial_and_Plant_Plastid Create database (note the -genbank flag): cd /path/to/snpEff java -jar snpEff.jar build -genbank -v CP000730","title":"Option 4: Building a database from GenBank files"},{"location":"se_buildingdb/#example-building-the-human-genome-database","text":"This is a full example on how to build the human genome database (using GTF file from ENSEBML), it includes support for regulatory features, sanity check, rare amino acids, etc.. # Go to SnpEff's install dir cd ~/snpeff # Create database dir mkdir data/GRCh37.70 cd data/GRCh37.70 # Download annotated genes wget ftp://ftp.ensembl.org/pub/release-70/gtf/homo_sapiens/Homo_sapiens.GRCh37.70.gtf.gz mv Homo_sapiens.GRCh37.70.gtf.gz genes.gtf.gz # Download proteins # This is used for: # - \"Rare Amino Acid\" annotations # - Sanity check (checking protein predicted from DNA sequences match 'real' proteins) wget ftp://ftp.ensembl.org/pub/release-70/fasta/homo_sapiens/pep/Homo_sapiens.GRCh37.70.pep.all.fa.gz mv Homo_sapiens.GRCh37.70.pep.all.fa.gz protein.fa.gz # Download CDSs # Note: This is used as \"sanity check\" (checking that CDSs predicted from gene sequences match 'real' CDSs) wget ftp://ftp.ensembl.org/pub/release-70/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh37.70.cdna.all.fa.gz mv Homo_sapiens.GRCh37.70.cdna.all.fa.gz cds.fa.gz # Download regulatory annotations wget ftp://ftp.ensembl.org/pub/release-70/regulation/homo_sapiens/AnnotatedFeatures.gff.gz mv AnnotatedFeatures.gff.gz regulation.gff.gz # Uncompress gunzip *.gz # Download genome cd ../genomes/ wget ftp://ftp.ensembl.org/pub/release-70/fasta/homo_sapiens/dna/Homo_sapiens.GRCh37.70.dna.toplevel.fa.gz mv Homo_sapiens.GRCh37.70.dna.toplevel.fa.gz GRCh37.70.fa.gz # Uncompress: # Why do we need to uncompress? # Because ENSEMBL compresses files using a block compress gzip which is not compatible with Java's library Gunzip gunzip GRCh37.70.fa.gz # Edit snpEff.config file # # WARNING! You must do this yourself. Just copying and pasting this into a terminal won't work. # # Add lines: # GRCh37.70.genome : Homo_sapiens # GRCh37.70.reference : ftp://ftp.ensembl.org/pub/release-70/gtf/ # Now we are ready to build the database cd ~/snpeff java -Xmx20g -jar snpEff.jar build -v GRCh37.70 2>&1 | tee GRCh37.70.build","title":"Example: Building the Human Genome database"},{"location":"se_buildingdb/#checking-cds-sequences","text":"When building a database, SnpEff will try to check CDS sequences for all transcripts in the database when building via GFT/GFF/RefSeq: A CDS sequences FASTA file is available. building via GenBank file: CDS sequences are available within the GenBank file Info You can disable this check unsing command line option -noCheckCds FASTA cds file format: The file name should be cds.fa (or cds.fa.gz if compressed) Each transcript should have one CDS sequence Each FASTA header has the transcript ID either: The header contains only the transcript ID The header contains Transcript ID and maybe other IDs separated by either spaces, commas, colon, dots, equal sign, or some combination of these Some example sequences with valid header examples: >ENST00000448914 ACTGGGGGATACG >chromosome:GRCh38:14:22449113:22449125:1 transcript:ENST00000448914.1 cds gene:ENSG00000228985.1 gene_biotype:TR_D_gene transcript_biotype:TR_D_gene gene_symbol:TRDD3 description:T cell receptor delta diversity 3 ACTGGGGGATACG CSD checking output. When run using the -v (verbose) command line option, for each transcript in the FASTA file, SnpEff will output one character + : OK, the CDS sequence matches the one predicted by SnpEff . : Missing transcript. SnpEff could not find the transcript ID from the FASTA file. This might indicate a problem parsing the FASTA file header to find the * : Error. The CDS sequence from inferred from SnpEff's database and the one provided in the CDS file do not match. After these line a \"Summary statistics\" line shows the total number of FASTA entries checked, as well as the number of errors (and a percentage), e.g.: CDS check: GRCh38.86 OK: 94384 Warnings: 22766 Not found: 103618 Errors: 0 Error percentage: 0.0% Warning As a \"rule of the thumb\", you should not get more than 2% or 3% of errors. Info Debugging: You can run SnpEff using -d (debug) command line option to get detailed messages for each CDS sequence comparison. The message shows the transcript ID, CDS sequence inferred by SnpEff's, and the CDS sequence from the FASTA file, as well as the places where they differ.","title":"Checking CDS sequences"},{"location":"se_buildingdb/#checking-protein-sequences","text":"This is very similar to the CDS checking in the previous sub-section. When building a database, SnpEff will also try to check Protein sequences for all transcripts when building via GFT/GFF/RefSeq: A protein sequences FASTA file is available. building via GenBank file: protein sequences are available within the GenBank file Info You can disable this check unsing command line option -noCheckProtein FASTA protein file: The file name should be protein.fa (or protein.fa.gz if compressed) Each transcript should have one protein sequence Each FASTA header has the transcript ID either: The header contains only the transcript ID The header contains Transcript ID and maybe other IDs separated by either spaces, commas, colon, dots, equal sign, or some combination of these Some example sequences with valid header examples (sequences have been cut for readability): >ENST00000382044 MPGEQMDPTGSQLDSDFSQQDTPCLIIEDSQPESQVLEDDSGSHFSMLSRHLPNLQTHKE NPVLDVVSNPEQTAGEERGDGNSGFNEHLKENKVADPVDSSNLDTCGSISQVIEQLPQPN RTSSVLGMSVESAPAVEEEKGEELEQKEKEKEEDTSGNTTHSLGAEDTASSQLGFGVLEL ... >ENSP00000371475 pep chromosome:GRCh38:15:43403061:43493171:-1 gene:ENSG00000067369 transcript:ENST00000382044 gene_biotype:protein_coding transcript_biotype:protein_coding gene_symbol:TP53BP1 description:tumor protein p53 binding protein MPGEQMDPTGSQLDSDFSQQDTPCLIIEDSQPESQVLEDDSGSHFSMLSRHLPNLQTHKE NPVLDVVSNPEQTAGEERGDGNSGFNEHLKENKVADPVDSSNLDTCGSISQVIEQLPQPN RTSSVLGMSVESAPAVEEEKGEELEQKEKEKEEDTSGNTTHSLGAEDTASSQLGFGVLEL ... Protein checking output: When run using the -v (verbose) command line option, for each transcript in the FASTA file, SnpEff will output one character: + : OK, the protein sequence matches the one predicted by SnpEff . : Missing transcript. SnpEff could not find the transcript ID from the FASTA file. This might indicate a problem parsing the FASTA file header to find the * : Error. The Protein sequence from inferred from SnpEff's database and the one provided in the protein file do not match. After these line a \"Summary statistics\" line shows the total number of FASTA entries checked, as well as the number of errors (and a percentage), e.g.: Protein check: GRCh38.86 OK: 94371 Not found: 0 Errors: 13 Error percentage: 0.01377352093575182% Warning As a \"rule of the thumb\", the errors should be below 2% or 3%. How exactly protein sequences are compared The rules used for protein sequence comparison are: Comparison is case-insensitive Trailing STOP codon ( '*' ) is removed Trailing incomplete codon ( '?' ) is removed Leading incomplete codons ( '?' ) are removed If these comparisons fails, further attempts are made: Replace \"unknown\" codon characters: Codons using old 'X' characters are replaced by newer '?' characters If any of the sequences only differ by the first codon, they are considered equal (the start codon is translates as 'Met' even when the codon code translates to another Amino acid) Replace rare amino acids, which often tranlate as stop codons in the middle of the sequence: E.g. replace '*' by 'U' Try replacing unknown aminco acids ( '?' ) by the ones at the same position in the protein sequence from the FASTA file If after all these attempts the protein sequence still do not match, they are considered \"not equal\". Info Debugging: You can run SnpEff using -d (debug) command line option to get detailed messages for each protein sequence comparison. The message shows the transcript ID, protein sequence inferred by SnpEff's, and the protein sequence from the FASTA file, as well as the places where they differ.","title":"Checking Protein sequences"},{"location":"se_buildingdb/#troubleshooting-database-builds","text":"Warning By far the most common problem is that the FASTA file chromosome names are different than the GFF chromosome names. Make sure chromosome names are consistent in all the files you use. When I build the database using GFF 3 SnpEff reports that Exons don't have sequences GFF3 files can have sequence information either in the same file or in a separate fasta file. In order to add sequence information in the GFF file, you can do this: cat annotations.gff > genes.gff echo \"###\" >> genes.gff echo \"##FASTA\" >> genes.gff cat sequence.fa >> genes.gff When building a database, I get zero protein coding genes When building a database, snpEff tries to find which transcripts are protein coding. This is done using the 'bioType' information. The bioType information is not a standard GFF or GTF feature. So I follow ENSEMBL's convention of using the second column ('source') for bioType, as well as the gene_biotype attribute. If your file was not produced by ENSEMBL, it probably doesn't have this information. This means that snpEff doesn't know which genes are protein coding and which ones are not. Having no information, snpEff will treat all genes as protein coding (assuming you have -treatAllAsProteinCoding Auto option in the command line, which is the default). So you will get effects as if all genes were protein coding, then you can filter out the irrelevant genes. Unfortunately, this is the best I can do if there is no 'bioType' information When building a database, I get too many warnings There are plenty of GFF and GTF files that, unfortunately, do not follow the specification. SnpEff usually complains about this, but tries hard to correct the problems. So the database may be OK even after you see many warnings. You can check the database to see if the features (genes, exons, UTRs) have been correctly incorporated, by taking a look at the database: java -jar snpEff.jar dump myGenome | less","title":"Troubleshooting Database builds"},{"location":"se_buildingreg/","text":"Building databases: Regulatory and Non-coding SnpEff supports regulatory and non-coding annotations. In this section we show how to build those databases. As in the previous section, most likely you will never have to do it yourself and can just use available pre-built databases. There are two ways to add support for regulatory annotations (these are not mutually exclusive, you can use both at the same time): GFF regulation file (from ENSEMBL). BED files. Warning Adding regulation support and analyzing data using regulation tracks can take much more memory. For instance, for the human genome I use 10Gb to 20Gb of RAM. Warning It is assumed the the genome is already installed, only regulatory tracks are added. Option 1: Using a GFF file This example shows how to create a regulation database for human (GRCh37.65): Get the GFF regulatory annotations (into path/to/snpEff/data/GRCh37.65/regulation.gff): cd path/to/snpEff/data/GRCh37.65 wget ftp:/ftp.ensembl.org/pub/release-65/regulation/homo_sapiens/AnnotatedFeatures.gff.gz mv AnnotatedFeatures.gff.gz regulation.gff.gz Create databases. Note that we use -onlyReg flag, because we are only creating regulatory databases. If you omit it, it will create both of \"normal' and regulatory databases: cd /path/to/snpEff java -Xmx20G -jar snpEff.jar build -v -onlyReg GRCh37.65 The output looks like this: Reading regulation elements (GFF) Chromosome '11' line: 226964 Chromosome '12' line: 493780 ... Chromosome '9' line: 4832434 Chromosome 'X' line: 5054301 Chromosome 'Y' line: 5166958 Done Total lines : 5176289 Total annotation count : 3961432 Percent : 76.5% Total annotated length : 3648200193 Number of cell/annotations : 266 Saving database 'HeLa-S3' in file '/path/to/snpEff/data/GRCh37.65/regulation_HeLa-S3.bin' Saving database 'HepG2' in file '/path/to/snpEff/data/GRCh37.65/regulation_HepG2.bin' Saving database 'NHEK' in file '/path/to/snpEff/data/GRCh37.65/regulation_NHEK.bin' Saving database 'GM12878' in file '/path/to/snpEff/data/GRCh37.65/regulation_GM12878.bin' Saving database 'HUVEC' in file '/path/to/snpEff/data/GRCh37.65/regulation_HUVEC.bin' Saving database 'H1ESC' in file '/path/to/snpEff/data/GRCh37.65/regulation_H1ESC.bin' Saving database 'CD4' in file '/path/to/snpEff/data/GRCh37.65/regulation_CD4.bin' Saving database 'GM06990' in file '/path/to/snpEff/data/GRCh37.65/regulation_GM06990.bin' Saving database 'IMR90' in file '/path/to/snpEff/data/GRCh37.65/regulation_IMR90.bin' Saving database 'K562' in file '/path/to/snpEff/data/GRCh37.65/regulation_K562.bin' Done. As you can see, annotations for each cell type are saved in different files. This makes it easier to load annotations only for the desired cell types when analyzing data. Option 2: Using an BED file This example shows how to create a regulation database for human (GRCh37.65). We assume we have a file called my_regulation.bed which has information for H3K9me3 in Pancreatic Islets (for instance, as a result of a Chip-Seq experiment and peak enrichment analysis). Add all your BED files to path/to/snpEff/data/GRCh37.65/regulation.bed/ dir: cd path/to/snpEff/data/GRCh37.65 mkdir regulation.bed cd regulation.bed mv where/ever/your/bed/file/is/my_regulation.bed ./regulation.Pancreatic_Islets.H3K9me3.bed Note: The name of the file must be regulation.CELL_TYPE.ANNOTATION_TYPE.bed . In this case, CELL_TYPE=Pancreatic_Islets and ANNOTATION_TYPE=H3K9me3 Create databases (note the -onlyReg flag): cd /path/to/snpEff java -Xmx20G -jar snpEff.jar build -v -onlyReg GRCh37.65 The output looks like this: Building database for 'GRCh37.65' Reading regulation elements (GFF) Cannot read regulation elements form file '/path/to/snpEff/data/GRCh37.65/regulation.gff' Directory has 1 bed files and 1 cell types Creating consensus for cellType 'Pancreatic_Islets', files: [/path/to/snpEff/data/GRCh37.65/regulation.bed/regulation.Pancreatic_Islets.H3K9me3.bed] Reading file '/path/to/snpEff/data/GRCh37.65/regulation.bed/regulation.Pancreatic_Islets.H3K9me3.bed' Chromosome '10' line: 5143 Chromosome '11' line: 8521 ... Chromosome 'X' line: 52481 Chromosome 'Y' line: 53340 Done Total lines : 53551 Total annotation count : 53573 Percent : 100.0% Total annotated length : 75489402 Number of cell/annotations : 1 Creating consensus for cell type: Pancreatic_Islets Sorting: Pancreatic_Islets , size: 53573 Adding to final consensus Final consensus for cell type: Pancreatic_Islets , size: 53549 Saving database 'Pancreatic_Islets' in file '/path/to/snpEff/data/GRCh37.65/regulation_Pancreatic_Islets.bin' Done Finishing up Note: If there are many annotations, they are saved in one binary file for each cell type (i.e. several BED files for different cell types are collapsed together). This makes it easier to load annotations only for the desired cell types when analyzing data.","title":"Building databases. Regulatory and Non-coding"},{"location":"se_buildingreg/#building-databases-regulatory-and-non-coding","text":"SnpEff supports regulatory and non-coding annotations. In this section we show how to build those databases. As in the previous section, most likely you will never have to do it yourself and can just use available pre-built databases. There are two ways to add support for regulatory annotations (these are not mutually exclusive, you can use both at the same time): GFF regulation file (from ENSEMBL). BED files. Warning Adding regulation support and analyzing data using regulation tracks can take much more memory. For instance, for the human genome I use 10Gb to 20Gb of RAM. Warning It is assumed the the genome is already installed, only regulatory tracks are added.","title":"Building databases: Regulatory and Non-coding"},{"location":"se_buildingreg/#option-1-using-a-gff-file","text":"This example shows how to create a regulation database for human (GRCh37.65): Get the GFF regulatory annotations (into path/to/snpEff/data/GRCh37.65/regulation.gff): cd path/to/snpEff/data/GRCh37.65 wget ftp:/ftp.ensembl.org/pub/release-65/regulation/homo_sapiens/AnnotatedFeatures.gff.gz mv AnnotatedFeatures.gff.gz regulation.gff.gz Create databases. Note that we use -onlyReg flag, because we are only creating regulatory databases. If you omit it, it will create both of \"normal' and regulatory databases: cd /path/to/snpEff java -Xmx20G -jar snpEff.jar build -v -onlyReg GRCh37.65 The output looks like this: Reading regulation elements (GFF) Chromosome '11' line: 226964 Chromosome '12' line: 493780 ... Chromosome '9' line: 4832434 Chromosome 'X' line: 5054301 Chromosome 'Y' line: 5166958 Done Total lines : 5176289 Total annotation count : 3961432 Percent : 76.5% Total annotated length : 3648200193 Number of cell/annotations : 266 Saving database 'HeLa-S3' in file '/path/to/snpEff/data/GRCh37.65/regulation_HeLa-S3.bin' Saving database 'HepG2' in file '/path/to/snpEff/data/GRCh37.65/regulation_HepG2.bin' Saving database 'NHEK' in file '/path/to/snpEff/data/GRCh37.65/regulation_NHEK.bin' Saving database 'GM12878' in file '/path/to/snpEff/data/GRCh37.65/regulation_GM12878.bin' Saving database 'HUVEC' in file '/path/to/snpEff/data/GRCh37.65/regulation_HUVEC.bin' Saving database 'H1ESC' in file '/path/to/snpEff/data/GRCh37.65/regulation_H1ESC.bin' Saving database 'CD4' in file '/path/to/snpEff/data/GRCh37.65/regulation_CD4.bin' Saving database 'GM06990' in file '/path/to/snpEff/data/GRCh37.65/regulation_GM06990.bin' Saving database 'IMR90' in file '/path/to/snpEff/data/GRCh37.65/regulation_IMR90.bin' Saving database 'K562' in file '/path/to/snpEff/data/GRCh37.65/regulation_K562.bin' Done. As you can see, annotations for each cell type are saved in different files. This makes it easier to load annotations only for the desired cell types when analyzing data.","title":"Option 1: Using a GFF file"},{"location":"se_buildingreg/#option-2-using-an-bed-file","text":"This example shows how to create a regulation database for human (GRCh37.65). We assume we have a file called my_regulation.bed which has information for H3K9me3 in Pancreatic Islets (for instance, as a result of a Chip-Seq experiment and peak enrichment analysis). Add all your BED files to path/to/snpEff/data/GRCh37.65/regulation.bed/ dir: cd path/to/snpEff/data/GRCh37.65 mkdir regulation.bed cd regulation.bed mv where/ever/your/bed/file/is/my_regulation.bed ./regulation.Pancreatic_Islets.H3K9me3.bed Note: The name of the file must be regulation.CELL_TYPE.ANNOTATION_TYPE.bed . In this case, CELL_TYPE=Pancreatic_Islets and ANNOTATION_TYPE=H3K9me3 Create databases (note the -onlyReg flag): cd /path/to/snpEff java -Xmx20G -jar snpEff.jar build -v -onlyReg GRCh37.65 The output looks like this: Building database for 'GRCh37.65' Reading regulation elements (GFF) Cannot read regulation elements form file '/path/to/snpEff/data/GRCh37.65/regulation.gff' Directory has 1 bed files and 1 cell types Creating consensus for cellType 'Pancreatic_Islets', files: [/path/to/snpEff/data/GRCh37.65/regulation.bed/regulation.Pancreatic_Islets.H3K9me3.bed] Reading file '/path/to/snpEff/data/GRCh37.65/regulation.bed/regulation.Pancreatic_Islets.H3K9me3.bed' Chromosome '10' line: 5143 Chromosome '11' line: 8521 ... Chromosome 'X' line: 52481 Chromosome 'Y' line: 53340 Done Total lines : 53551 Total annotation count : 53573 Percent : 100.0% Total annotated length : 75489402 Number of cell/annotations : 1 Creating consensus for cell type: Pancreatic_Islets Sorting: Pancreatic_Islets , size: 53573 Adding to final consensus Final consensus for cell type: Pancreatic_Islets , size: 53549 Saving database 'Pancreatic_Islets' in file '/path/to/snpEff/data/GRCh37.65/regulation_Pancreatic_Islets.bin' Done Finishing up Note: If there are many annotations, they are saved in one binary file for each cell type (i.e. several BED files for different cell types are collapsed together). This makes it easier to load annotations only for the desired cell types when analyzing data.","title":"Option 2: Using an BED file"},{"location":"se_cansersamples/","text":"Cancer samples Here we describe details about annotating cancer samples. Single multi-sample VCF vs. multiple VCF files. It is common practice, to have all samples in a single \"multi-sample VCF file\" (having two or more separate VCF files is highly discouraged). This is also the \"gold standard\" in cancer analysis standard, so all samples (both somatic and germline) should be in one VCF file. SnpEff requires that you follow gold standard practices, thus requires a single multi-sample VCF (it is not possible to run cancer analysis using multiple VCF files). Running in cancer analysis mode Using the -cancer command line option, you can compare somatic vs germline samples. So an example command line would be: $ java -Xmx8g -jar snpEff.jar -v -cancer GRCh37.75 cancer.vcf > cancer.ann.vcf Representing cancer data In a typical cancer sequencing experiment, we want to measure and annotate differences between germline (healthy) and somatic (cancer) tissue samples from the same patient. The complication is that germline is not always the same as the reference genome, so a typical annotation does not work. For instance, let's assume that at a given genomic position (e.g. chr1:69091), reference genome is 'A', germline is 'C' and somatic is 'G'. This should be represented in a VCF file as: #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Patient_01_Germline Patient_01_Somatic 1 69091 . A C,G . PASS AC=1 GT 1/0 2/1 Warning Some people tend to represent this by changing REF base 'A' using germline 'C'. This is a mistake, REF must always represent the reference genome, not one of your samples. Under normal conditions, SnpEff would provide the effects of changes \"A -> C\" and \"A -> G\". But in case of cancer samples, we are actually interested in the difference between somatic and germline, so we'd like to calculate the effect of a \"C -> G\" mutation. Calculating this effect is not trivial, since we have to build a new \"reference\" by calculating the effect of the first mutation (\"A -> C\") and then calculate the effect of the second one (\"C -> G\") on our \"new reference\". Info In order to activate cancer analysis, you must use -cancer command line option. Defining cancer samples As we already mentioned, cancer data is represented in a VCF file using multiple ALTs (REF field always is reference genome). In order to specify which samples are somatic and which ones are germline, there are two options: Use a TXT file using -cancerSamples command line option. Use the PEDIGREE meta information in your VCF file's header. This is the default, but some people might find hard to edit / change information in VCF file's headers. Warning If you do not provide either PEDIGREE meta information or a TXT samples file, SnpEff will not know which somatic samples derive from which germline samples. Thus it will be unable to perform cancer effect analysis. TXT file This is quite easy. All you have to do is to create a tab-separated TXT file having two columns: the first column has the germline sample names and the second column has the somatic sample names. Make sure that sample names match exactly the ones in the VCF file. E.g.: Create a TXT file named 'samples_cancer.txt' Patient_01_Germline Patient_01_Somatic Patient_02_Germline Patient_02_Somatic Patient_03_Germline Patient_03_Somatic Patient_04_Germline Patient_04_Somatic Then you have to specify this TXT file when invoking SnpEff, using the -cancerSamples command line option. E.g. In our example, the file name is 'samples_cancer.txt', so the command line would look like this: $ cat examples/samples_cancer_one.txt Patient_01_Germline Patient_01_Somatic $ java -Xmx8g -jar snpEff.jar -v \\ -cancer \\ -cancerSamples examples/samples_cancer_one.txt \\ GRCh37.75 \\ examples/cancer.vcf \\ > cancer.ann.vcf VCF header This is the default method and the main advantage is that you don't have to carry information on a separate TXT file (all the information is within your VCF file). You have to add the PEDIGREE header with the appropriate information to your VCF file. Obviously this requires you to edit you VCF file's header. Warning How to edit VCF headers is beyond the scope of this manual (we recommend using vcf-annotate from VCFtools). But if you find adding PEDIGREE information to your VCF file difficult, just use the TXT file method described in the previous sub-section. E.g.: Pedigree information in a VCF file would look like this: $ cat examples/cancer_pedigree.vcf ##PEDIGREE=<Derived=Patient_01_Somatic,Original=Patient_01_Germline> #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Patient_01_Germline Patient_01_Somatic 1 69091 . A C,G . PASS AF=0.1122 GT 1/0 2/1 1 69849 . G A,C . PASS AF=0.1122 GT 1/0 2/1 1 69511 . A C,G . PASS AF=0.3580 GT 1/1 2/2 $ java -Xmx8g -jar snpEff.jar -v -cancer GRCh37.75 examples/cancer_pedigree.vcf > examples/cancer_pedigree.ann.vcf Here we say that the sample called Patient_01_Somatic is derived from the sample called Patient_01_Germline . In this context, this means that cancer sample is derived from the healthy tissue. Interpreting Cancer annotations Interpretation of ANN field cancer sample relies on 'Allele' sub-field. Just as a reminder, ANN field has the following format: ANN = Allele | Annotation | Annotation_Impact | Gene_Name | Gene_ID | Feature_Type | Feature_ID | Transcript_BioType | Rank | HGVS.c | HGVS.p | cDNA.pos / cDNA.length | CDS.pos / CDS.length | AA.pos / AA.length | Distance | ERRORS_WARNINGS_INFO The Allele field tells you which effect relates to which genotype. More importantly, genotype difference between Somatic and Germline. Example: when there are multiple ALTs (e.g. REF='A' ALT='C,G') and the genotype field says: Allele = \"C\": it means is the effect related to the first ALT ('C') Allele = \"G\" if it's the effect related to the second ALT ('G') Allele = \"G-C\" means that this is the effect of having the second ALT as variant while using the first ALT as reference (\"C -> G\"). It is important that you understand the meaning of the last one, because you'll use it often for your cancer analysis. Example: Sample output for the previously mentioned VCF example would be (the output has been edited for readability reasons) For the first line we get (edited for readability): $ java -Xmx8g -jar snpEff.jar -v -cancer -cancerSamples examples/samples_cancer_one.txt GRCh37.75 examples/cancer.vcf > examples/cancer.eff.vcf 1 69091 . A C,G . PASS AF=0.1122; ANN=G|start_lost|HIGH|OR4F5|ENSG00000186092|transcript|ENST00000335137|protein_coding|1/1|c.1A>G|p.Met1?|1/918|1/918|1/305|| ,G-C|start_lost|HIGH|OR4F5|ENSG00000186092|transcript|ENST00000335137|protein_coding|1/1|c.1A>G|p.Leu1?|1/918|1/918|1/305|| ,C|initiator_codon_variant|LOW|OR4F5|ENSG00000186092|transcript|ENST00000335137|protein_coding|1/1|c.1A>C|p.Met1?|1/918|1/918|1/305|| GT 1/0 2/1 What does it mean: In this case, we have two ALTs = 'C' and 'G'. Germline sample is heterozygous 'C/A' (GT = '1/0') Somatic tissue is heterozygous 'G/C' (GT = '2/1') Change A -> C and A -> G are always calculated by SnpEff (this is the \"default mode\"). A -> C produces this effect: C|initiator_codon_variant|LOW|OR4F5|ENSG00000186092|transcript|ENST00000335137|protein_coding|1/1|c.1A>C|p.Met1?|1/918|1/918|1/305|| Note that the last field (genotype field) is 'C' indicating this is produced by the first ALT. A -> G produces this effect: G|start_lost|HIGH|OR4F5|ENSG00000186092|transcript|ENST00000335137|protein_coding|1/1|c.1A>G|p.Met1?|1/918|1/918|1/305|| Note that the last field (genotype field) is 'G' indicating this is produced by the second ALT. Finally, this is what you were expecting for, the cancer comparisons. Since both germline and somatic are heterozygous (GT are '1/0' and '2/1'), there are 4 possible comparisons to make: G vs C : This is the Somatic vs Germline we are interested in. SnpEff reports this one G vs A : This compares ALT to REF, so it was already reported in \"default mode\". SnpEff doesn't report this one again. C vs C : This is not a variant, since both og them ar '1'. SnpEff skips this one. C vs A : This compares ALT to REF, so it was already reported in \"default mode\". SnpEff doesn't report this one again. I know is confusing, but the bottom line is that only the first comparison one makes sense, and is the one SnpEff reports. So 'C -> G' produces the following effect: G-C|start_lost|HIGH|OR4F5|ENSG00000186092|transcript|ENST00000335137|protein_coding|1/1|c.1A>G|p.Leu1?|1/918|1/918|1/305|| Warning Notice the genotype field is \"G-C\" meaning the we produce a new reference on the fly using ALT 1 ('C') and then used ALT 2 ('G') as the variant. So we compare 'G' (ALT) to 'C' (REF). Cancer annotations using 'EFF' field: Interpretation of EFF field cancer sample relies on 'Genotype' sub-field. Just as a reminder, EFF field has the following format: EFF = Effect ( Effect_Impact | Functional_Class | Codon_Change | Amino_Acid_Change| Amino_Acid_Length | Gene_Name | Transcript_BioType | Gene_Coding | Transcript_ID | Exon_Rank | Genotype_Number [ | ERRORS | WARNINGS ] ) For the previous example, we get (edited for readability): $ java -Xmx8g -jar snpEff.jar -v -classic -cancer -cancerSamples examples/samples_cancer_one.txt GRCh37.75 examples/cancer.vcf > examples/cancer.eff.vcf 1 69091 . A C,G . PASS AC=1; EFF=START_LOST(HIGH|MISSENSE|Atg/Gtg|M1V|305|OR4F5|protein_coding|CODING|ENST00000335137|1|G) ,START_LOST(HIGH|MISSENSE|Ctg/Gtg|L1V|305|OR4F5|protein_coding|CODING|ENST00000335137|1|G-C) ,NON_SYNONYMOUS_START(LOW|MISSENSE|Atg/Ctg|M1L|305|OR4F5|protein_coding|CODING|ENST00000335137|1|C) The GenotypeNum field tells you which effect relates to which genotype. More importantly, genotype difference between Somatic and Germline. Example: when there are multiple ALTs (e.g. REF='A' ALT='C,G') and the genotype field says: GenotypeNum = \"1\": it means is the effect related to the first ALT ('C') GenotypeNum = \"2\" if it's the effect related to the second ALT ('G') GenotypeNum = \"2-1\" means that this is the effect of having the second ALT as variant while using the first ALT as reference (\"C -> G\").","title":"Cancer samples"},{"location":"se_cansersamples/#cancer-samples","text":"Here we describe details about annotating cancer samples. Single multi-sample VCF vs. multiple VCF files. It is common practice, to have all samples in a single \"multi-sample VCF file\" (having two or more separate VCF files is highly discouraged). This is also the \"gold standard\" in cancer analysis standard, so all samples (both somatic and germline) should be in one VCF file. SnpEff requires that you follow gold standard practices, thus requires a single multi-sample VCF (it is not possible to run cancer analysis using multiple VCF files).","title":"Cancer samples"},{"location":"se_cansersamples/#running-in-cancer-analysis-mode","text":"Using the -cancer command line option, you can compare somatic vs germline samples. So an example command line would be: $ java -Xmx8g -jar snpEff.jar -v -cancer GRCh37.75 cancer.vcf > cancer.ann.vcf","title":"Running in cancer analysis mode"},{"location":"se_cansersamples/#representing-cancer-data","text":"In a typical cancer sequencing experiment, we want to measure and annotate differences between germline (healthy) and somatic (cancer) tissue samples from the same patient. The complication is that germline is not always the same as the reference genome, so a typical annotation does not work. For instance, let's assume that at a given genomic position (e.g. chr1:69091), reference genome is 'A', germline is 'C' and somatic is 'G'. This should be represented in a VCF file as: #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Patient_01_Germline Patient_01_Somatic 1 69091 . A C,G . PASS AC=1 GT 1/0 2/1 Warning Some people tend to represent this by changing REF base 'A' using germline 'C'. This is a mistake, REF must always represent the reference genome, not one of your samples. Under normal conditions, SnpEff would provide the effects of changes \"A -> C\" and \"A -> G\". But in case of cancer samples, we are actually interested in the difference between somatic and germline, so we'd like to calculate the effect of a \"C -> G\" mutation. Calculating this effect is not trivial, since we have to build a new \"reference\" by calculating the effect of the first mutation (\"A -> C\") and then calculate the effect of the second one (\"C -> G\") on our \"new reference\". Info In order to activate cancer analysis, you must use -cancer command line option.","title":"Representing cancer data"},{"location":"se_cansersamples/#defining-cancer-samples","text":"As we already mentioned, cancer data is represented in a VCF file using multiple ALTs (REF field always is reference genome). In order to specify which samples are somatic and which ones are germline, there are two options: Use a TXT file using -cancerSamples command line option. Use the PEDIGREE meta information in your VCF file's header. This is the default, but some people might find hard to edit / change information in VCF file's headers. Warning If you do not provide either PEDIGREE meta information or a TXT samples file, SnpEff will not know which somatic samples derive from which germline samples. Thus it will be unable to perform cancer effect analysis. TXT file This is quite easy. All you have to do is to create a tab-separated TXT file having two columns: the first column has the germline sample names and the second column has the somatic sample names. Make sure that sample names match exactly the ones in the VCF file. E.g.: Create a TXT file named 'samples_cancer.txt' Patient_01_Germline Patient_01_Somatic Patient_02_Germline Patient_02_Somatic Patient_03_Germline Patient_03_Somatic Patient_04_Germline Patient_04_Somatic Then you have to specify this TXT file when invoking SnpEff, using the -cancerSamples command line option. E.g. In our example, the file name is 'samples_cancer.txt', so the command line would look like this: $ cat examples/samples_cancer_one.txt Patient_01_Germline Patient_01_Somatic $ java -Xmx8g -jar snpEff.jar -v \\ -cancer \\ -cancerSamples examples/samples_cancer_one.txt \\ GRCh37.75 \\ examples/cancer.vcf \\ > cancer.ann.vcf VCF header This is the default method and the main advantage is that you don't have to carry information on a separate TXT file (all the information is within your VCF file). You have to add the PEDIGREE header with the appropriate information to your VCF file. Obviously this requires you to edit you VCF file's header. Warning How to edit VCF headers is beyond the scope of this manual (we recommend using vcf-annotate from VCFtools). But if you find adding PEDIGREE information to your VCF file difficult, just use the TXT file method described in the previous sub-section. E.g.: Pedigree information in a VCF file would look like this: $ cat examples/cancer_pedigree.vcf ##PEDIGREE=<Derived=Patient_01_Somatic,Original=Patient_01_Germline> #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Patient_01_Germline Patient_01_Somatic 1 69091 . A C,G . PASS AF=0.1122 GT 1/0 2/1 1 69849 . G A,C . PASS AF=0.1122 GT 1/0 2/1 1 69511 . A C,G . PASS AF=0.3580 GT 1/1 2/2 $ java -Xmx8g -jar snpEff.jar -v -cancer GRCh37.75 examples/cancer_pedigree.vcf > examples/cancer_pedigree.ann.vcf Here we say that the sample called Patient_01_Somatic is derived from the sample called Patient_01_Germline . In this context, this means that cancer sample is derived from the healthy tissue.","title":"Defining cancer samples"},{"location":"se_cansersamples/#interpreting-cancer-annotations","text":"Interpretation of ANN field cancer sample relies on 'Allele' sub-field. Just as a reminder, ANN field has the following format: ANN = Allele | Annotation | Annotation_Impact | Gene_Name | Gene_ID | Feature_Type | Feature_ID | Transcript_BioType | Rank | HGVS.c | HGVS.p | cDNA.pos / cDNA.length | CDS.pos / CDS.length | AA.pos / AA.length | Distance | ERRORS_WARNINGS_INFO The Allele field tells you which effect relates to which genotype. More importantly, genotype difference between Somatic and Germline. Example: when there are multiple ALTs (e.g. REF='A' ALT='C,G') and the genotype field says: Allele = \"C\": it means is the effect related to the first ALT ('C') Allele = \"G\" if it's the effect related to the second ALT ('G') Allele = \"G-C\" means that this is the effect of having the second ALT as variant while using the first ALT as reference (\"C -> G\"). It is important that you understand the meaning of the last one, because you'll use it often for your cancer analysis. Example: Sample output for the previously mentioned VCF example would be (the output has been edited for readability reasons) For the first line we get (edited for readability): $ java -Xmx8g -jar snpEff.jar -v -cancer -cancerSamples examples/samples_cancer_one.txt GRCh37.75 examples/cancer.vcf > examples/cancer.eff.vcf 1 69091 . A C,G . PASS AF=0.1122; ANN=G|start_lost|HIGH|OR4F5|ENSG00000186092|transcript|ENST00000335137|protein_coding|1/1|c.1A>G|p.Met1?|1/918|1/918|1/305|| ,G-C|start_lost|HIGH|OR4F5|ENSG00000186092|transcript|ENST00000335137|protein_coding|1/1|c.1A>G|p.Leu1?|1/918|1/918|1/305|| ,C|initiator_codon_variant|LOW|OR4F5|ENSG00000186092|transcript|ENST00000335137|protein_coding|1/1|c.1A>C|p.Met1?|1/918|1/918|1/305|| GT 1/0 2/1 What does it mean: In this case, we have two ALTs = 'C' and 'G'. Germline sample is heterozygous 'C/A' (GT = '1/0') Somatic tissue is heterozygous 'G/C' (GT = '2/1') Change A -> C and A -> G are always calculated by SnpEff (this is the \"default mode\"). A -> C produces this effect: C|initiator_codon_variant|LOW|OR4F5|ENSG00000186092|transcript|ENST00000335137|protein_coding|1/1|c.1A>C|p.Met1?|1/918|1/918|1/305|| Note that the last field (genotype field) is 'C' indicating this is produced by the first ALT. A -> G produces this effect: G|start_lost|HIGH|OR4F5|ENSG00000186092|transcript|ENST00000335137|protein_coding|1/1|c.1A>G|p.Met1?|1/918|1/918|1/305|| Note that the last field (genotype field) is 'G' indicating this is produced by the second ALT. Finally, this is what you were expecting for, the cancer comparisons. Since both germline and somatic are heterozygous (GT are '1/0' and '2/1'), there are 4 possible comparisons to make: G vs C : This is the Somatic vs Germline we are interested in. SnpEff reports this one G vs A : This compares ALT to REF, so it was already reported in \"default mode\". SnpEff doesn't report this one again. C vs C : This is not a variant, since both og them ar '1'. SnpEff skips this one. C vs A : This compares ALT to REF, so it was already reported in \"default mode\". SnpEff doesn't report this one again. I know is confusing, but the bottom line is that only the first comparison one makes sense, and is the one SnpEff reports. So 'C -> G' produces the following effect: G-C|start_lost|HIGH|OR4F5|ENSG00000186092|transcript|ENST00000335137|protein_coding|1/1|c.1A>G|p.Leu1?|1/918|1/918|1/305|| Warning Notice the genotype field is \"G-C\" meaning the we produce a new reference on the fly using ALT 1 ('C') and then used ALT 2 ('G') as the variant. So we compare 'G' (ALT) to 'C' (REF).","title":"Interpreting Cancer annotations"},{"location":"se_cansersamples/#cancer-annotations-using-eff-field","text":"Interpretation of EFF field cancer sample relies on 'Genotype' sub-field. Just as a reminder, EFF field has the following format: EFF = Effect ( Effect_Impact | Functional_Class | Codon_Change | Amino_Acid_Change| Amino_Acid_Length | Gene_Name | Transcript_BioType | Gene_Coding | Transcript_ID | Exon_Rank | Genotype_Number [ | ERRORS | WARNINGS ] ) For the previous example, we get (edited for readability): $ java -Xmx8g -jar snpEff.jar -v -classic -cancer -cancerSamples examples/samples_cancer_one.txt GRCh37.75 examples/cancer.vcf > examples/cancer.eff.vcf 1 69091 . A C,G . PASS AC=1; EFF=START_LOST(HIGH|MISSENSE|Atg/Gtg|M1V|305|OR4F5|protein_coding|CODING|ENST00000335137|1|G) ,START_LOST(HIGH|MISSENSE|Ctg/Gtg|L1V|305|OR4F5|protein_coding|CODING|ENST00000335137|1|G-C) ,NON_SYNONYMOUS_START(LOW|MISSENSE|Atg/Ctg|M1L|305|OR4F5|protein_coding|CODING|ENST00000335137|1|C) The GenotypeNum field tells you which effect relates to which genotype. More importantly, genotype difference between Somatic and Germline. Example: when there are multiple ALTs (e.g. REF='A' ALT='C,G') and the genotype field says: GenotypeNum = \"1\": it means is the effect related to the first ALT ('C') GenotypeNum = \"2\" if it's the effect related to the second ALT ('G') GenotypeNum = \"2-1\" means that this is the effect of having the second ALT as variant while using the first ALT as reference (\"C -> G\").","title":"Cancer annotations using 'EFF' field:"},{"location":"se_commandline/","text":"Commands & command line options SnpEff has several 'commands' that can be used for different annotations. The default command is 'eff' used to annotate variants. Help: In order to see all available commands, you can run SnpEff without any arguments: # This will show a 'help' message java -jar snpEff.jar Commands Here is a list of what each command does: Command Meaning [eff|ann] This is the default command. It is used for annotating variant filed (e.g. VCF files). build Build a SnpEff database from reference genome files (FASTA, GTF, etc.). buildNextProt Build NextProt database using XML files cds Compare CDS sequences calculated form a SnpEff database to the one in a FASTA file. Used for checking databases correctness (invoked automatically when building a database). closest Annotate the closest genomic region. count Count how many intervals (from a BAM, BED or VCF file) overlap with each genomic interval. databases Show currently available databases (from local config file). download Download a SnpEff database. dump Dump to STDOUT a SnpEff database (mostly used for debugging). genes2bed Create a bed file from a genes list. len Calculate total genomic length for each marker type. protein Compare protein sequences calculated form a SnpEff database to the one in a FASTA file. Used for checking databases correctness. (invoked automatically when building a database). spliceAnalysis Perform an analysis of splice sites. Experimental feature. Common options The general help shows some options that are available to all commands. For instance, at the time of writing, the common options are under \"Generic options\" and \"Database options\" are these: $ java -jar snpEff.jar SnpEff version SnpEff 4.1 (build 2015-01-07), by Pablo Cingolani Usage: snpEff [command] [options] [files] Run 'java -jar snpEff.jar command' for help on each specific command Available commands: [eff|ann] : Annotate variants / calculate effects (you can use either 'ann' or 'eff', they mean the same). Default: ann (no command or 'ann'). build : Build a SnpEff database. buildNextProt : Build a SnpEff for NextProt (using NextProt's XML files). cds : Compare CDS sequences calculated form a SnpEff database to the one in a FASTA file. Used for checking databases correctness. closest : Annotate the closest genomic region. count : Count how many intervals (from a BAM, BED or VCF file) overlap with each genomic interval. databases : Show currently available databases (from local config file). download : Download a SnpEff database. dump : Dump to STDOUT a SnpEff database (mostly used for debugging). genes2bed : Create a bed file from a genes list. len : Calculate total genomic length for each marker type. protein : Compare protein sequences calculated form a SnpEff database to the one in a FASTA file. Used for checking databases correctness. spliceAnalysis : Perform an analysis of splice sites. Experimental feature. Generic options: -c , -config : Specify config file -d , -debug : Debug mode (very verbose). -dataDir <path> : Override data_dir parameter from config file. -download : Download a SnpEff database, if not available locally. Default: true -nodownload : Do not download a SnpEff database, if not available locally. -noShiftHgvs : Do not shift variants towards most 3-prime position (as required by HGVS). -h , -help : Show this help and exit -noLog : Do not report usage statistics to server -t : Use multiple threads (implies '-noStats'). Default 'off' -q , -quiet : Quiet mode (do not show any messages or errors) -v , -verbose : Verbose mode Database options: -canon : Only use canonical transcripts. -interval : Use a custom intervals in TXT/BED/BigBed/VCF/GFF file (you may use this option many times) -motif : Annotate using motifs (requires Motif database). -nextProt : Annotate using NextProt (requires NextProt database). -noGenome : Do not load any genomic database (e.g. annotate using custom files). -noMotif : Disable motif annotations. -noNextProt : Disable NextProt annotations. -onlyReg : Only use regulation tracks. -onlyProtein : Only use protein coding transcripts. Default: false -onlyTr <file.txt> : Only use the transcripts in this file. Format: One transcript ID per line. -reg <name> : Regulation track to use (this option can be used add several times). -ss , -spliceSiteSize <int> : Set size for splice sites (donor and acceptor) in bases. Default: 2 -strict : Only use 'validated' transcripts (i.e. sequence has been checked). Default: false Help (command specific): In order to see a help message for a particular command, you can run the command without any arguments or use -help command line option: # This will show a 'help' message for the 'ann' (aka 'eff') command $ java -jar snpEff.jar ann snpEff version SnpEff 4.1 (build 2015-01-07), by Pablo Cingolani Usage: snpEff [eff] [options] genome_version [input_file] variants_file : Default is STDIN Options: -chr <string> : Prepend 'string' to chromosome name (e.g. 'chr1' instead of '1'). Only on TXT output. -classic : Use old style annotations instead of Sequence Ontology and Hgvs. -download : Download reference genome if not available. Default: true -i <format> : Input format [ vcf, bed ]. Default: VCF. -fileList : Input actually contains a list of files to process. -o <format> : Ouput format [ vcf, gatk, bed, bedAnn ]. Default: VCF. -s , -stats : Name of stats file (summary). Default is 'snpEff_summary.html' -noStats : Do not create stats (summary) file -csvStats : Create CSV summary file instead of HTML Results filter options: -fi , -filterInterval <file> : Only analyze changes that intersect with the intervals specified in this file (you may use this option many times) -no-downstream : Do not show DOWNSTREAM changes -no-intergenic : Do not show INTERGENIC changes -no-intron : Do not show INTRON changes -no-upstream : Do not show UPSTREAM changes -no-utr : Do not show 5_PRIME_UTR or 3_PRIME_UTR changes -no EffectType : Do not show 'EffectType'. This option can be used several times. Annotations options: -cancer : Perform 'cancer' comparisons (Somatic vs Germline). Default: false -cancerSamples <file> : Two column TXT file defining 'original \\t derived' samples. -formatEff : Use 'EFF' field compatible with older versions (instead of 'ANN'). -geneId : Use gene ID instead of gene name (VCF output). Default: false -hgvs : Use HGVS annotations for amino acid sub-field. Default: true -lof : Add loss of function (LOF) and Nonsense mediated decay (NMD) tags. -noHgvs : Do not add HGVS annotations. -noLof : Do not add LOF and NMD annotations. -noShiftHgvs : Do not shift variants according to HGVS notation (most 3prime end). -oicr : Add OICR tag in VCF file. Default: false -sequenceOntology : Use Sequence Ontology terms. Default: true Generic options: -c , -config : Specify config file -d , -debug : Debug mode (very verbose). -dataDir <path> : Override data_dir parameter from config file. -download : Download a SnpEff database, if not available locally. Default: true -nodownload : Do not download a SnpEff database, if not available locally. -noShiftHgvs : Do not shift variants towards most 3-prime position (as required by HGVS). -h , -help : Show this help and exit -noLog : Do not report usage statistics to server -t : Use multiple threads (implies '-noStats'). Default 'off' -q , -quiet : Quiet mode (do not show any messages or errors) -v , -verbose : Verbose mode Database options: -canon : Only use canonical transcripts. -interval : Use a custom intervals in TXT/BED/BigBed/VCF/GFF file (you may use this option many times) -motif : Annotate using motifs (requires Motif database). -nextProt : Annotate using NextProt (requires NextProt database). -noGenome : Do not load any genomic database (e.g. annotate using custom files). -noMotif : Disable motif annotations. -noNextProt : Disable NextProt annotations. -onlyReg : Only use regulation tracks. -onlyProtein : Only use protein coding transcripts. Default: false -onlyTr <file.txt> : Only use the transcripts in this file. Format: One transcript ID per line. -reg <name> : Regulation track to use (this option can be used add several times). -ss , -spliceSiteSize <int> : Set size for splice sites (donor and acceptor) in bases. Default: 2 -strict : Only use 'validated' transcripts (i.e. sequence has been checked). Default: false -ud , -upDownStreamLen <int> : Set upstream downstream interval length (in bases) Speed up options: Multithreaded & No statistics In order to speed up the annotation process, there are two options that can be activated: No statistics: Calculating statistics can take a significant amount of time. Particularly if there are hundreds or thousands of samples in the VCF file. The command line option -noStats disables the statistics and may result in a significant speedup. Multithreaded: SnpEff has a multithreaded implementation. This allows to use several cores available in the local machine. It can be activated using the -t command line option. Warning Some features are not available when running in multithreaded mode. For instance, statistics are disabled in order to speed up the annotation process. Warning In multithreaded mode, SnpEff will attempt to use all available cores. Nevertheless is very rare that all cores get 100% usage. HGVS /Classic notation SnpEff uses HGVS notation , which is somewhat popular amongst clinicians. You can de-activate HGVS notation (to use the old annotation style) using the command line option -classic . Logging SnpEff will try to log usage statistics to our \"log server\". This is useful for us to understand user's needs and have some statistics on what users are doing with the program (e.g. decide whether a command or option is useful or not). Logging can be deactivated by using the -noLog command line option. Filters SnpEff supports filter of output results by using combinations of the following command line options: Warning Output filters can be implemented using SnpSift filter , which allows to create more flexible and complex filters. Command line option Meaning -no-downstream Do not show DOWNSTREAM changes -no-intergenic Do not show INTERGENIC changes -no-intron Do not show INTRON changes -no-upstream Do not show UPSTREAM changes -no-utr Do not show 5_PRIME_UTR or 3_PRIME_UTR changes -no EffectType Do not show 'EffectType' (it can be used several times) e.g: -no INTERGENIC -no SPLICE_SITE_REGION Annotating selected intervals You can use the -fi intervals.bed command line option (filterInterval). For instance, let's assume you have an interval file 'intervals.bed': 2L 10000 10999 2L 12000 12999 2L 14000 14999 2L 16000 16999 2L 18000 18999 In order to get only variants matching your intervals, you can use the command: $ java -Xmx8g -jar snpEff.jar -fi intervals.bed GRCh38.76 test.chr22.vcf Canonical transcripts SnpEff allows to annotate using canonical transcripts by using -canon command line option. Warning Canonical transcripts are defined as the longest CDS of amongst the protein coding transcripts in a gene. If none of the transcripts in a gene is protein coding, then it is the longest cDNA. Warning Although this seems to be the standard definitions of \"canonical transcript\", there is no warranties that what SnpEff considers a canonical transcript will match exactly what UCSC or ENSEMBL consider a canonical transcript. Example on how to use canonical transcripts annotations: $ java -Xmx8g -jar snpEff.jar -v -canon GRCh37.75 examples/test.chr22.vcf > file.ann.canon.vcf In order to get a list of canonical transcripts, you can use the -d (debug) command line option. E.g.: $ java -Xmx8g -jar snpEff.jar -d -v -canon GRCh37.75 test.vcf 00:00:00.000 Reading configuration file 'snpEff.config' 00:00:00.173 done 00:00:00.173 Reading database for genome version 'GRCh37.66' 00:00:02.834 done 00:00:02.845 Filtering out non-canonical transcripts. 00:00:03.219 Canonical transcripts: geneName geneId transcriptId cdsLength GGPS1 ENSG00000152904 ENST00000488594 903 RP11-628K18.1.1 ENSG00000235112 ENST00000430808 296 MIPEPP2 ENSG00000224783 ENST00000422560 1819 FEN1P1 ENSG00000215873 ENST00000401028 1145 AL591704.7.1 ENSG00000224784 ENST00000421658 202 CAPNS1P1 ENSG00000215874 ENST00000401029 634 ST13P20 ENSG00000215875 ENST00000447996 1061 NCDN ENSG00000020129 ENST00000373243 2190 RP11-99H8.1.1 ENSG00000226208 ENST00000423187 432 AL391001.1 ENSG00000242652 ENST00000489859 289 ... Selected list of transcripts SnpEff allows you to provide a list of transcripts to use for annotations by using the -onlyTr file.txt and providing a file with one transcript ID per line. Any other transcript will be ignored. $ java -Xmx8g -jar snpEff.jar -onlyTr my_transcripts.txt GRCh37.75 test.chr22.vcf > test.chr22.ann.vcf Upstream and downstream You can change the default upstream and downstream interval size (default is 5K) using the -ud size_in_bases option. This also allows to eliminate any upstream and downstream effect by using \"-ud 0\". Example: Make upstream and downstream size zero (i.e. do not report any upstream or downstream effect). $ java -Xmx8g -jar snpEff.jar -ud 0 GRCh37.75 test.chr22.vcf > test.chr22.ann.vcf Splice site size You can change the default splice site size (default is 2 bases) using the -spliceSiteSize size_in_bases option. Example: Make splice sites four bases long $ java -Xmx8g -jar snpEff.jar -spliceSiteSize 4 GRCh37.75 test.chr22.vcf > test.chr22.ann.vcf Adding your own annotations SnpEff allows user defined intervals to be annotated. This is achieved using the -interval file.bed command line option, which can be used multiple times in the same command line (it accepts files in TXT, BED, BigBed, VCF, GFF formats). Any variant that intersects an interval defined in those files, will be annotated using the \"name\" field (fourth column) in the input bed file. Example: We create our own annotations in my_annotations.bed $ cat my_annotations.bed 1 10000 20000 MY_ANNOTATION $ cat test.vcf 1 10469 . C G 365.78 PASS AC=30;AF=0.0732 Annotate (output edited for readability) $ java -Xmx8g -jar snpEff.jar -interval my_annotations.bed GRCh37.66 test.vcf 1 10469 . C G 365.78 PASS AC=30;AF=0.0732; ANN=G|upstream_gene_variant|MODIFIER|DDX11L1|ENSG00000223972|transcript|ENST00000456328|processed_transcript||n.-1C>G|||||1400| ... G|custom|MODIFIER|||CUSTOM&my_annotations|MY_ANNOTATION||||||||| Notice that the variant was annotated using \"MY_ANNOTATION\" in the ANN field. Gene ID instead of gene names You can obtain gene IDs instead of gene names by using the command line option -geneId . Note: This is only for the old 'EFF' field ('ANN' field always shows both gene name and gene ID). Example: $ java -Xmx8g -jar snpEff.jar -geneId GRCh37.66 test.vcf 1 902128 3617 C T . PASS AC=80;EFF=NON_SYNONYMOUS_CODING(MODERATE|MISSENSE|gCt/gTt|A43V|576|ENSG00000187583|protein_coding|CODING|ENST00000379407|2|1),... Note: The gene 'PLEKHN1' was annotated as 'ENSG00000187583'. Compressed files SnpEff will automatically open gzip compresssed files, even if you don't specify the '.gz' extension. Example # Create compressed version of the examples files cp examples/test.chr22.vcf my.vcf # Compress it gzip my.vcf # Annotate (note the it doesn't require the ending '.gz') java -Xmx8g -jar snpEff.jar GRCh37.75 my.vcf > my.ann.vcf Streaming files Info You can use \"-\" as input file name to specify STDIN . As of version 4.0 onwards STDIN is the default, so using no name at all, also means 'STDIN'. For example, you can easily stream files like this: # These three commands are the same # Using STDIN (pipe), implicit (no input file name) cat test.chr22.vcf | java -Xmx8g -jar snpEff.jar hg19 > test.chr22.ann.vcf # Using STDIN (pipe), exlicit '-' input file name cat test.chr22.vcf | java -Xmx8g -jar snpEff.jar hg19 - > test.chr22.ann.vcf # Using explicit file name java -Xmx8g -jar snpEff.jar hg19 test.chr22.vcf > test.chr22.ann.vcf","title":"Commands &amp; command line options"},{"location":"se_commandline/#commands-command-line-options","text":"SnpEff has several 'commands' that can be used for different annotations. The default command is 'eff' used to annotate variants. Help: In order to see all available commands, you can run SnpEff without any arguments: # This will show a 'help' message java -jar snpEff.jar","title":"Commands &amp; command line options"},{"location":"se_commandline/#commands","text":"Here is a list of what each command does: Command Meaning [eff|ann] This is the default command. It is used for annotating variant filed (e.g. VCF files). build Build a SnpEff database from reference genome files (FASTA, GTF, etc.). buildNextProt Build NextProt database using XML files cds Compare CDS sequences calculated form a SnpEff database to the one in a FASTA file. Used for checking databases correctness (invoked automatically when building a database). closest Annotate the closest genomic region. count Count how many intervals (from a BAM, BED or VCF file) overlap with each genomic interval. databases Show currently available databases (from local config file). download Download a SnpEff database. dump Dump to STDOUT a SnpEff database (mostly used for debugging). genes2bed Create a bed file from a genes list. len Calculate total genomic length for each marker type. protein Compare protein sequences calculated form a SnpEff database to the one in a FASTA file. Used for checking databases correctness. (invoked automatically when building a database). spliceAnalysis Perform an analysis of splice sites. Experimental feature. Common options The general help shows some options that are available to all commands. For instance, at the time of writing, the common options are under \"Generic options\" and \"Database options\" are these: $ java -jar snpEff.jar SnpEff version SnpEff 4.1 (build 2015-01-07), by Pablo Cingolani Usage: snpEff [command] [options] [files] Run 'java -jar snpEff.jar command' for help on each specific command Available commands: [eff|ann] : Annotate variants / calculate effects (you can use either 'ann' or 'eff', they mean the same). Default: ann (no command or 'ann'). build : Build a SnpEff database. buildNextProt : Build a SnpEff for NextProt (using NextProt's XML files). cds : Compare CDS sequences calculated form a SnpEff database to the one in a FASTA file. Used for checking databases correctness. closest : Annotate the closest genomic region. count : Count how many intervals (from a BAM, BED or VCF file) overlap with each genomic interval. databases : Show currently available databases (from local config file). download : Download a SnpEff database. dump : Dump to STDOUT a SnpEff database (mostly used for debugging). genes2bed : Create a bed file from a genes list. len : Calculate total genomic length for each marker type. protein : Compare protein sequences calculated form a SnpEff database to the one in a FASTA file. Used for checking databases correctness. spliceAnalysis : Perform an analysis of splice sites. Experimental feature. Generic options: -c , -config : Specify config file -d , -debug : Debug mode (very verbose). -dataDir <path> : Override data_dir parameter from config file. -download : Download a SnpEff database, if not available locally. Default: true -nodownload : Do not download a SnpEff database, if not available locally. -noShiftHgvs : Do not shift variants towards most 3-prime position (as required by HGVS). -h , -help : Show this help and exit -noLog : Do not report usage statistics to server -t : Use multiple threads (implies '-noStats'). Default 'off' -q , -quiet : Quiet mode (do not show any messages or errors) -v , -verbose : Verbose mode Database options: -canon : Only use canonical transcripts. -interval : Use a custom intervals in TXT/BED/BigBed/VCF/GFF file (you may use this option many times) -motif : Annotate using motifs (requires Motif database). -nextProt : Annotate using NextProt (requires NextProt database). -noGenome : Do not load any genomic database (e.g. annotate using custom files). -noMotif : Disable motif annotations. -noNextProt : Disable NextProt annotations. -onlyReg : Only use regulation tracks. -onlyProtein : Only use protein coding transcripts. Default: false -onlyTr <file.txt> : Only use the transcripts in this file. Format: One transcript ID per line. -reg <name> : Regulation track to use (this option can be used add several times). -ss , -spliceSiteSize <int> : Set size for splice sites (donor and acceptor) in bases. Default: 2 -strict : Only use 'validated' transcripts (i.e. sequence has been checked). Default: false Help (command specific): In order to see a help message for a particular command, you can run the command without any arguments or use -help command line option: # This will show a 'help' message for the 'ann' (aka 'eff') command $ java -jar snpEff.jar ann snpEff version SnpEff 4.1 (build 2015-01-07), by Pablo Cingolani Usage: snpEff [eff] [options] genome_version [input_file] variants_file : Default is STDIN Options: -chr <string> : Prepend 'string' to chromosome name (e.g. 'chr1' instead of '1'). Only on TXT output. -classic : Use old style annotations instead of Sequence Ontology and Hgvs. -download : Download reference genome if not available. Default: true -i <format> : Input format [ vcf, bed ]. Default: VCF. -fileList : Input actually contains a list of files to process. -o <format> : Ouput format [ vcf, gatk, bed, bedAnn ]. Default: VCF. -s , -stats : Name of stats file (summary). Default is 'snpEff_summary.html' -noStats : Do not create stats (summary) file -csvStats : Create CSV summary file instead of HTML Results filter options: -fi , -filterInterval <file> : Only analyze changes that intersect with the intervals specified in this file (you may use this option many times) -no-downstream : Do not show DOWNSTREAM changes -no-intergenic : Do not show INTERGENIC changes -no-intron : Do not show INTRON changes -no-upstream : Do not show UPSTREAM changes -no-utr : Do not show 5_PRIME_UTR or 3_PRIME_UTR changes -no EffectType : Do not show 'EffectType'. This option can be used several times. Annotations options: -cancer : Perform 'cancer' comparisons (Somatic vs Germline). Default: false -cancerSamples <file> : Two column TXT file defining 'original \\t derived' samples. -formatEff : Use 'EFF' field compatible with older versions (instead of 'ANN'). -geneId : Use gene ID instead of gene name (VCF output). Default: false -hgvs : Use HGVS annotations for amino acid sub-field. Default: true -lof : Add loss of function (LOF) and Nonsense mediated decay (NMD) tags. -noHgvs : Do not add HGVS annotations. -noLof : Do not add LOF and NMD annotations. -noShiftHgvs : Do not shift variants according to HGVS notation (most 3prime end). -oicr : Add OICR tag in VCF file. Default: false -sequenceOntology : Use Sequence Ontology terms. Default: true Generic options: -c , -config : Specify config file -d , -debug : Debug mode (very verbose). -dataDir <path> : Override data_dir parameter from config file. -download : Download a SnpEff database, if not available locally. Default: true -nodownload : Do not download a SnpEff database, if not available locally. -noShiftHgvs : Do not shift variants towards most 3-prime position (as required by HGVS). -h , -help : Show this help and exit -noLog : Do not report usage statistics to server -t : Use multiple threads (implies '-noStats'). Default 'off' -q , -quiet : Quiet mode (do not show any messages or errors) -v , -verbose : Verbose mode Database options: -canon : Only use canonical transcripts. -interval : Use a custom intervals in TXT/BED/BigBed/VCF/GFF file (you may use this option many times) -motif : Annotate using motifs (requires Motif database). -nextProt : Annotate using NextProt (requires NextProt database). -noGenome : Do not load any genomic database (e.g. annotate using custom files). -noMotif : Disable motif annotations. -noNextProt : Disable NextProt annotations. -onlyReg : Only use regulation tracks. -onlyProtein : Only use protein coding transcripts. Default: false -onlyTr <file.txt> : Only use the transcripts in this file. Format: One transcript ID per line. -reg <name> : Regulation track to use (this option can be used add several times). -ss , -spliceSiteSize <int> : Set size for splice sites (donor and acceptor) in bases. Default: 2 -strict : Only use 'validated' transcripts (i.e. sequence has been checked). Default: false -ud , -upDownStreamLen <int> : Set upstream downstream interval length (in bases)","title":"Commands"},{"location":"se_commandline/#speed-up-options-multithreaded-no-statistics","text":"In order to speed up the annotation process, there are two options that can be activated: No statistics: Calculating statistics can take a significant amount of time. Particularly if there are hundreds or thousands of samples in the VCF file. The command line option -noStats disables the statistics and may result in a significant speedup. Multithreaded: SnpEff has a multithreaded implementation. This allows to use several cores available in the local machine. It can be activated using the -t command line option. Warning Some features are not available when running in multithreaded mode. For instance, statistics are disabled in order to speed up the annotation process. Warning In multithreaded mode, SnpEff will attempt to use all available cores. Nevertheless is very rare that all cores get 100% usage.","title":"Speed up options: Multithreaded &amp; No statistics"},{"location":"se_commandline/#hgvs-classic-notation","text":"SnpEff uses HGVS notation , which is somewhat popular amongst clinicians. You can de-activate HGVS notation (to use the old annotation style) using the command line option -classic .","title":"HGVS /Classic notation"},{"location":"se_commandline/#logging","text":"SnpEff will try to log usage statistics to our \"log server\". This is useful for us to understand user's needs and have some statistics on what users are doing with the program (e.g. decide whether a command or option is useful or not). Logging can be deactivated by using the -noLog command line option.","title":"Logging"},{"location":"se_commandline/#filters","text":"SnpEff supports filter of output results by using combinations of the following command line options: Warning Output filters can be implemented using SnpSift filter , which allows to create more flexible and complex filters. Command line option Meaning -no-downstream Do not show DOWNSTREAM changes -no-intergenic Do not show INTERGENIC changes -no-intron Do not show INTRON changes -no-upstream Do not show UPSTREAM changes -no-utr Do not show 5_PRIME_UTR or 3_PRIME_UTR changes -no EffectType Do not show 'EffectType' (it can be used several times) e.g: -no INTERGENIC -no SPLICE_SITE_REGION","title":"Filters"},{"location":"se_commandline/#annotating-selected-intervals","text":"You can use the -fi intervals.bed command line option (filterInterval). For instance, let's assume you have an interval file 'intervals.bed': 2L 10000 10999 2L 12000 12999 2L 14000 14999 2L 16000 16999 2L 18000 18999 In order to get only variants matching your intervals, you can use the command: $ java -Xmx8g -jar snpEff.jar -fi intervals.bed GRCh38.76 test.chr22.vcf","title":"Annotating selected intervals"},{"location":"se_commandline/#canonical-transcripts","text":"SnpEff allows to annotate using canonical transcripts by using -canon command line option. Warning Canonical transcripts are defined as the longest CDS of amongst the protein coding transcripts in a gene. If none of the transcripts in a gene is protein coding, then it is the longest cDNA. Warning Although this seems to be the standard definitions of \"canonical transcript\", there is no warranties that what SnpEff considers a canonical transcript will match exactly what UCSC or ENSEMBL consider a canonical transcript. Example on how to use canonical transcripts annotations: $ java -Xmx8g -jar snpEff.jar -v -canon GRCh37.75 examples/test.chr22.vcf > file.ann.canon.vcf In order to get a list of canonical transcripts, you can use the -d (debug) command line option. E.g.: $ java -Xmx8g -jar snpEff.jar -d -v -canon GRCh37.75 test.vcf 00:00:00.000 Reading configuration file 'snpEff.config' 00:00:00.173 done 00:00:00.173 Reading database for genome version 'GRCh37.66' 00:00:02.834 done 00:00:02.845 Filtering out non-canonical transcripts. 00:00:03.219 Canonical transcripts: geneName geneId transcriptId cdsLength GGPS1 ENSG00000152904 ENST00000488594 903 RP11-628K18.1.1 ENSG00000235112 ENST00000430808 296 MIPEPP2 ENSG00000224783 ENST00000422560 1819 FEN1P1 ENSG00000215873 ENST00000401028 1145 AL591704.7.1 ENSG00000224784 ENST00000421658 202 CAPNS1P1 ENSG00000215874 ENST00000401029 634 ST13P20 ENSG00000215875 ENST00000447996 1061 NCDN ENSG00000020129 ENST00000373243 2190 RP11-99H8.1.1 ENSG00000226208 ENST00000423187 432 AL391001.1 ENSG00000242652 ENST00000489859 289 ...","title":"Canonical transcripts"},{"location":"se_commandline/#selected-list-of-transcripts","text":"SnpEff allows you to provide a list of transcripts to use for annotations by using the -onlyTr file.txt and providing a file with one transcript ID per line. Any other transcript will be ignored. $ java -Xmx8g -jar snpEff.jar -onlyTr my_transcripts.txt GRCh37.75 test.chr22.vcf > test.chr22.ann.vcf","title":"Selected list of transcripts"},{"location":"se_commandline/#upstream-and-downstream","text":"You can change the default upstream and downstream interval size (default is 5K) using the -ud size_in_bases option. This also allows to eliminate any upstream and downstream effect by using \"-ud 0\". Example: Make upstream and downstream size zero (i.e. do not report any upstream or downstream effect). $ java -Xmx8g -jar snpEff.jar -ud 0 GRCh37.75 test.chr22.vcf > test.chr22.ann.vcf","title":"Upstream and downstream"},{"location":"se_commandline/#splice-site-size","text":"You can change the default splice site size (default is 2 bases) using the -spliceSiteSize size_in_bases option. Example: Make splice sites four bases long $ java -Xmx8g -jar snpEff.jar -spliceSiteSize 4 GRCh37.75 test.chr22.vcf > test.chr22.ann.vcf","title":"Splice site size"},{"location":"se_commandline/#adding-your-own-annotations","text":"SnpEff allows user defined intervals to be annotated. This is achieved using the -interval file.bed command line option, which can be used multiple times in the same command line (it accepts files in TXT, BED, BigBed, VCF, GFF formats). Any variant that intersects an interval defined in those files, will be annotated using the \"name\" field (fourth column) in the input bed file. Example: We create our own annotations in my_annotations.bed $ cat my_annotations.bed 1 10000 20000 MY_ANNOTATION $ cat test.vcf 1 10469 . C G 365.78 PASS AC=30;AF=0.0732 Annotate (output edited for readability) $ java -Xmx8g -jar snpEff.jar -interval my_annotations.bed GRCh37.66 test.vcf 1 10469 . C G 365.78 PASS AC=30;AF=0.0732; ANN=G|upstream_gene_variant|MODIFIER|DDX11L1|ENSG00000223972|transcript|ENST00000456328|processed_transcript||n.-1C>G|||||1400| ... G|custom|MODIFIER|||CUSTOM&my_annotations|MY_ANNOTATION||||||||| Notice that the variant was annotated using \"MY_ANNOTATION\" in the ANN field.","title":"Adding your own annotations"},{"location":"se_commandline/#gene-id-instead-of-gene-names","text":"You can obtain gene IDs instead of gene names by using the command line option -geneId . Note: This is only for the old 'EFF' field ('ANN' field always shows both gene name and gene ID). Example: $ java -Xmx8g -jar snpEff.jar -geneId GRCh37.66 test.vcf 1 902128 3617 C T . PASS AC=80;EFF=NON_SYNONYMOUS_CODING(MODERATE|MISSENSE|gCt/gTt|A43V|576|ENSG00000187583|protein_coding|CODING|ENST00000379407|2|1),... Note: The gene 'PLEKHN1' was annotated as 'ENSG00000187583'.","title":"Gene ID instead of gene names"},{"location":"se_commandline/#compressed-files","text":"SnpEff will automatically open gzip compresssed files, even if you don't specify the '.gz' extension. Example # Create compressed version of the examples files cp examples/test.chr22.vcf my.vcf # Compress it gzip my.vcf # Annotate (note the it doesn't require the ending '.gz') java -Xmx8g -jar snpEff.jar GRCh37.75 my.vcf > my.ann.vcf","title":"Compressed files"},{"location":"se_commandline/#streaming-files","text":"Info You can use \"-\" as input file name to specify STDIN . As of version 4.0 onwards STDIN is the default, so using no name at all, also means 'STDIN'. For example, you can easily stream files like this: # These three commands are the same # Using STDIN (pipe), implicit (no input file name) cat test.chr22.vcf | java -Xmx8g -jar snpEff.jar hg19 > test.chr22.ann.vcf # Using STDIN (pipe), exlicit '-' input file name cat test.chr22.vcf | java -Xmx8g -jar snpEff.jar hg19 - > test.chr22.ann.vcf # Using explicit file name java -Xmx8g -jar snpEff.jar hg19 test.chr22.vcf > test.chr22.ann.vcf","title":"Streaming files"},{"location":"se_commands/","text":"Commands and utilities SnpEff provides several other commands and utilities that can be useful for genomic data analysis. Most of this manual was dedicated the SnpEff eff and SnpEff build commands, which annotate effects and build databases respectively. Here we describe all the other commands and some scripts provided, that are useful for genomic data analysis. SnpEff closest Annotates using the closest genomic region (e.g. exon, transcript ID, gene name) and distance in bases. Example: $ java -Xmx8g -jar snpEff.jar closest GRCh37.66 test.vcf ##INFO=<ID=CLOSEST,Number=4,Type=String,Description=\"Closest exon: Distance (bases), exons Id, transcript Id, gene name\"> 1 12078 . G A 25.69 PASS AC=2;AF=0.048;CLOSEST=0,exon_1_11869_12227,ENST00000456328,DDX11L1 1 16097 . T G 42.42 PASS AC=9;AF=0.0113;CLOSEST=150,exon_1_15796_15947,ENST00000423562,WASH7P 1 40261 . C A 366.26 PASS AC=30;AF=0.484;CLOSEST=4180,exon_1_35721_36081,ENST00000417324,FAM138A 1 63880 . C T 82.13 PASS AC=10;AF=0.0400;CLOSEST=0,exon_1_62948_63887,ENST00000492842,OR4G11P For instance, in the third line (1:16097 T G), it added the tag CLOSEST=150,exon_1_15796_15947,ENST00000423562,WASH7P , which means that the variant is 150 bases away from exon \"exon_1_15796_15947\". The exon belongs to transcript \"ENST00000423562\" of gene \"WASH7P\". Info If multiple markers are available (at the same distance) the one belonging to the longest mRna transcript is shown. The input can also be a BED file, the output file has the same information as CLOSEST info field, added to the fourth column of the output BED file: $ snpeff closest -bed GRCh37.66 test.bed 1 12077 12078 line_1;0,exon_1_11869_12227,ENST00000456328,DDX11L1 1 16096 16097 line_2;150,exon_1_15796_15947,ENST00000423562,WASH7P 1 40260 40261 line_3;4180,exon_1_35721_36081,ENST00000417324,FAM138A 1 63879 63880 line_4;0,exon_1_62948_63887,ENST00000492842,OR4G11P SnpEff count As the name suggests, snpEff count command counts how many reads and bases from a BAM file hit a gene, transcript, exon, intron, etc. Input files can be in BAM, SAM, VCF, BED or BigBed formats. A summary HTML file with charts is generated. Here are some examples: If you need to count how many reads (and bases) from a BAM file hit each genomic region, you can use 'count' utility. The command line is quite simple. E.g. in order to count how many reads (from N BAM files) hit regions of the human genome, you simply run: java -Xmx8g -jar snpEff.jar count GRCh37.68 readsFile_1.bam readsFile_2.bam ... readsFile_N.bam > countReads.txt The output is a TXT (tab-separated) file, that looks like this: chr start end type IDs Reads:readsFile_1.bam Bases:readsFile_1.bam Reads:readsFile_2.bam Bases:readsFile_2.bam ... 1 1 11873 Intergenic DDX11L1 130 6631 50 2544 1 1 249250621 Chromosome 1 2527754 251120400 2969569 328173439 1 6874 11873 Upstream NR_046018;DDX11L1 130 6631 50 2544 1 9362 14361 Downstream NR_024540;WASH7P 243 13702 182 9279 1 11874 12227 Exon exon_1;NR_046018;DDX11L1 4 116 2 102 1 11874 14408 Gene DDX11L1 114 7121 135 6792 1 11874 14408 Transcript NR_046018;DDX11L1 114 7121 135 6792 1 12228 12229 SpliceSiteDonor exon_1;NR_046018;DDX11L1 3 6 0 0 1 12228 12612 Intron intron_1;NR_046018;DDX11L1 13 649 0 0 1 12611 12612 SpliceSiteAcceptor exon_2;NR_046018;DDX11L1 0 0 0 0 1 12613 12721 Exon exon_2;NR_046018;DDX11L1 3 24 1 51 1 12722 12723 SpliceSiteDonor exon_2;NR_046018;DDX11L1 3 6 0 0 1 12722 13220 Intron intron_2;NR_046018;DDX11L1 22 2110 20 987 1 13219 13220 SpliceSiteAcceptor exon_3;NR_046018;DDX11L1 5 10 1 2 1 13221 14408 Exon exon_3;NR_046018;DDX11L1 82 4222 113 5652 1 14362 14829 Exon exon_11;NR_024540;WASH7P 37 1830 7 357 1 14362 29370 Transcript NR_024540;WASH7P 704 37262 524 34377 1 14362 29370 Gene WASH7P 704 37262 524 34377 1 14409 19408 Downstream NR_046018;DDX11L1 122 7633 39 4254 The columns are: Column 1: Chromosome name Column 2: Genomic region start Column 3: Genomic region end Column 4: Genomic region type (e.g. Exon, Gene, SpliceSiteDonor, etc.) Column 5: ID (e.g. exon ID ; transcript ID; gene ID) Column 6: Count of reads (in file readsFile_1.bam) intersecting genomic region. Column 7: Count of bases (in file readsFile_1.bam) intersecting genomic region, i.e. each read is intersected and the resulting number of bases added. Column ...: (repeat count reads and bases for each BAM file provided) Totals and Binomial model Using command line option -p , you can calculate p-values based on a Binomial model. For example (output edited for the sake of brevity): $ java -Xmx8g -jar snpEff.jar count -v BDGP5.69 fly.bam > countReads.txt 00:00:00.000 Reading configuration file 'snpEff.config' ... 00:00:12.148 Calculating probability model for read length 50 ... type p.binomial reads.fly expected.fly pvalue.fly Chromosome 1.0 205215 205215 1.0 Downstream 0.29531659795589793 59082 60603 1.0 Exon 0.2030262729897713 53461 41664 0.0 Gene 0.49282883664487515 110475 101136 0.0 Intergenic 0.33995644860241336 54081 69764 0.9999999963234701 Intron 0.3431415343615103 72308 70418 9.06236369003514E-19 RareAminoAcid 9.245222303207472E-7 3 0 9.879186871519377E-4 SpliceSiteAcceptor 0.014623209601955131 3142 3001 0.005099810118785825 SpliceSiteDonor 0.015279075154423956 2998 3135 0.9937690786738507 Transcript 0.49282883664487515 110475 101136 0.0 Upstream 0.31499087549896493 64181 64641 0.9856950416729887 Utr3prime 0.03495370828296416 8850 7173 1.1734134297889064E-84 Utr5prime 0.02765432673262785 8146 5675 7.908406840800345E-215 The columns in for this table are (in the previous example the input file was 'fly.bam' so fileName is 'fly'): type : Type of interval p.binomial : Probability that a random read hits this 'type' of interval (in binomial model) reads.fileName : Total number of reads in 'fileName' (user provided BAM/SAM file) expected.fileName : Expected number of reads hitting this 'type' of interval (for user provided BAM/SAM file) pvalue.fileName : p-value that 'reads.fileName' reads or more hit this 'type' of interval (for user provided BAM/SAM file) Column ...: (repeat last three column for each BAM/SAM file provided by the user) User defined intervals You can add user defined intervals using -i file.bed command line option. The option can be used multiple times, thus allowing multiple BED files to be added. Example : You want to know how many reads intersect each peak from a peak detection algorithm: java -Xmx8g -jar snpEff.jar count -i peaks.bed GRCh37.68 reads.bam SnpEff databases This command provides a list of configured databases, i.e. available in snpEff.config file. Example: $ java -jar snpEff.jar databases Genome Organism Status Bundle Database download link ------ -------- ------ ------ ---------------------- 129S1_SvImJ_v1.99 Mus_musculus_129s1svimj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_129S1_SvImJ_v1.99.zip AIIM_Pcri_1.0.99 Pavo_cristatus https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AIIM_Pcri_1.0.99.zip AKR_J_v1.99 Mus_musculus_akrj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AKR_J_v1.99.zip AP006557.1 SARS coronavirus TWH genomic RNA, complete genome. https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AP006557.1.zip AP006558.1 SARS coronavirus TWJ genomic RNA, complete genome. https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AP006558.1.zip AP006559.1 SARS coronavirus TWK genomic RNA, complete genome. https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AP006559.1.zip AP006560.1 SARS coronavirus TWS genomic RNA, complete genome. https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AP006560.1.zip AP006561.1 SARS coronavirus TWY genomic RNA, complete genome. https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AP006561.1.zip ... SnpEff download This command downloads and installs a database. Warning Note that the database must be configured in snpEff.config and available at the download site. Example: Download and install C.Elegans genome: $ java -jar snpEff.jar download -v WBcel215.69 00:00:00.000 Downloading database for 'WBcel215.69' 00:00:00.002 Connecting to http://downloads.sourceforge.net/project/snpeff/databases/v3_1/snpEff_v3_1_WBcel215.69.zip 00:00:00.547 Copying file (type: application/zip, modified on: Sat Dec 01 20:59:55 EST 2012) 00:00:00.547 Local file name: 'snpEff_v3_1_WBcel215.69.zip' 00:00:01.949 Downloaded 1049506 bytes 00:00:03.624 Downloaded 2135266 bytes 00:00:05.067 Downloaded 3185026 bytes 00:00:06.472 Downloaded 4234786 bytes 00:00:07.877 Downloaded 5284546 bytes 00:00:09.580 Downloaded 6374626 bytes 00:00:11.005 Downloaded 7424386 bytes 00:00:12.410 Downloaded 8474146 bytes 00:00:13.815 Downloaded 9523906 bytes 00:00:15.358 Downloaded 10604226 bytes 00:00:16.761 Downloaded 11653666 bytes 00:00:18.168 Downloaded 12703426 bytes 00:00:19.573 Downloaded 13753186 bytes 00:00:21.198 Downloaded 14837506 bytes 00:00:22.624 Downloaded 15887266 bytes 00:00:24.029 Downloaded 16937026 bytes 00:00:25.434 Downloaded 17986786 bytes 00:00:26.864 Downloaded 19036546 bytes 00:00:28.269 Downloaded 20086306 bytes 00:00:29.155 Donwload finished. Total 20748168 bytes. 00:00:29.156 Local file name: '/home/pcingola//snpEff/data/WBcel215.69/snpEffectPredictor.bin' 00:00:29.156 Extracting file 'data/WBcel215.69/snpEffectPredictor.bin' to '/home/pcingola//snpEff/data/WBcel215.69/snpEffectPredictor.bin' 00:00:29.157 Creating local directory: '/home/pcingola/snpEff/data/WBcel215.69' 00:00:29.424 Unzip: OK 00:00:29.424 Done SnpEff dump Dump the contents of a database to a text file, a BED file or a tab separated TXT file (that can be loaded into R). BED file example : $ java -jar snpEff.jar download -v GRCh37.70 $ java -Xmx8g -jar snpEff.jar dump -v -bed GRCh37.70 > GRCh37.70.bed 00:00:00.000 Reading database for genome 'GRCh37.70' (this might take a while) 00:00:32.476 done 00:00:32.477 Building interval forest 00:00:45.928 Done. The output file looks like a typical BED file (chr \\t start \\t end \\t name). Warning Keep in mind that BED file coordinates are zero based, semi-open intervals. So a 2 base interval at (one-based) positions 100 and 101 is expressed as a BED interval [99 - 101] . $ head GRCh37.70.bed 1 0 249250621 Chromosome_1 1 111833483 111863188 Gene_ENSG00000134216 1 111853089 111863002 Transcript_ENST00000489524 1 111861741 111861861 Cds_CDS_1_111861742_111861861 1 111861948 111862090 Cds_CDS_1_111861949_111862090 1 111860607 111860731 Cds_CDS_1_111860608_111860731 1 111861114 111861300 Cds_CDS_1_111861115_111861300 1 111860305 111860427 Cds_CDS_1_111860306_111860427 1 111862834 111863002 Cds_CDS_1_111862835_111863002 1 111853089 111853114 Utr5prime_exon_1_111853090_111853114 TXT file example : $ java -Xmx8g -jar snpEff.jar dump -v -txt GRCh37.70 > GRCh37.70.txt 00:00:00.000 Reading database for genome 'GRCh37.70' (this might take a while) 00:00:31.961 done 00:00:31.962 Building interval forest 00:00:45.467 Done. In this case, the output file looks like a typical BED file (chr \\t start \\t end \\t name): $ head GRCh37.70.txt chr start end strand type id geneName geneId numberOfTranscripts canonicalTranscriptLength transcriptId cdsLength numerOfExons exonRank exonSpliceType 1 1 249250622 +1 Chromosome 1 1 111833484 111863189 +1 Gene ENSG00000134216 CHIA ENSG00000134216 10 1431 1 111853090 111863003 +1 Transcript ENST00000489524 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 1 111861742 111861862 +1 Cds CDS_1_111861742_111861861 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 1 111861949 111862091 +1 Cds CDS_1_111861949_111862090 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 1 111853090 111853115 +1 Utr5prime exon_1_111853090_111853114 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 1 ALTTENATIVE_3SS 1 111854311 111854341 +1 Utr5prime exon_1_111854311_111854340 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 2 SKIPPED 1 111860608 111860732 +1 Exon exon_1_111860608_111860731 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 5 RETAINED 1 111853090 111853115 +1 Exon exon_1_111853090_111853114 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 1 ALTTENATIVE_3SS 1 111861742 111861862 +1 Exon exon_1_111861742_111861861 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 7 RETAINED The format is: Column Meaning chr Chromosome name start Marker start (one-based coordinate) end Marker end (one-based coordinate) strand Strand (positive or negative) type Type of marker (e.g. exon, transcript, etc.) id ID. E.g. if it's a Gene, then it may be ENSEBML's gene ID geneName Gene name, if marker is within a gene (exon, transcript, UTR, etc.), empty otherwise (e.g. intergenic) geneId Gene is, if marker is within a gene numberOfTranscripts Number of transcripts in the gene canonicalTranscriptLength CDS length of canonical transcript transcriptId Transcript ID, if marker is within a transcript cdsLength CDS length of the transcript numerOfExons Number of exons in this transcript exonRank Exon rank, if marker is an exon exonSpliceType Exon splice type, if marker is an exon SnpEff genes2bed Dumps a selected set of genes as BED intervals. Warning The functionality of this command is a subset of SnpEff dump , so it is likely to be deprecated in the future. Example: $ java -Xmx8g -jar snpEff.jar genes2bed GRCh37.66 DDX11L1 WASH7P #chr start end geneName;geneId 1 11868 14411 DDX11L1;ENSG00000223972 1 14362 29805 WASH7P;ENSG00000227232 SnpEff cds & SnpEff protein These commands perform SnpEff database sanity checks. They calculate CDS and protein sequences from a SnpEff database and then compare the results to a FASTA file (having the \"correct\" sequences). The commands are invoked automatically when building databases, so there is no need for the user to invoke them manually. SnpEff len Calculates the genomic length of every type of marker (Gene, Exon, Utr, etc.). Length is calculated by overlapping all markers and counting the number of bases (e.g. a base is counted as 'Exon' if any exon falls onto that base). This command also reports the probability of a Binomial model. Info Parameter -r num adjusts the model for a read length of 'num' bases. That is, if two markers of the same type are closer than 'num' bases, it joins them by inclining the bases separating them. E.g.: $ java -Xmx1g -jar snpEff.jar len -r 100 BDGP5.69 marker size count raw_size raw_count binomial_p Cds 22767006 56955 45406378 122117 0.13492635563570918 Chromosome 168736537 15 168736537 15 1.0 Downstream 49570138 5373 254095562 50830 0.29377240330587084 Exon 31275946 61419 63230008 138474 0.18535372691689175 Gene 82599213 11659 87017182 15222 0.4895158717166277 Intergenic 56792611 11637 56792611 11650 0.3365756581812509 Intron 55813748 42701 168836797 113059 0.33077452573297744 SpliceSiteAcceptor 97977 48983 226118 113059 5.806507691929223E-4 SpliceSiteDonor 101996 50981 226118 113059 6.044689657225808E-4 Transcript 82599213 11659 232066805 25415 0.4895158717166277 Upstream 52874082 5658 254044876 50830 0.3133528928592389 Utr3prime 5264120 13087 10828991 24324 0.031197274126824114 Utr5prime 3729197 19324 6368070 33755 0.02210070839607192 Column meaning: marker : Type of marker interval size : Size of all intervals in the genome, after overlap and join. count : Number of intervals in the genome, after overlap and join. raw_size : Size of all intervals in the genome. Note that this could be larger than the genome. raw_count : Number of intervals in the genome. Scripts Several scripts are provided in the scripts directory. Here we briefly describe their functionality: sam2fastq.pl Convert a SAM input to a FASTQ output. Example: samtools view test.bam | ./scripts/bam2fastq.pl | head -n 12 @HWI-ST1220:76:D12CHACXX:7:2207:18986:95756 CGACAATGCACGACAGAGGAAGCAGAACAGATATTTAGATTGCCTCTCATT + CCCFFFFFGHHHHIIJIJJIJIJJIJJIIIJIIHIJJJIJJIJJJJJJIJJ @HWI-ST1220:76:D12CHACXX:7:2206:4721:162268 ATATTATAGGGAGAAATATGATCGCGTATGCGAGAGTAGTGCCAACATATT + @@@DDD>DAB;?DGGEGGBCD>BFGI?FCFFBFGG@<?B*?BFB9FGII@E @HWI-ST1220:76:D12CHACXX:7:1304:13069:17740 ATAGGGAGAAATATGATCGCGTATGCGAGAGTAGTGCCAACATATTGTGCT + CCCFFFFFHHHHHJJJJJJJJGIJJJJJJAGBGGIIIJJJJJJJJJJJIJG fasta2tab.pl Convert a fasta file to a two column tab-separated TXT file (name \\t sequence) Example (output truncated for brevity): $ zcat ce6.fa.gz | ./scripts/fasta2tab.pl chrI gcctaagcctaagcctaagcctaagcctaagcctaagcctaagcct... chrV GAATTcctaagcctaagcctaagcctaagcctaagcctaagcctaa... chrII cctaagcctaagcctaagcctaagcctaagcctaagcctaagccta... chrM CAGTAAATAGTTTAATAAAAATATAGCATTTGGGTTGCTAAGATAT... chrX ctaagcctaagcctaagcctaagcctaagcctaagcctaagcctaa... chrIV cctaagcctaagcctaagcctaagcctaagcctaagcctaagccta... chrIII cctaagcctaagcctaagcctaagcctaagcctaagcctaagccta... fastaSplit.pl Split a multiple sequence FASTA file to individual files. Example: Creates one file per chromosome: $ zcat ce6.fa.gz | ./scripts/fastaSplit.pl Writing to chrI.fa Writing to chrV.fa Writing to chrII.fa Writing to chrM.fa Writing to chrX.fa Writing to chrIV.fa Writing to chrIII.fa plotHistogram.pl Given a list of numbers (one per line), shows a histogram. Note: It requires R. Example: Extract the file sizes in a directory and show a histogram $ ls -al scripts/ | tr -s \" \" | cut -f 5 -d \" \" | ./scripts/hist.pl Creates the following plot: plotMA.pl, plot.pl, plotQQ.pl, plotSmoothScatter.pl Similar to 'hist.pl', these perform plots based on input from STDIN. Note that in some cases, inputs are expected to be probabilities (qqplot.pl) or pairs of numbers (maPlot.pl). $ ls -al scripts/ | tr -s \" \" | cut -f 5 -d \" \" | ./scripts/plot.pl Creates the following plot: queue.pl Process a list of statements in parallel according to the number of CPUs available in the local machine. splitChr.pl Splits a file by chromosome. Works on any tab separated file that the first column is CHR field (e.g. BED, VCF, etc.) Example: $ cat large_test.vcf | ./scripts/splitChr.pl Input line 28. Creating file 'chr1.txt' Input line 13332. Creating file 'chr2.txt' Input line 22097. Creating file 'chr3.txt' Input line 29289. Creating file 'chr4.txt' Input line 34236. Creating file 'chr5.txt' Input line 39899. Creating file 'chr6.txt' Input line 47120. Creating file 'chr7.txt' Input line 53371. Creating file 'chr8.txt' Input line 57810. Creating file 'chr9.txt' Input line 63005. Creating file 'chr10.txt' Input line 68080. Creating file 'chr11.txt' Input line 76629. Creating file 'chr12.txt' Input line 83071. Creating file 'chr13.txt' Input line 85124. Creating file 'chr14.txt' Input line 89281. Creating file 'chr15.txt' Input line 93215. Creating file 'chr16.txt' Input line 99081. Creating file 'chr17.txt' Input line 106405. Creating file 'chr18.txt' Input line 108330. Creating file 'chr19.txt' Input line 118568. Creating file 'chr20.txt' Input line 121795. Creating file 'chr21.txt' Input line 123428. Creating file 'chr22.txt' Input line 126520. Creating file 'chrX.txt' Input line 129094. Creating file 'chrY.txt' Input line 129113. Creating file 'chrMT.txt' uniqCount.pl Count number of unique lines. It's the same as doing cat lines.tst | sort | uniq -c , but much faster. Particularly useful for very large inputs. vcfEffOnePerLine.pl Splits EFF fields in a VCF file, creating multiple lines, each one with only one effect. Very useful for filtering with SnpSift. Example: $ cat test.stop.vcf 1 897062 . C T 100.0 PASS AC=1;EFF=STOP_GAINED(HIGH|NONSENSE|Cag/Tag|Q141*|642|KLHL17||CODING|NM_198317|),UPSTREAM(MODIFIER||||576|PLEKHN1||CODING|NM_001160184|),UPSTREAM(MODIFIER||||611|PLEKHN1||CODING|NM_032129|),UPSTREAM(MODIFIER||||749|NOC2L||CODING|NM_015658|) $ cat test.stop.vcf | ./scripts/vcfEffOnePerLine.pl 1 897062 . C T 100.0 PASS AC=1;EFF=STOP_GAINED(HIGH|NONSENSE|Cag/Tag|Q141*|642|KLHL17||CODING|NM_198317|) 1 897062 . C T 100.0 PASS AC=1;EFF=UPSTREAM(MODIFIER||||576|PLEKHN1||CODING|NM_001160184|) 1 897062 . C T 100.0 PASS AC=1;EFF=UPSTREAM(MODIFIER||||611|PLEKHN1||CODING|NM_032129|) 1 897062 . C T 100.0 PASS AC=1;EFF=UPSTREAM(MODIFIER||||749|NOC2L||CODING|NM_015658|)","title":"Commands and utilities"},{"location":"se_commands/#commands-and-utilities","text":"SnpEff provides several other commands and utilities that can be useful for genomic data analysis. Most of this manual was dedicated the SnpEff eff and SnpEff build commands, which annotate effects and build databases respectively. Here we describe all the other commands and some scripts provided, that are useful for genomic data analysis.","title":"Commands and utilities"},{"location":"se_commands/#snpeff-closest","text":"Annotates using the closest genomic region (e.g. exon, transcript ID, gene name) and distance in bases. Example: $ java -Xmx8g -jar snpEff.jar closest GRCh37.66 test.vcf ##INFO=<ID=CLOSEST,Number=4,Type=String,Description=\"Closest exon: Distance (bases), exons Id, transcript Id, gene name\"> 1 12078 . G A 25.69 PASS AC=2;AF=0.048;CLOSEST=0,exon_1_11869_12227,ENST00000456328,DDX11L1 1 16097 . T G 42.42 PASS AC=9;AF=0.0113;CLOSEST=150,exon_1_15796_15947,ENST00000423562,WASH7P 1 40261 . C A 366.26 PASS AC=30;AF=0.484;CLOSEST=4180,exon_1_35721_36081,ENST00000417324,FAM138A 1 63880 . C T 82.13 PASS AC=10;AF=0.0400;CLOSEST=0,exon_1_62948_63887,ENST00000492842,OR4G11P For instance, in the third line (1:16097 T G), it added the tag CLOSEST=150,exon_1_15796_15947,ENST00000423562,WASH7P , which means that the variant is 150 bases away from exon \"exon_1_15796_15947\". The exon belongs to transcript \"ENST00000423562\" of gene \"WASH7P\". Info If multiple markers are available (at the same distance) the one belonging to the longest mRna transcript is shown. The input can also be a BED file, the output file has the same information as CLOSEST info field, added to the fourth column of the output BED file: $ snpeff closest -bed GRCh37.66 test.bed 1 12077 12078 line_1;0,exon_1_11869_12227,ENST00000456328,DDX11L1 1 16096 16097 line_2;150,exon_1_15796_15947,ENST00000423562,WASH7P 1 40260 40261 line_3;4180,exon_1_35721_36081,ENST00000417324,FAM138A 1 63879 63880 line_4;0,exon_1_62948_63887,ENST00000492842,OR4G11P","title":"SnpEff closest"},{"location":"se_commands/#snpeff-count","text":"As the name suggests, snpEff count command counts how many reads and bases from a BAM file hit a gene, transcript, exon, intron, etc. Input files can be in BAM, SAM, VCF, BED or BigBed formats. A summary HTML file with charts is generated. Here are some examples: If you need to count how many reads (and bases) from a BAM file hit each genomic region, you can use 'count' utility. The command line is quite simple. E.g. in order to count how many reads (from N BAM files) hit regions of the human genome, you simply run: java -Xmx8g -jar snpEff.jar count GRCh37.68 readsFile_1.bam readsFile_2.bam ... readsFile_N.bam > countReads.txt The output is a TXT (tab-separated) file, that looks like this: chr start end type IDs Reads:readsFile_1.bam Bases:readsFile_1.bam Reads:readsFile_2.bam Bases:readsFile_2.bam ... 1 1 11873 Intergenic DDX11L1 130 6631 50 2544 1 1 249250621 Chromosome 1 2527754 251120400 2969569 328173439 1 6874 11873 Upstream NR_046018;DDX11L1 130 6631 50 2544 1 9362 14361 Downstream NR_024540;WASH7P 243 13702 182 9279 1 11874 12227 Exon exon_1;NR_046018;DDX11L1 4 116 2 102 1 11874 14408 Gene DDX11L1 114 7121 135 6792 1 11874 14408 Transcript NR_046018;DDX11L1 114 7121 135 6792 1 12228 12229 SpliceSiteDonor exon_1;NR_046018;DDX11L1 3 6 0 0 1 12228 12612 Intron intron_1;NR_046018;DDX11L1 13 649 0 0 1 12611 12612 SpliceSiteAcceptor exon_2;NR_046018;DDX11L1 0 0 0 0 1 12613 12721 Exon exon_2;NR_046018;DDX11L1 3 24 1 51 1 12722 12723 SpliceSiteDonor exon_2;NR_046018;DDX11L1 3 6 0 0 1 12722 13220 Intron intron_2;NR_046018;DDX11L1 22 2110 20 987 1 13219 13220 SpliceSiteAcceptor exon_3;NR_046018;DDX11L1 5 10 1 2 1 13221 14408 Exon exon_3;NR_046018;DDX11L1 82 4222 113 5652 1 14362 14829 Exon exon_11;NR_024540;WASH7P 37 1830 7 357 1 14362 29370 Transcript NR_024540;WASH7P 704 37262 524 34377 1 14362 29370 Gene WASH7P 704 37262 524 34377 1 14409 19408 Downstream NR_046018;DDX11L1 122 7633 39 4254 The columns are: Column 1: Chromosome name Column 2: Genomic region start Column 3: Genomic region end Column 4: Genomic region type (e.g. Exon, Gene, SpliceSiteDonor, etc.) Column 5: ID (e.g. exon ID ; transcript ID; gene ID) Column 6: Count of reads (in file readsFile_1.bam) intersecting genomic region. Column 7: Count of bases (in file readsFile_1.bam) intersecting genomic region, i.e. each read is intersected and the resulting number of bases added. Column ...: (repeat count reads and bases for each BAM file provided) Totals and Binomial model Using command line option -p , you can calculate p-values based on a Binomial model. For example (output edited for the sake of brevity): $ java -Xmx8g -jar snpEff.jar count -v BDGP5.69 fly.bam > countReads.txt 00:00:00.000 Reading configuration file 'snpEff.config' ... 00:00:12.148 Calculating probability model for read length 50 ... type p.binomial reads.fly expected.fly pvalue.fly Chromosome 1.0 205215 205215 1.0 Downstream 0.29531659795589793 59082 60603 1.0 Exon 0.2030262729897713 53461 41664 0.0 Gene 0.49282883664487515 110475 101136 0.0 Intergenic 0.33995644860241336 54081 69764 0.9999999963234701 Intron 0.3431415343615103 72308 70418 9.06236369003514E-19 RareAminoAcid 9.245222303207472E-7 3 0 9.879186871519377E-4 SpliceSiteAcceptor 0.014623209601955131 3142 3001 0.005099810118785825 SpliceSiteDonor 0.015279075154423956 2998 3135 0.9937690786738507 Transcript 0.49282883664487515 110475 101136 0.0 Upstream 0.31499087549896493 64181 64641 0.9856950416729887 Utr3prime 0.03495370828296416 8850 7173 1.1734134297889064E-84 Utr5prime 0.02765432673262785 8146 5675 7.908406840800345E-215 The columns in for this table are (in the previous example the input file was 'fly.bam' so fileName is 'fly'): type : Type of interval p.binomial : Probability that a random read hits this 'type' of interval (in binomial model) reads.fileName : Total number of reads in 'fileName' (user provided BAM/SAM file) expected.fileName : Expected number of reads hitting this 'type' of interval (for user provided BAM/SAM file) pvalue.fileName : p-value that 'reads.fileName' reads or more hit this 'type' of interval (for user provided BAM/SAM file) Column ...: (repeat last three column for each BAM/SAM file provided by the user) User defined intervals You can add user defined intervals using -i file.bed command line option. The option can be used multiple times, thus allowing multiple BED files to be added. Example : You want to know how many reads intersect each peak from a peak detection algorithm: java -Xmx8g -jar snpEff.jar count -i peaks.bed GRCh37.68 reads.bam","title":"SnpEff count"},{"location":"se_commands/#snpeff-databases","text":"This command provides a list of configured databases, i.e. available in snpEff.config file. Example: $ java -jar snpEff.jar databases Genome Organism Status Bundle Database download link ------ -------- ------ ------ ---------------------- 129S1_SvImJ_v1.99 Mus_musculus_129s1svimj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_129S1_SvImJ_v1.99.zip AIIM_Pcri_1.0.99 Pavo_cristatus https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AIIM_Pcri_1.0.99.zip AKR_J_v1.99 Mus_musculus_akrj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AKR_J_v1.99.zip AP006557.1 SARS coronavirus TWH genomic RNA, complete genome. https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AP006557.1.zip AP006558.1 SARS coronavirus TWJ genomic RNA, complete genome. https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AP006558.1.zip AP006559.1 SARS coronavirus TWK genomic RNA, complete genome. https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AP006559.1.zip AP006560.1 SARS coronavirus TWS genomic RNA, complete genome. https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AP006560.1.zip AP006561.1 SARS coronavirus TWY genomic RNA, complete genome. https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AP006561.1.zip ...","title":"SnpEff databases"},{"location":"se_commands/#snpeff-download","text":"This command downloads and installs a database. Warning Note that the database must be configured in snpEff.config and available at the download site. Example: Download and install C.Elegans genome: $ java -jar snpEff.jar download -v WBcel215.69 00:00:00.000 Downloading database for 'WBcel215.69' 00:00:00.002 Connecting to http://downloads.sourceforge.net/project/snpeff/databases/v3_1/snpEff_v3_1_WBcel215.69.zip 00:00:00.547 Copying file (type: application/zip, modified on: Sat Dec 01 20:59:55 EST 2012) 00:00:00.547 Local file name: 'snpEff_v3_1_WBcel215.69.zip' 00:00:01.949 Downloaded 1049506 bytes 00:00:03.624 Downloaded 2135266 bytes 00:00:05.067 Downloaded 3185026 bytes 00:00:06.472 Downloaded 4234786 bytes 00:00:07.877 Downloaded 5284546 bytes 00:00:09.580 Downloaded 6374626 bytes 00:00:11.005 Downloaded 7424386 bytes 00:00:12.410 Downloaded 8474146 bytes 00:00:13.815 Downloaded 9523906 bytes 00:00:15.358 Downloaded 10604226 bytes 00:00:16.761 Downloaded 11653666 bytes 00:00:18.168 Downloaded 12703426 bytes 00:00:19.573 Downloaded 13753186 bytes 00:00:21.198 Downloaded 14837506 bytes 00:00:22.624 Downloaded 15887266 bytes 00:00:24.029 Downloaded 16937026 bytes 00:00:25.434 Downloaded 17986786 bytes 00:00:26.864 Downloaded 19036546 bytes 00:00:28.269 Downloaded 20086306 bytes 00:00:29.155 Donwload finished. Total 20748168 bytes. 00:00:29.156 Local file name: '/home/pcingola//snpEff/data/WBcel215.69/snpEffectPredictor.bin' 00:00:29.156 Extracting file 'data/WBcel215.69/snpEffectPredictor.bin' to '/home/pcingola//snpEff/data/WBcel215.69/snpEffectPredictor.bin' 00:00:29.157 Creating local directory: '/home/pcingola/snpEff/data/WBcel215.69' 00:00:29.424 Unzip: OK 00:00:29.424 Done","title":"SnpEff download"},{"location":"se_commands/#snpeff-dump","text":"Dump the contents of a database to a text file, a BED file or a tab separated TXT file (that can be loaded into R). BED file example : $ java -jar snpEff.jar download -v GRCh37.70 $ java -Xmx8g -jar snpEff.jar dump -v -bed GRCh37.70 > GRCh37.70.bed 00:00:00.000 Reading database for genome 'GRCh37.70' (this might take a while) 00:00:32.476 done 00:00:32.477 Building interval forest 00:00:45.928 Done. The output file looks like a typical BED file (chr \\t start \\t end \\t name). Warning Keep in mind that BED file coordinates are zero based, semi-open intervals. So a 2 base interval at (one-based) positions 100 and 101 is expressed as a BED interval [99 - 101] . $ head GRCh37.70.bed 1 0 249250621 Chromosome_1 1 111833483 111863188 Gene_ENSG00000134216 1 111853089 111863002 Transcript_ENST00000489524 1 111861741 111861861 Cds_CDS_1_111861742_111861861 1 111861948 111862090 Cds_CDS_1_111861949_111862090 1 111860607 111860731 Cds_CDS_1_111860608_111860731 1 111861114 111861300 Cds_CDS_1_111861115_111861300 1 111860305 111860427 Cds_CDS_1_111860306_111860427 1 111862834 111863002 Cds_CDS_1_111862835_111863002 1 111853089 111853114 Utr5prime_exon_1_111853090_111853114 TXT file example : $ java -Xmx8g -jar snpEff.jar dump -v -txt GRCh37.70 > GRCh37.70.txt 00:00:00.000 Reading database for genome 'GRCh37.70' (this might take a while) 00:00:31.961 done 00:00:31.962 Building interval forest 00:00:45.467 Done. In this case, the output file looks like a typical BED file (chr \\t start \\t end \\t name): $ head GRCh37.70.txt chr start end strand type id geneName geneId numberOfTranscripts canonicalTranscriptLength transcriptId cdsLength numerOfExons exonRank exonSpliceType 1 1 249250622 +1 Chromosome 1 1 111833484 111863189 +1 Gene ENSG00000134216 CHIA ENSG00000134216 10 1431 1 111853090 111863003 +1 Transcript ENST00000489524 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 1 111861742 111861862 +1 Cds CDS_1_111861742_111861861 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 1 111861949 111862091 +1 Cds CDS_1_111861949_111862090 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 1 111853090 111853115 +1 Utr5prime exon_1_111853090_111853114 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 1 ALTTENATIVE_3SS 1 111854311 111854341 +1 Utr5prime exon_1_111854311_111854340 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 2 SKIPPED 1 111860608 111860732 +1 Exon exon_1_111860608_111860731 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 5 RETAINED 1 111853090 111853115 +1 Exon exon_1_111853090_111853114 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 1 ALTTENATIVE_3SS 1 111861742 111861862 +1 Exon exon_1_111861742_111861861 CHIA ENSG00000134216 10 1431 ENST00000489524 862 9 7 RETAINED The format is: Column Meaning chr Chromosome name start Marker start (one-based coordinate) end Marker end (one-based coordinate) strand Strand (positive or negative) type Type of marker (e.g. exon, transcript, etc.) id ID. E.g. if it's a Gene, then it may be ENSEBML's gene ID geneName Gene name, if marker is within a gene (exon, transcript, UTR, etc.), empty otherwise (e.g. intergenic) geneId Gene is, if marker is within a gene numberOfTranscripts Number of transcripts in the gene canonicalTranscriptLength CDS length of canonical transcript transcriptId Transcript ID, if marker is within a transcript cdsLength CDS length of the transcript numerOfExons Number of exons in this transcript exonRank Exon rank, if marker is an exon exonSpliceType Exon splice type, if marker is an exon","title":"SnpEff dump"},{"location":"se_commands/#snpeff-genes2bed","text":"Dumps a selected set of genes as BED intervals. Warning The functionality of this command is a subset of SnpEff dump , so it is likely to be deprecated in the future. Example: $ java -Xmx8g -jar snpEff.jar genes2bed GRCh37.66 DDX11L1 WASH7P #chr start end geneName;geneId 1 11868 14411 DDX11L1;ENSG00000223972 1 14362 29805 WASH7P;ENSG00000227232","title":"SnpEff genes2bed"},{"location":"se_commands/#snpeff-cds-snpeff-protein","text":"These commands perform SnpEff database sanity checks. They calculate CDS and protein sequences from a SnpEff database and then compare the results to a FASTA file (having the \"correct\" sequences). The commands are invoked automatically when building databases, so there is no need for the user to invoke them manually.","title":"SnpEff cds &amp; SnpEff protein"},{"location":"se_commands/#snpeff-len","text":"Calculates the genomic length of every type of marker (Gene, Exon, Utr, etc.). Length is calculated by overlapping all markers and counting the number of bases (e.g. a base is counted as 'Exon' if any exon falls onto that base). This command also reports the probability of a Binomial model. Info Parameter -r num adjusts the model for a read length of 'num' bases. That is, if two markers of the same type are closer than 'num' bases, it joins them by inclining the bases separating them. E.g.: $ java -Xmx1g -jar snpEff.jar len -r 100 BDGP5.69 marker size count raw_size raw_count binomial_p Cds 22767006 56955 45406378 122117 0.13492635563570918 Chromosome 168736537 15 168736537 15 1.0 Downstream 49570138 5373 254095562 50830 0.29377240330587084 Exon 31275946 61419 63230008 138474 0.18535372691689175 Gene 82599213 11659 87017182 15222 0.4895158717166277 Intergenic 56792611 11637 56792611 11650 0.3365756581812509 Intron 55813748 42701 168836797 113059 0.33077452573297744 SpliceSiteAcceptor 97977 48983 226118 113059 5.806507691929223E-4 SpliceSiteDonor 101996 50981 226118 113059 6.044689657225808E-4 Transcript 82599213 11659 232066805 25415 0.4895158717166277 Upstream 52874082 5658 254044876 50830 0.3133528928592389 Utr3prime 5264120 13087 10828991 24324 0.031197274126824114 Utr5prime 3729197 19324 6368070 33755 0.02210070839607192 Column meaning: marker : Type of marker interval size : Size of all intervals in the genome, after overlap and join. count : Number of intervals in the genome, after overlap and join. raw_size : Size of all intervals in the genome. Note that this could be larger than the genome. raw_count : Number of intervals in the genome.","title":"SnpEff len"},{"location":"se_commands/#scripts","text":"Several scripts are provided in the scripts directory. Here we briefly describe their functionality:","title":"Scripts"},{"location":"se_commands/#sam2fastqpl","text":"Convert a SAM input to a FASTQ output. Example: samtools view test.bam | ./scripts/bam2fastq.pl | head -n 12 @HWI-ST1220:76:D12CHACXX:7:2207:18986:95756 CGACAATGCACGACAGAGGAAGCAGAACAGATATTTAGATTGCCTCTCATT + CCCFFFFFGHHHHIIJIJJIJIJJIJJIIIJIIHIJJJIJJIJJJJJJIJJ @HWI-ST1220:76:D12CHACXX:7:2206:4721:162268 ATATTATAGGGAGAAATATGATCGCGTATGCGAGAGTAGTGCCAACATATT + @@@DDD>DAB;?DGGEGGBCD>BFGI?FCFFBFGG@<?B*?BFB9FGII@E @HWI-ST1220:76:D12CHACXX:7:1304:13069:17740 ATAGGGAGAAATATGATCGCGTATGCGAGAGTAGTGCCAACATATTGTGCT + CCCFFFFFHHHHHJJJJJJJJGIJJJJJJAGBGGIIIJJJJJJJJJJJIJG","title":"sam2fastq.pl"},{"location":"se_commands/#fasta2tabpl","text":"Convert a fasta file to a two column tab-separated TXT file (name \\t sequence) Example (output truncated for brevity): $ zcat ce6.fa.gz | ./scripts/fasta2tab.pl chrI gcctaagcctaagcctaagcctaagcctaagcctaagcctaagcct... chrV GAATTcctaagcctaagcctaagcctaagcctaagcctaagcctaa... chrII cctaagcctaagcctaagcctaagcctaagcctaagcctaagccta... chrM CAGTAAATAGTTTAATAAAAATATAGCATTTGGGTTGCTAAGATAT... chrX ctaagcctaagcctaagcctaagcctaagcctaagcctaagcctaa... chrIV cctaagcctaagcctaagcctaagcctaagcctaagcctaagccta... chrIII cctaagcctaagcctaagcctaagcctaagcctaagcctaagccta...","title":"fasta2tab.pl"},{"location":"se_commands/#fastasplitpl","text":"Split a multiple sequence FASTA file to individual files. Example: Creates one file per chromosome: $ zcat ce6.fa.gz | ./scripts/fastaSplit.pl Writing to chrI.fa Writing to chrV.fa Writing to chrII.fa Writing to chrM.fa Writing to chrX.fa Writing to chrIV.fa Writing to chrIII.fa","title":"fastaSplit.pl"},{"location":"se_commands/#plothistogrampl","text":"Given a list of numbers (one per line), shows a histogram. Note: It requires R. Example: Extract the file sizes in a directory and show a histogram $ ls -al scripts/ | tr -s \" \" | cut -f 5 -d \" \" | ./scripts/hist.pl Creates the following plot:","title":"plotHistogram.pl"},{"location":"se_commands/#plotmapl-plotpl-plotqqpl-plotsmoothscatterpl","text":"Similar to 'hist.pl', these perform plots based on input from STDIN. Note that in some cases, inputs are expected to be probabilities (qqplot.pl) or pairs of numbers (maPlot.pl). $ ls -al scripts/ | tr -s \" \" | cut -f 5 -d \" \" | ./scripts/plot.pl Creates the following plot:","title":"plotMA.pl, plot.pl, plotQQ.pl, plotSmoothScatter.pl"},{"location":"se_commands/#queuepl","text":"Process a list of statements in parallel according to the number of CPUs available in the local machine.","title":"queue.pl"},{"location":"se_commands/#splitchrpl","text":"Splits a file by chromosome. Works on any tab separated file that the first column is CHR field (e.g. BED, VCF, etc.) Example: $ cat large_test.vcf | ./scripts/splitChr.pl Input line 28. Creating file 'chr1.txt' Input line 13332. Creating file 'chr2.txt' Input line 22097. Creating file 'chr3.txt' Input line 29289. Creating file 'chr4.txt' Input line 34236. Creating file 'chr5.txt' Input line 39899. Creating file 'chr6.txt' Input line 47120. Creating file 'chr7.txt' Input line 53371. Creating file 'chr8.txt' Input line 57810. Creating file 'chr9.txt' Input line 63005. Creating file 'chr10.txt' Input line 68080. Creating file 'chr11.txt' Input line 76629. Creating file 'chr12.txt' Input line 83071. Creating file 'chr13.txt' Input line 85124. Creating file 'chr14.txt' Input line 89281. Creating file 'chr15.txt' Input line 93215. Creating file 'chr16.txt' Input line 99081. Creating file 'chr17.txt' Input line 106405. Creating file 'chr18.txt' Input line 108330. Creating file 'chr19.txt' Input line 118568. Creating file 'chr20.txt' Input line 121795. Creating file 'chr21.txt' Input line 123428. Creating file 'chr22.txt' Input line 126520. Creating file 'chrX.txt' Input line 129094. Creating file 'chrY.txt' Input line 129113. Creating file 'chrMT.txt'","title":"splitChr.pl"},{"location":"se_commands/#uniqcountpl","text":"Count number of unique lines. It's the same as doing cat lines.tst | sort | uniq -c , but much faster. Particularly useful for very large inputs.","title":"uniqCount.pl"},{"location":"se_commands/#vcfeffoneperlinepl","text":"Splits EFF fields in a VCF file, creating multiple lines, each one with only one effect. Very useful for filtering with SnpSift. Example: $ cat test.stop.vcf 1 897062 . C T 100.0 PASS AC=1;EFF=STOP_GAINED(HIGH|NONSENSE|Cag/Tag|Q141*|642|KLHL17||CODING|NM_198317|),UPSTREAM(MODIFIER||||576|PLEKHN1||CODING|NM_001160184|),UPSTREAM(MODIFIER||||611|PLEKHN1||CODING|NM_032129|),UPSTREAM(MODIFIER||||749|NOC2L||CODING|NM_015658|) $ cat test.stop.vcf | ./scripts/vcfEffOnePerLine.pl 1 897062 . C T 100.0 PASS AC=1;EFF=STOP_GAINED(HIGH|NONSENSE|Cag/Tag|Q141*|642|KLHL17||CODING|NM_198317|) 1 897062 . C T 100.0 PASS AC=1;EFF=UPSTREAM(MODIFIER||||576|PLEKHN1||CODING|NM_001160184|) 1 897062 . C T 100.0 PASS AC=1;EFF=UPSTREAM(MODIFIER||||611|PLEKHN1||CODING|NM_032129|) 1 897062 . C T 100.0 PASS AC=1;EFF=UPSTREAM(MODIFIER||||749|NOC2L||CODING|NM_015658|)","title":"vcfEffOnePerLine.pl"},{"location":"se_faq/","text":"SnpEff: Frequently Asked Questions Error and Warning messages SnpEff defines several messages in roughly 3 categories: INFO: An informative message WARNING: A problem in the reference genome definition that MAY result in an incorrect variant annotation ERROR: A problem in the reference genome definition that WILL ALMOST CERTAINLY result in an incorrect variant annotation INFO_REALIGN_3_PRIME The variant has been realigned to the most 3-prime position within the transcript. This is usually done to comply with HGVS specification to always report the most 3-prime annotation. While VCF requires to realign to the left-most of the reference genome, HGSV requires to realign to the most 3-prime. These two specifications are contradicting in some cases, so in order to comply with HGSV, sometimes a local realignment is required. IMPORTANT: This message is just indicating that a realignment was performed, so when this INFO message is present, the original coordinates from the VCF file are not exactly the same as the coordinates used to calculate the variant annotation WARNING_SEQUENCE_NOT_AVAILABLE The exon does not have reference sequence information. The annotation may not be calculated (e.g. incomplete transcripts). WARNING_REF_DOES_NOT_MATCH_GENOME The genome reference does not match the variant's reference. For example, if the VCF file indicates that the reference at a certain location is 'A', while SnpEff's database indicates that the reference should be 'C', this WARNING would be added. Under normal circumstances, there should be none of these warnings (or at most a handful). IMPORTANT: If too many of these warnings are seen, this indicates a severe problem (version mismatch between your VCF files and the reference genome). A typical case when too many of these warning are seen is when trying to annotate using a different genome than the one used for alignment (e.g. reads are aligned to hg19 but variants are annotated to using hg38) WARNING_TRANSCRIPT_INCOMPLETE The number of coding bases is NOT multiple of 3, so there is missing information for at least one codon. This indicates an error in the reference genome gene and/or transcript definition. This could happen in genomes that are not well understood. WARNING_TRANSCRIPT_MULTIPLE_STOP_CODONS Multiple STOP codons found in a CDS. There should be only one STOP codon at the end of the transcript, but in this case, the transcript has multiple STOP codons, which is unlikely to be real. This usually indicates an error on the reference genome (or database). Could for, for example, indicating frame errors in the reference genome for one or more exons in this transcript. WARNING_TRANSCRIPT_NO_START_CODON Start codon does not match any 'start' codon in the CodonTable. This usually indicates an error on the reference genome (or database) but could be also due to a misconfigured codon table for the genome. You should check that the codon table is properly set in snpEff.config WARNING_TRANSCRIPT_NO_STOP_CODON Stop codon does not match any 'stop' codon in the CodonTable. This usually indicates an error on the reference genome (or database) but could be also due to a misconfigured codon table for the genome. You should check that the codon table is properly set in snpEff.config ERROR_CHROMOSOME_NOT_FOUND Chromosome name not found. Typically due to mismatch in chromosome naming conventions between variants file and database, but can be a more several problems (different reference genome). See more details (here)[https://github.com/pcingola/SnpEff/wiki/ERROR_CHROMOSOME_NOT_FOUND] ERROR_OUT_OF_CHROMOSOME_RANGE Variant's genomic position is outside chromosome's range. Simple, the variant coordinate is outside the reference genome chromosome's length. IMPORTANT: If too many of these warnings are seen, this indicates a severe problem (version mismatch between your VCF files and the reference genome). A typical case when too many of these warning are seen is when trying to annotate using a different genome than the one used for alignment (e.g. reads are aligned to hg19 but variants are annotated to using hg38) ERROR_OUT_OF_EXON An exonic variant is falling outside the exon. ERROR_MISSING_CDS_SEQUENCE Missing coding sequence information. In this case, the full variant annotation cannot be calculated due to missing CDS information. This usually indicates an error on the reference genome (or database). ERROR_CHROMOSOME_NOT_FOUND: Details The error is due to a difference between the chromosome names in input VCF file and the chromosome names in SnpEff's database. Chromosome does not exist in the reference database. Typically this means that there is a mismatch between the chromosome names in your input file and the chromosome names used in the reference genome to build SnpEff's database. Warning This error could be caused because you are trying to annotate using a reference genome that is different than the one you used for sequence alignment. Obviously doing this makes no sense and the annotation information you'll get will be garbage. That's why SnpEff shows you an error message. Solution Sometimes SnpEff database matches the reference genome for your organism, and it's just that the chromosome names are changed. In this case, you can fix the error by changing the chromosome names in your input file. Info You can see the chromosome names used by SnpEff's database by using -v (verbose) option. SnpEff will show a line like this one: $ java -Xmx4g -jar snpEff.jar -v genomeName my.vcf > my.ann.vcf ... ... # Chromosomes names [sizes] : '1' [249250621] '2' [243199373] ... ... Info You can see the chromosome names in your input VCF file using a command like this one cat input.vcf | grep -v \"^#\" | cut -f 1 | uniq Once you know the names of the input file and the name used by SnpEff's database, you can adjust the chromosome name using a simple sed command. For example, if you input file's chromosome name is INPUT_CHR_NAME and the name in SnpEff's database is SNPEFF_CHR_NAME , you could use the following command: cat input.vcf | sed \"s/^INPUT_CHR_NAME/SNPEFF_CHR_NAME/\" > input_updated_chr.vcf How to building an NCBI genome (GenBank file) When building a database with SnpEff if your genomic reference is in NCBI, there is a script that might help you build the database. The script is buildDbNcbi.sh and is located in snpEff's scripts directory. It takes only one argument, which is the NCBI's ID. Example: Salmonella enterica In this example, we build the database for \"Salmonella enterica subsp. enterica serovar Typhi str. P-stx-12\" having accession ID CP003278.1 $ cd ~/snpEff # Note: Output edited for brevity $ ./scripts/buildDbNcbi.sh CP003278.1 Downloading genome CP003278.1 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 10.2M 0 10.2M 0 0 3627k 0 --:--:-- 0:00:02 --:--:-- 3627k 00:00:00 SnpEff version SnpEff 4.3p (build 2017-07-28 14:02), by Pablo Cingolani 00:00:00 Command: 'build' 00:00:00 Building database for 'CP003278.1' 00:00:00 Reading configuration file 'snpEff.config'. Genome: 'CP003278.1' 00:00:00 Reading config file: /home/pcingola/workspace/SnpEff/snpEff.config 00:00:00 done Chromosome: 'CP003278' length: 4768352 Create exons from CDS (if needed): .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. Exons created for 4690 transcripts. ... 00:00:01 Reading proteins from file '/home/pcingola/workspace/SnpEff/./data/CP003278.1/genes.gbk'... 00:00:01 done (4690 Proteins). 00:00:01 Comparing Proteins... Labels: '+' : OK '.' : Missing '*' : Error +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ... +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ Protein check: CP003278.1 OK: 4690 Not found: 0 Errors: 0 Error percentage: 0.0% 00:00:02 Saving database ... 00:00:04 Done. Creating a protein sequence FASTA file SnpEff ann command has a command line option called -fastaProt that tells SnpEff to output the \"original\" and \"resulting\" protein sequences for each variant into a FASTA file. This means that for each variant, the output FASTA file will have an entry with protein sequence resulting from applying that variant to the reference sequence. Here is an example: $ cat z.vcf 1 889455 . G A . . . $ java -Xmx6g -jar snpEff.jar ann -fastaProt z.prot.fa hg19 z.vcf > z.ann.vcf The resulting fasta file z.prot.fa looks like this (lines edited for readibility): >NM_015658.3 Ref MAAAGSR...LLFGKVAKDSSRMLQPSSSPLWGKLRVDIKAYLGS... >NM_015658.3 Variant 1:889455-889455 Ref:G Alt:A HGVS.p:p.Gln236* MAAAGSR...LLFGKVAKDSSRML*PSSSPLWGKLRVDIKAYLGS... Genome reference Having a standard reference sequence is the key to establish comparisons and analysis. In order to compare DNA from different individuals (or samples), we need a reference genome sequence and genomic annotations . Alignment and annotations must be based on the exact same reference genome sequence. Variants are called based on the reference genome, thus variant annotations must be performed using same reference genome. For instance, performing variant calling respect to hg19 and then performing variant annotations using hg38 genome, would result in completely erroneous results. Oftentimes lack of consistency between SnpEff annotations and genome coordinated from other data sources (e.g. a genome browser or other online databases) are due to the fact that there is a difference in genome reference versions. For example, maybe the VCF file was annotated using SnpEff's GRCh38.99 database, but you are looking at an hg38 genome browser (both reference are human, version 38, but different transcript versions). Genome reference data sources SnpEff genome databases are built from genomic data sources, such as Ensembl, RefSeq, NCBI, UCSC, etc. To find which data source was used, sometimes the information is provided in the snpEff.config file, under the genome_name.reference entry. Example 1: GRCh37.75 If you are looking for the GRCh37.75 genome, you can search for the entry in snpEff.conf file: $ grep -A 1 GRCh37.75 snpEff.config GRCh37.75.genome : Homo_sapiens GRCh37.75.reference : ftp://ftp.ensembl.org/pub/release-75/gtf/ As you can see, the genome data is from Ensembl, release 75 (as expected). Example 2: hg19 If you are looking for the hg19 genome, you can also search for the entry in snpEff.conf file: $ grep -i hg19.genome snpEff.config hg19.genome : Homo_sapiens (USCS) ... In this case, there is no hg19.reference entry, but the genome name clearly states that the database was retrieved from UCSC (having RefSeq). Which exact sub-version is this hg19? Well, unfortunately, UCSC does not keep track of sub-versions. A rule of the thumb is that the database is retrieved before it is built, so you can look at the date/time from the snpEff database: $ ls -al data/hg19/snpEffectPredictor.bin -rw-r--r-- 1 pcingola pcingola 52630202 Mar 19 08:27 data/hg19/snpEffectPredictor.bin So this hg19 database was retrieved from UCSC around on March 19th. Example 3: Salmonella_enterica Sometimes the information is in the genome's reference entry is not enough to determine which exact version was used, but the snpEff.config file provides some additional information in the comments For example, let's say we'd like to find the data source for Salmonella_enterica genome If we edit the snpEff.config and find the entry for Salmonella_enterica, we see something like this: Salmonella_enterica.genome : Salmonella_enterica Salmonella_enterica.reference : ftp.ensemblgenomes.org OK, it is from Ensembl, but which version? If you scroll up in the config file, you'll see a comment like this: #--- # ENSEMBL BFMPP release 32 #--- Here ENSEMBL BFMPP stands for Endembl Bacteria, Fungi, Metazoa, Plants and Protists. So the comment is indicating that this is Ensembl's release 32. Number of variants in VCF and HTML summary do not match First of all, SnpEff probably giving you the right numbers, the mismatch might not be a bug, but a simple interpretation issue. Counting variants / annotations It is important to remember that the VCF format specification allows having multiple variants in a single line. Also, a single variant can have more than one annotation, due to: Multiple transcripts (isoforms) of a gene (e.g. the human genome has on average 8.8 transcrips per gene) Multiple (overlapping) genes in the genomic location of the variant. A variant spanning multiple genes (e.g. a translocation, large deletion, etc.) When you count the number of variants, you must keep all these in mind to count them properly. Obviously, SnpEff does take all this into account when counting the variants for the summary HTML. Typical counting mistake Many people who claim that there is a mismatch between the number of variants in the summary (HTML) file and the number of variants in the VCF file, are just making mistakes when counting the variants because they forget one or more of these previous items. A typical scenario is, for example, that people are \"counting missense variants\" using something like this: grep missense file.vcf | wc -l This is counting \"lines in a VCF file that have at least one missense variants\" , as opposed to counting \"missense annotations\" and, as mentioned previously, the number of lines in a VCF file is not the same as the number of annotations or the number of variants. SnpEff taking too long Usually SnpEff runs within minutes. Unless you are analyzing extremely large files with thousands (or hundreds of thousands) of samples. But even in those cases SnpEff is efficient and it doesn't take too long. There are several things you should do to optimize: Run with \"-v\" option to check progress Use enough memory in your Java process (see \"How much memory should I use\" FAQ) You can disable the HTML report (command line option -noStats ). The report is usually quite time consuming, particularly if the number of samples in the VCF is large How much memory should I use How much memory to use is very specifcic to your project / application, but here are some guidelines: - Default 8 GB: Typically 8G of memory is enough for analyzing a human genome (i.e. `java -Xmx8G -jar snpEff.jar ... ~) - Medium 16 GB: It is rare that for single sample VCF file annotations more than 8G is required, but for some large genomes and/or VCF with too many samples, you might need more memory. - Very large 128GB: It is extremely uncommon for SnpEff to require over 128GB of RAM for annotating with SnpEff, but it might happen on very large projects. Multiple version of RefSeq transcripts When using RefSeq transcripts, for instance in the human genome versions hg38 or hg19 , can lead to some confusion due to multiply mapped transcripts. Example: NM_001135865.1 from hg38 From the original RefSeq data, you can see that there are actually four mappings of NM_001135865.1: # Note: Output edited for readbility $ zgrep NM_001135865.1 ~/snpEff/data/hg38/genes.refseq.gz 751 NM_001135865.1 chr16 - 21834582 21857657 21834717 21857378 11 ... 756 NM_001135865.1 chr16 + 22513522 22536520 22513801 22536385 7 ... 597 NM_001135865.1 chr16_KV880768v1_fix + 1679394 1702742 1679673 1702607 11 ... 589 NM_001135865.1 chr16_KV880768v1_fix - 568516 591514 568651 591235 7 ... Warning To make matters even worse, not only NM_001135865.1 maps twice to regions in chr16 , but also one is mapped in the forward strand and the other on the reverse strand (notice the + and - signs) How do you know which of the four NM_001135865.1 version is SnpEff refering to? When there are multiple mappings for a transcipt SnpEff will make sure each mapping is uniquely identified by appending a number to the original transcript ID. So the transcript IDs are named (notice that the first one is not changed): NM_001135865.1 NM_001135865.1.2 NM_001135865.1.3 NM_001135865.1.4 Even though they are mapped to different chromosomes and strands in chr16 , the protein sequence will be very similar (that's why RefSeq has multiple mappings of the same transcript). Info You can get details of each transcript using the SnpEff show command (e.g. java -jar snpEff.jar show ... ) We can analyse the difference, for instance NM_001135865.1 and NM_001135865.1.4 are mapped to chr16 . If you look at the protein sequences you'll notice that there is one small difference in amino acid 138 ('G' vs 'V'): $ java -jar snpEff.jar show NM_001135865.1 NM_001135865.1.4 | tee show.txt # Note: Output edited for readability # # Scroll right to see the difference ------>>> | AA 138 # | /Users/kqrw311/snpEff/issue_284$ | Showing genes and transcripts using zero-based coordinates | Transcript (codon table: Standard ) : 16:22513522-22536519, strand: +, id:NM_001135865.1, Protein, DNA check | ... | Protein : MVKLSIVLTPQFLSHDQGQLTKELQQHVKSVTCPCEYLRKVINTLADHHHRGTDFGGSPWLHVIIAFPTSYKVVITLWIVYLWVSLLKTIFWSRNGHDGSTDVQQRAWRSNRRRQEGLRSICMHTKKRVSSFRGNKIGLKDVITLRRHVETKVRAKIRKRKVTTKINHHDKINGKRKTARKQKMFQRAQELRRRAEDYHKCKIPPSARKALCNWVRMA... ... | NM_001135865.1 has a 'G' | Transcript (codon table: Standard ) : 16:21834582-21857656, strand: -, id:NM_001135865.1.4, Protein | ... | Protein : MVKLSIVLTPQFLSHDQGQLTKELQQHVKSVTCPCEYLRKVINTLADHHHRGTDFGGSPWLHVIIAFPTSYKVVITLWIVYLWVSLLKTIFWSRNGHDGSTDVQQRAWRSNRRRQEGLRSICMHTKKRVSSFRGNKIVLKDVITLRRHVETKVRAKIRKRKVTTKINHHDKINGKRKTARKQKMFQRAQELRRRAEDYHKCKIPPSARKALCNWVRMA... ... | NM_001135865.1.4 has a 'V'","title":"Frequently Asked Questions"},{"location":"se_faq/#snpeff-frequently-asked-questions","text":"","title":"SnpEff: Frequently Asked Questions"},{"location":"se_faq/#error-and-warning-messages","text":"SnpEff defines several messages in roughly 3 categories: INFO: An informative message WARNING: A problem in the reference genome definition that MAY result in an incorrect variant annotation ERROR: A problem in the reference genome definition that WILL ALMOST CERTAINLY result in an incorrect variant annotation INFO_REALIGN_3_PRIME The variant has been realigned to the most 3-prime position within the transcript. This is usually done to comply with HGVS specification to always report the most 3-prime annotation. While VCF requires to realign to the left-most of the reference genome, HGSV requires to realign to the most 3-prime. These two specifications are contradicting in some cases, so in order to comply with HGSV, sometimes a local realignment is required. IMPORTANT: This message is just indicating that a realignment was performed, so when this INFO message is present, the original coordinates from the VCF file are not exactly the same as the coordinates used to calculate the variant annotation WARNING_SEQUENCE_NOT_AVAILABLE The exon does not have reference sequence information. The annotation may not be calculated (e.g. incomplete transcripts). WARNING_REF_DOES_NOT_MATCH_GENOME The genome reference does not match the variant's reference. For example, if the VCF file indicates that the reference at a certain location is 'A', while SnpEff's database indicates that the reference should be 'C', this WARNING would be added. Under normal circumstances, there should be none of these warnings (or at most a handful). IMPORTANT: If too many of these warnings are seen, this indicates a severe problem (version mismatch between your VCF files and the reference genome). A typical case when too many of these warning are seen is when trying to annotate using a different genome than the one used for alignment (e.g. reads are aligned to hg19 but variants are annotated to using hg38) WARNING_TRANSCRIPT_INCOMPLETE The number of coding bases is NOT multiple of 3, so there is missing information for at least one codon. This indicates an error in the reference genome gene and/or transcript definition. This could happen in genomes that are not well understood. WARNING_TRANSCRIPT_MULTIPLE_STOP_CODONS Multiple STOP codons found in a CDS. There should be only one STOP codon at the end of the transcript, but in this case, the transcript has multiple STOP codons, which is unlikely to be real. This usually indicates an error on the reference genome (or database). Could for, for example, indicating frame errors in the reference genome for one or more exons in this transcript. WARNING_TRANSCRIPT_NO_START_CODON Start codon does not match any 'start' codon in the CodonTable. This usually indicates an error on the reference genome (or database) but could be also due to a misconfigured codon table for the genome. You should check that the codon table is properly set in snpEff.config WARNING_TRANSCRIPT_NO_STOP_CODON Stop codon does not match any 'stop' codon in the CodonTable. This usually indicates an error on the reference genome (or database) but could be also due to a misconfigured codon table for the genome. You should check that the codon table is properly set in snpEff.config ERROR_CHROMOSOME_NOT_FOUND Chromosome name not found. Typically due to mismatch in chromosome naming conventions between variants file and database, but can be a more several problems (different reference genome). See more details (here)[https://github.com/pcingola/SnpEff/wiki/ERROR_CHROMOSOME_NOT_FOUND] ERROR_OUT_OF_CHROMOSOME_RANGE Variant's genomic position is outside chromosome's range. Simple, the variant coordinate is outside the reference genome chromosome's length. IMPORTANT: If too many of these warnings are seen, this indicates a severe problem (version mismatch between your VCF files and the reference genome). A typical case when too many of these warning are seen is when trying to annotate using a different genome than the one used for alignment (e.g. reads are aligned to hg19 but variants are annotated to using hg38) ERROR_OUT_OF_EXON An exonic variant is falling outside the exon. ERROR_MISSING_CDS_SEQUENCE Missing coding sequence information. In this case, the full variant annotation cannot be calculated due to missing CDS information. This usually indicates an error on the reference genome (or database).","title":"Error and Warning messages"},{"location":"se_faq/#error_chromosome_not_found-details","text":"The error is due to a difference between the chromosome names in input VCF file and the chromosome names in SnpEff's database. Chromosome does not exist in the reference database. Typically this means that there is a mismatch between the chromosome names in your input file and the chromosome names used in the reference genome to build SnpEff's database. Warning This error could be caused because you are trying to annotate using a reference genome that is different than the one you used for sequence alignment. Obviously doing this makes no sense and the annotation information you'll get will be garbage. That's why SnpEff shows you an error message. Solution Sometimes SnpEff database matches the reference genome for your organism, and it's just that the chromosome names are changed. In this case, you can fix the error by changing the chromosome names in your input file. Info You can see the chromosome names used by SnpEff's database by using -v (verbose) option. SnpEff will show a line like this one: $ java -Xmx4g -jar snpEff.jar -v genomeName my.vcf > my.ann.vcf ... ... # Chromosomes names [sizes] : '1' [249250621] '2' [243199373] ... ... Info You can see the chromosome names in your input VCF file using a command like this one cat input.vcf | grep -v \"^#\" | cut -f 1 | uniq Once you know the names of the input file and the name used by SnpEff's database, you can adjust the chromosome name using a simple sed command. For example, if you input file's chromosome name is INPUT_CHR_NAME and the name in SnpEff's database is SNPEFF_CHR_NAME , you could use the following command: cat input.vcf | sed \"s/^INPUT_CHR_NAME/SNPEFF_CHR_NAME/\" > input_updated_chr.vcf","title":"ERROR_CHROMOSOME_NOT_FOUND: Details"},{"location":"se_faq/#how-to-building-an-ncbi-genome-genbank-file","text":"When building a database with SnpEff if your genomic reference is in NCBI, there is a script that might help you build the database. The script is buildDbNcbi.sh and is located in snpEff's scripts directory. It takes only one argument, which is the NCBI's ID. Example: Salmonella enterica In this example, we build the database for \"Salmonella enterica subsp. enterica serovar Typhi str. P-stx-12\" having accession ID CP003278.1 $ cd ~/snpEff # Note: Output edited for brevity $ ./scripts/buildDbNcbi.sh CP003278.1 Downloading genome CP003278.1 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 10.2M 0 10.2M 0 0 3627k 0 --:--:-- 0:00:02 --:--:-- 3627k 00:00:00 SnpEff version SnpEff 4.3p (build 2017-07-28 14:02), by Pablo Cingolani 00:00:00 Command: 'build' 00:00:00 Building database for 'CP003278.1' 00:00:00 Reading configuration file 'snpEff.config'. Genome: 'CP003278.1' 00:00:00 Reading config file: /home/pcingola/workspace/SnpEff/snpEff.config 00:00:00 done Chromosome: 'CP003278' length: 4768352 Create exons from CDS (if needed): .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. Exons created for 4690 transcripts. ... 00:00:01 Reading proteins from file '/home/pcingola/workspace/SnpEff/./data/CP003278.1/genes.gbk'... 00:00:01 done (4690 Proteins). 00:00:01 Comparing Proteins... Labels: '+' : OK '.' : Missing '*' : Error +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ... +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ Protein check: CP003278.1 OK: 4690 Not found: 0 Errors: 0 Error percentage: 0.0% 00:00:02 Saving database ... 00:00:04 Done.","title":"How to building an NCBI genome (GenBank file)"},{"location":"se_faq/#creating-a-protein-sequence-fasta-file","text":"SnpEff ann command has a command line option called -fastaProt that tells SnpEff to output the \"original\" and \"resulting\" protein sequences for each variant into a FASTA file. This means that for each variant, the output FASTA file will have an entry with protein sequence resulting from applying that variant to the reference sequence. Here is an example: $ cat z.vcf 1 889455 . G A . . . $ java -Xmx6g -jar snpEff.jar ann -fastaProt z.prot.fa hg19 z.vcf > z.ann.vcf The resulting fasta file z.prot.fa looks like this (lines edited for readibility): >NM_015658.3 Ref MAAAGSR...LLFGKVAKDSSRMLQPSSSPLWGKLRVDIKAYLGS... >NM_015658.3 Variant 1:889455-889455 Ref:G Alt:A HGVS.p:p.Gln236* MAAAGSR...LLFGKVAKDSSRML*PSSSPLWGKLRVDIKAYLGS...","title":"Creating a protein sequence FASTA file"},{"location":"se_faq/#genome-reference","text":"Having a standard reference sequence is the key to establish comparisons and analysis. In order to compare DNA from different individuals (or samples), we need a reference genome sequence and genomic annotations . Alignment and annotations must be based on the exact same reference genome sequence. Variants are called based on the reference genome, thus variant annotations must be performed using same reference genome. For instance, performing variant calling respect to hg19 and then performing variant annotations using hg38 genome, would result in completely erroneous results. Oftentimes lack of consistency between SnpEff annotations and genome coordinated from other data sources (e.g. a genome browser or other online databases) are due to the fact that there is a difference in genome reference versions. For example, maybe the VCF file was annotated using SnpEff's GRCh38.99 database, but you are looking at an hg38 genome browser (both reference are human, version 38, but different transcript versions).","title":"Genome reference"},{"location":"se_faq/#genome-reference-data-sources","text":"SnpEff genome databases are built from genomic data sources, such as Ensembl, RefSeq, NCBI, UCSC, etc. To find which data source was used, sometimes the information is provided in the snpEff.config file, under the genome_name.reference entry. Example 1: GRCh37.75 If you are looking for the GRCh37.75 genome, you can search for the entry in snpEff.conf file: $ grep -A 1 GRCh37.75 snpEff.config GRCh37.75.genome : Homo_sapiens GRCh37.75.reference : ftp://ftp.ensembl.org/pub/release-75/gtf/ As you can see, the genome data is from Ensembl, release 75 (as expected). Example 2: hg19 If you are looking for the hg19 genome, you can also search for the entry in snpEff.conf file: $ grep -i hg19.genome snpEff.config hg19.genome : Homo_sapiens (USCS) ... In this case, there is no hg19.reference entry, but the genome name clearly states that the database was retrieved from UCSC (having RefSeq). Which exact sub-version is this hg19? Well, unfortunately, UCSC does not keep track of sub-versions. A rule of the thumb is that the database is retrieved before it is built, so you can look at the date/time from the snpEff database: $ ls -al data/hg19/snpEffectPredictor.bin -rw-r--r-- 1 pcingola pcingola 52630202 Mar 19 08:27 data/hg19/snpEffectPredictor.bin So this hg19 database was retrieved from UCSC around on March 19th. Example 3: Salmonella_enterica Sometimes the information is in the genome's reference entry is not enough to determine which exact version was used, but the snpEff.config file provides some additional information in the comments For example, let's say we'd like to find the data source for Salmonella_enterica genome If we edit the snpEff.config and find the entry for Salmonella_enterica, we see something like this: Salmonella_enterica.genome : Salmonella_enterica Salmonella_enterica.reference : ftp.ensemblgenomes.org OK, it is from Ensembl, but which version? If you scroll up in the config file, you'll see a comment like this: #--- # ENSEMBL BFMPP release 32 #--- Here ENSEMBL BFMPP stands for Endembl Bacteria, Fungi, Metazoa, Plants and Protists. So the comment is indicating that this is Ensembl's release 32.","title":"Genome reference data sources"},{"location":"se_faq/#number-of-variants-in-vcf-and-html-summary-do-not-match","text":"First of all, SnpEff probably giving you the right numbers, the mismatch might not be a bug, but a simple interpretation issue. Counting variants / annotations It is important to remember that the VCF format specification allows having multiple variants in a single line. Also, a single variant can have more than one annotation, due to: Multiple transcripts (isoforms) of a gene (e.g. the human genome has on average 8.8 transcrips per gene) Multiple (overlapping) genes in the genomic location of the variant. A variant spanning multiple genes (e.g. a translocation, large deletion, etc.) When you count the number of variants, you must keep all these in mind to count them properly. Obviously, SnpEff does take all this into account when counting the variants for the summary HTML. Typical counting mistake Many people who claim that there is a mismatch between the number of variants in the summary (HTML) file and the number of variants in the VCF file, are just making mistakes when counting the variants because they forget one or more of these previous items. A typical scenario is, for example, that people are \"counting missense variants\" using something like this: grep missense file.vcf | wc -l This is counting \"lines in a VCF file that have at least one missense variants\" , as opposed to counting \"missense annotations\" and, as mentioned previously, the number of lines in a VCF file is not the same as the number of annotations or the number of variants.","title":"Number of variants in VCF and HTML summary do not match"},{"location":"se_faq/#snpeff-taking-too-long","text":"Usually SnpEff runs within minutes. Unless you are analyzing extremely large files with thousands (or hundreds of thousands) of samples. But even in those cases SnpEff is efficient and it doesn't take too long. There are several things you should do to optimize: Run with \"-v\" option to check progress Use enough memory in your Java process (see \"How much memory should I use\" FAQ) You can disable the HTML report (command line option -noStats ). The report is usually quite time consuming, particularly if the number of samples in the VCF is large","title":"SnpEff taking too long"},{"location":"se_faq/#how-much-memory-should-i-use","text":"How much memory to use is very specifcic to your project / application, but here are some guidelines: - Default 8 GB: Typically 8G of memory is enough for analyzing a human genome (i.e. `java -Xmx8G -jar snpEff.jar ... ~) - Medium 16 GB: It is rare that for single sample VCF file annotations more than 8G is required, but for some large genomes and/or VCF with too many samples, you might need more memory. - Very large 128GB: It is extremely uncommon for SnpEff to require over 128GB of RAM for annotating with SnpEff, but it might happen on very large projects.","title":"How much memory should I use"},{"location":"se_faq/#multiple-version-of-refseq-transcripts","text":"When using RefSeq transcripts, for instance in the human genome versions hg38 or hg19 , can lead to some confusion due to multiply mapped transcripts. Example: NM_001135865.1 from hg38 From the original RefSeq data, you can see that there are actually four mappings of NM_001135865.1: # Note: Output edited for readbility $ zgrep NM_001135865.1 ~/snpEff/data/hg38/genes.refseq.gz 751 NM_001135865.1 chr16 - 21834582 21857657 21834717 21857378 11 ... 756 NM_001135865.1 chr16 + 22513522 22536520 22513801 22536385 7 ... 597 NM_001135865.1 chr16_KV880768v1_fix + 1679394 1702742 1679673 1702607 11 ... 589 NM_001135865.1 chr16_KV880768v1_fix - 568516 591514 568651 591235 7 ... Warning To make matters even worse, not only NM_001135865.1 maps twice to regions in chr16 , but also one is mapped in the forward strand and the other on the reverse strand (notice the + and - signs) How do you know which of the four NM_001135865.1 version is SnpEff refering to? When there are multiple mappings for a transcipt SnpEff will make sure each mapping is uniquely identified by appending a number to the original transcript ID. So the transcript IDs are named (notice that the first one is not changed): NM_001135865.1 NM_001135865.1.2 NM_001135865.1.3 NM_001135865.1.4 Even though they are mapped to different chromosomes and strands in chr16 , the protein sequence will be very similar (that's why RefSeq has multiple mappings of the same transcript). Info You can get details of each transcript using the SnpEff show command (e.g. java -jar snpEff.jar show ... ) We can analyse the difference, for instance NM_001135865.1 and NM_001135865.1.4 are mapped to chr16 . If you look at the protein sequences you'll notice that there is one small difference in amino acid 138 ('G' vs 'V'): $ java -jar snpEff.jar show NM_001135865.1 NM_001135865.1.4 | tee show.txt # Note: Output edited for readability # # Scroll right to see the difference ------>>> | AA 138 # | /Users/kqrw311/snpEff/issue_284$ | Showing genes and transcripts using zero-based coordinates | Transcript (codon table: Standard ) : 16:22513522-22536519, strand: +, id:NM_001135865.1, Protein, DNA check | ... | Protein : MVKLSIVLTPQFLSHDQGQLTKELQQHVKSVTCPCEYLRKVINTLADHHHRGTDFGGSPWLHVIIAFPTSYKVVITLWIVYLWVSLLKTIFWSRNGHDGSTDVQQRAWRSNRRRQEGLRSICMHTKKRVSSFRGNKIGLKDVITLRRHVETKVRAKIRKRKVTTKINHHDKINGKRKTARKQKMFQRAQELRRRAEDYHKCKIPPSARKALCNWVRMA... ... | NM_001135865.1 has a 'G' | Transcript (codon table: Standard ) : 16:21834582-21857656, strand: -, id:NM_001135865.1.4, Protein | ... | Protein : MVKLSIVLTPQFLSHDQGQLTKELQQHVKSVTCPCEYLRKVINTLADHHHRGTDFGGSPWLHVIIAFPTSYKVVITLWIVYLWVSLLKTIFWSRNGHDGSTDVQQRAWRSNRRRQEGLRSICMHTKKRVSSFRGNKIVLKDVITLRRHVETKVRAKIRKRKVTTKINHHDKINGKRKTARKQKMFQRAQELRRRAEDYHKCKIPPSARKALCNWVRMA... ... | NM_001135865.1.4 has a 'V'","title":"Multiple version of RefSeq transcripts"},{"location":"se_human_genomes/","text":"Human Genomes There are several version of the human genome supported by SnpEff Here we explain the subtle differences between each version: Who is who Here is a brief explanation of who are the key releases of the Human Genome (all quotes are from their respective web sites, at the time I created this page): Ensembl : : - \u201cEnsembl creates, integrates and distributes reference datasets and analysis tools that enable genomics. We are based at EMBL-EBI (European Molecular Biology Laboratory, European Bioinformatics Institute)\u201d - \u201cEnsembl transcripts displayed on our website are products of the Ensembl automatic gene annotation system (a collection of gene annotation pipelines), termed the Ensembl annotation process. All Ensembl transcripts are based on experimental evidence and thus the automated pipeline relies on the mRNAs and protein sequences deposited into public databases from the scientific community. Manually-curated transcripts are produced by the HAVANA group.\u201d RefSeq: - Provided by NCBI (National Center for Biotechnology Information) - \u201cThe Reference Sequence (RefSeq) collection provides a comprehensive, integrated, non-redundant, well-annotated set of sequences, including genomic DNA, transcripts, and proteins\u201d Gencode : - \u201cThe goal of the GENCODE project is to identify and classify all gene features in the human and mouse genomes with high accuracy based on biological evidence, and to release these annotations for the benefit of biomedical research and genome interpretation.\u201d - \u201cThe GENCODE annotation is made by merging the manual gene annotation produced by the Ensembl-Havana team and the Ensembl-genebuild automated gene annotation. \u2026 The GENCODE releases coincide with the Ensembl releases\u2026. In practical terms, the GENCODE annotation is essentially identical to the Ensembl annotation.\u201d GRCh : Genome Reference Consortium (human) Human Genome versions Which Human genome version correspond to which genome names: GRCh38.mane.0.93.ensembl: Human genome GRCh38, using MANE transcripts v0.93, Ensembl IDs. See MANE below for details. GRCh38.mane.0.93.refseq: Human genome GRCh38, using MANE transcripts v0.93, RefSeq IDs. See MANE below for details. GRCh38. NN (e.g. GRCh38.104): These are genome annotations from ENSEMBL, created from GRCh38/hg38 reference genome sequence. GRCh37. NN (e.g. GRCh37.75): These are the genome annotations from ENSEMBL, created from GRCh37/hg19 reference genome sequence. WARNING: Ensembl stopped releasing genomes based on GRCh37/hg19 on February 2014. GRCh38.p NN (e.g. GRCh38.p13): These are RefSeq transcripts from NCBI mapped to GRCh38/hg38 reference genome sequence GRCh37.p NN (e.g. GRCh37.p13): These are RefSeq transcripts from NCBI mapped to GRCh38/hg19 reference genome sequence hg38: UCSC genome with RefSeq transcripts mapped to GRCh38/hg38 reference genome sequence hg19: UCSC genome with RefSeq transcripts mapped to GRCh37/hg19 reference genome sequence hg38kg: UCSC genome with KnownGenes transcripts mapped to GRCh38/hg38 reference genome sequence hg19kg: UCSC genome with KnownGenes transcripts mapped to GRCh37/hg19 reference genome sequence Important considerations There are some things you need to consider when looking at genomic variants results. Do not mix genome versions. It is important not to confuse different genome versions when comparing results. For example, if you use SnpEff to annotate variants using GRCh38.103 (from ENSEMBL) and then look at the variant using UCSC's genome browser (which uses RefSeq transcripts) there might be differences because your are using different transcripts set, thus the variant annotations may not match. Canonical is ill-defined: Everybody has a different definition of what a canonical transcript is (see details in the next section). HGSV requires realignment : HGVS \"sometimes\" recommends to shift the variants \"right\" respect to the transcript, whereas VCF specification requires to always shift left respect to he genome. This can catch off guard many scientist who are unaware of this side effect of using HGVS notation and wonder why the variant annotation software is reporting some variants as if they were aligned to \"another location\". In order to warn the users that such realignment occurred, an INFO_REALIGN_3_PRIME message is added to annotation in the VCF entry. Important considerations: RefSeq These are some considerations to keep in mind while working with RefSeq transcripts, this includes SnpEff genomes hg19, hg38, GRCh38.p13, GRCh37.p13, etc. RefSeq transcripts may NOT match the reference genome. This is a surprise for a lot of people, but RefSeq was designed as a consensus of transcript sequences as opposed as predicted from the reference genome. As a result a RefSeq transcript may not match the reference genome. RefSeq transcripts differ ~5% respect to the reference genome. This is a consequence of the previous item. Between 3% to 7% of the transcripts in RefSeq do not exactly match the reference genome, thus the proteins inferred from the genomic CDSs sequences are different than the \"real\" RefSeq CDS sequences. Most of the time, the difference (if any) is only one amino acid in the whole protein, but sometimes the difference is much larger. Variant annotations using RefSeq may not be precise at the exact loci where the RefSeq transcript doesn't match the genome reference. This is yet another consequence of the previous items, but since the transcript do not match the reference genome, and variant annotations are based on the reference genome, the variant annotaion predictions might be off at those genomic loci. NCBI's gene IDs are just gene names, simetime with '_1', '_2', ..., etc. Gene IDs from NCBI genomes (e.g. GRCh38.p13) are just gene names. If a gene is mapped to multiple genomic loci, then the same gene name is used and string is added to make it unique ('_1', for the first duplicate, '_2' for the second and so on). For example, here are the gene IDs for gene 'KIR3DL3' (note the last line is 'KIR3DL3_46', so there are 47 loci for this gene): # Note: Results edited for readability $ grep \"gene\\t\" GCF_000001405.39_GRCh38.p13_genomic.gtf | grep KIR3DL3 NC_000019.10 BestRefSeq gene 54724442 54736632 . + . gene_id \"KIR3DL3\"; ... NW_016107300.1 BestRefSeq gene 26066 38262 . + . gene_id \"KIR3DL3_1\"; ... NW_016107301.1 BestRefSeq gene 26066 38253 . + . gene_id \"KIR3DL3_2\"; ... NW_016107302.1 BestRefSeq gene 26075 38226 . + . gene_id \"KIR3DL3_3\"; ... NW_016107303.1 BestRefSeq gene 26066 38222 . + . gene_id \"KIR3DL3_4\"; ... NW_016107304.1 BestRefSeq gene 26066 38255 . + . gene_id \"KIR3DL3_5\"; ... NW_016107305.1 BestRefSeq gene 26072 38219 . + . gene_id \"KIR3DL3_6\"; ... ... NT_187686.1 BestRefSeq gene 177446 189666 . - . gene_id \"KIR3DL3_44\"; ... NT_187687.1 BestRefSeq gene 132277 144472 . - . gene_id \"KIR3DL3_45\"; ... NT_113949.2 BestRefSeq gene 139138 151310 . - . gene_id \"KIR3DL3_46\"; ... UCSC transcripts (hg19/hg38) are not unique. Transcript IDs might not be unique. Many assume that IDs are unique, but this is not always true to UCSC's genomic files. A UCSC transcripts (hg19/hg38) can map to multiple loci. A transcript from hg19/hg39 can map to multiple genomic loci, this is a consequence of transcripts IDs not being unique. For example, transcript NR_110738.1 is mapped to 123 loci: $ cat hg38.refseq | cut -f 2 | sort | uniq -c | sort -rn | head 123 NR_110738.1 92 NR_110737.1 92 NM_014218.3 91 NM_001368251.1 71 NM_001281972.2 54 NM_001291696.1 54 NM_001281971.2 53 NM_014513.2 53 NM_001360171.1 52 NM_014512.1 Canonical transcripts You need to be careful because the definition of \"Canonical trnascript\" changes for each data source and sometimes for each genome version. The definition used by SnpEff is: \u201cThe canonical transcript is defined as either the longest CDS, if the gene has translated transcripts, or the longest cDNA.\u201d (Ref: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2686571) Just to show that there are subtle differences, here some of the definitions Canonical from some prominent genomic sources: Ensembl (Ref: http://useast.ensembl.org/Help/Glossary) Longest CCDS translation with no stop codons longest Ensembl/Havana merged translation with no stop codons longest translation with no stop codons. If no translation, choose the longest non-protein-coding transcript. Note: \u201c\u2026does not necessarily reflect the most biologically relevant transcript of a gene\u201d UCSC (Ref: https://genome.ucsc.edu/FAQ/FAQgenes.html) hg19: \u201cGenerally, this is the longest isoform.\u201d hg38: \u201cThe canonical transcript is chosen using the APPRIS principal transcript when available. If no APPRIS tag exists for any transcript associated with the cluster, then a transcript in the BASIC set is chosen. If no BASIC transcript exists, then the longest isoform is used\u201d. UniProt (Ref: https://www.uniprot.org/help/canonical_and_isoforms) It is the most prevalent. It is the most similar to orthologous sequences found in other species. By virtue of its length or amino acid composition, it allows the clearest description of domains, isoforms, genetic variation, post-translational modifications, etc. In the absence of any information, we choose the longest sequence. As you can see these definitions do not match and obviously these differences could affect your analysis. MANE MANE stands for \"Matched Annotation from NCBI and EMBL-EBI\". Both NCBI and ENSEMBL have been joining efforts in this new initiative to provide a joint transcript set compatible with both. MANE started in 2018, to converge into a common set of transcripts that has desirable characteristics: contains one well-supported transcript per protein-coding locus, perfectly align to the reference genome, has 100\\% match between RefSeq and ENSEMBL (including coding sequence and UTRs), has been manually curated by both groups, is versioned and largely stable. includes additional transcripts (i.e. more than one per gene) required to report variants of clinical interest, and will become the default transcripts shown in Genome Browsers. As of this writing, version 0.93 was released in January 2021. Furthermore, the upcoming ENSEMBL release 104 is expected to switch the definition of \"Canonical Transcript\" to favor MANE transcripts. References: https://www.ncbi.nlm.nih.gov/refseq/MANE/ https://www.ensembl.info/tag/mane/ https://useast.ensembl.org/info/genome/genebuild/mane.html","title":"Human Genomes"},{"location":"se_human_genomes/#human-genomes","text":"There are several version of the human genome supported by SnpEff Here we explain the subtle differences between each version:","title":"Human Genomes"},{"location":"se_human_genomes/#who-is-who","text":"Here is a brief explanation of who are the key releases of the Human Genome (all quotes are from their respective web sites, at the time I created this page): Ensembl : : - \u201cEnsembl creates, integrates and distributes reference datasets and analysis tools that enable genomics. We are based at EMBL-EBI (European Molecular Biology Laboratory, European Bioinformatics Institute)\u201d - \u201cEnsembl transcripts displayed on our website are products of the Ensembl automatic gene annotation system (a collection of gene annotation pipelines), termed the Ensembl annotation process. All Ensembl transcripts are based on experimental evidence and thus the automated pipeline relies on the mRNAs and protein sequences deposited into public databases from the scientific community. Manually-curated transcripts are produced by the HAVANA group.\u201d RefSeq: - Provided by NCBI (National Center for Biotechnology Information) - \u201cThe Reference Sequence (RefSeq) collection provides a comprehensive, integrated, non-redundant, well-annotated set of sequences, including genomic DNA, transcripts, and proteins\u201d Gencode : - \u201cThe goal of the GENCODE project is to identify and classify all gene features in the human and mouse genomes with high accuracy based on biological evidence, and to release these annotations for the benefit of biomedical research and genome interpretation.\u201d - \u201cThe GENCODE annotation is made by merging the manual gene annotation produced by the Ensembl-Havana team and the Ensembl-genebuild automated gene annotation. \u2026 The GENCODE releases coincide with the Ensembl releases\u2026. In practical terms, the GENCODE annotation is essentially identical to the Ensembl annotation.\u201d GRCh : Genome Reference Consortium (human)","title":"Who is who"},{"location":"se_human_genomes/#human-genome-versions","text":"Which Human genome version correspond to which genome names: GRCh38.mane.0.93.ensembl: Human genome GRCh38, using MANE transcripts v0.93, Ensembl IDs. See MANE below for details. GRCh38.mane.0.93.refseq: Human genome GRCh38, using MANE transcripts v0.93, RefSeq IDs. See MANE below for details. GRCh38. NN (e.g. GRCh38.104): These are genome annotations from ENSEMBL, created from GRCh38/hg38 reference genome sequence. GRCh37. NN (e.g. GRCh37.75): These are the genome annotations from ENSEMBL, created from GRCh37/hg19 reference genome sequence. WARNING: Ensembl stopped releasing genomes based on GRCh37/hg19 on February 2014. GRCh38.p NN (e.g. GRCh38.p13): These are RefSeq transcripts from NCBI mapped to GRCh38/hg38 reference genome sequence GRCh37.p NN (e.g. GRCh37.p13): These are RefSeq transcripts from NCBI mapped to GRCh38/hg19 reference genome sequence hg38: UCSC genome with RefSeq transcripts mapped to GRCh38/hg38 reference genome sequence hg19: UCSC genome with RefSeq transcripts mapped to GRCh37/hg19 reference genome sequence hg38kg: UCSC genome with KnownGenes transcripts mapped to GRCh38/hg38 reference genome sequence hg19kg: UCSC genome with KnownGenes transcripts mapped to GRCh37/hg19 reference genome sequence","title":"Human Genome versions"},{"location":"se_human_genomes/#important-considerations","text":"There are some things you need to consider when looking at genomic variants results. Do not mix genome versions. It is important not to confuse different genome versions when comparing results. For example, if you use SnpEff to annotate variants using GRCh38.103 (from ENSEMBL) and then look at the variant using UCSC's genome browser (which uses RefSeq transcripts) there might be differences because your are using different transcripts set, thus the variant annotations may not match. Canonical is ill-defined: Everybody has a different definition of what a canonical transcript is (see details in the next section). HGSV requires realignment : HGVS \"sometimes\" recommends to shift the variants \"right\" respect to the transcript, whereas VCF specification requires to always shift left respect to he genome. This can catch off guard many scientist who are unaware of this side effect of using HGVS notation and wonder why the variant annotation software is reporting some variants as if they were aligned to \"another location\". In order to warn the users that such realignment occurred, an INFO_REALIGN_3_PRIME message is added to annotation in the VCF entry.","title":"Important considerations"},{"location":"se_human_genomes/#important-considerations-refseq","text":"These are some considerations to keep in mind while working with RefSeq transcripts, this includes SnpEff genomes hg19, hg38, GRCh38.p13, GRCh37.p13, etc. RefSeq transcripts may NOT match the reference genome. This is a surprise for a lot of people, but RefSeq was designed as a consensus of transcript sequences as opposed as predicted from the reference genome. As a result a RefSeq transcript may not match the reference genome. RefSeq transcripts differ ~5% respect to the reference genome. This is a consequence of the previous item. Between 3% to 7% of the transcripts in RefSeq do not exactly match the reference genome, thus the proteins inferred from the genomic CDSs sequences are different than the \"real\" RefSeq CDS sequences. Most of the time, the difference (if any) is only one amino acid in the whole protein, but sometimes the difference is much larger. Variant annotations using RefSeq may not be precise at the exact loci where the RefSeq transcript doesn't match the genome reference. This is yet another consequence of the previous items, but since the transcript do not match the reference genome, and variant annotations are based on the reference genome, the variant annotaion predictions might be off at those genomic loci. NCBI's gene IDs are just gene names, simetime with '_1', '_2', ..., etc. Gene IDs from NCBI genomes (e.g. GRCh38.p13) are just gene names. If a gene is mapped to multiple genomic loci, then the same gene name is used and string is added to make it unique ('_1', for the first duplicate, '_2' for the second and so on). For example, here are the gene IDs for gene 'KIR3DL3' (note the last line is 'KIR3DL3_46', so there are 47 loci for this gene): # Note: Results edited for readability $ grep \"gene\\t\" GCF_000001405.39_GRCh38.p13_genomic.gtf | grep KIR3DL3 NC_000019.10 BestRefSeq gene 54724442 54736632 . + . gene_id \"KIR3DL3\"; ... NW_016107300.1 BestRefSeq gene 26066 38262 . + . gene_id \"KIR3DL3_1\"; ... NW_016107301.1 BestRefSeq gene 26066 38253 . + . gene_id \"KIR3DL3_2\"; ... NW_016107302.1 BestRefSeq gene 26075 38226 . + . gene_id \"KIR3DL3_3\"; ... NW_016107303.1 BestRefSeq gene 26066 38222 . + . gene_id \"KIR3DL3_4\"; ... NW_016107304.1 BestRefSeq gene 26066 38255 . + . gene_id \"KIR3DL3_5\"; ... NW_016107305.1 BestRefSeq gene 26072 38219 . + . gene_id \"KIR3DL3_6\"; ... ... NT_187686.1 BestRefSeq gene 177446 189666 . - . gene_id \"KIR3DL3_44\"; ... NT_187687.1 BestRefSeq gene 132277 144472 . - . gene_id \"KIR3DL3_45\"; ... NT_113949.2 BestRefSeq gene 139138 151310 . - . gene_id \"KIR3DL3_46\"; ... UCSC transcripts (hg19/hg38) are not unique. Transcript IDs might not be unique. Many assume that IDs are unique, but this is not always true to UCSC's genomic files. A UCSC transcripts (hg19/hg38) can map to multiple loci. A transcript from hg19/hg39 can map to multiple genomic loci, this is a consequence of transcripts IDs not being unique. For example, transcript NR_110738.1 is mapped to 123 loci: $ cat hg38.refseq | cut -f 2 | sort | uniq -c | sort -rn | head 123 NR_110738.1 92 NR_110737.1 92 NM_014218.3 91 NM_001368251.1 71 NM_001281972.2 54 NM_001291696.1 54 NM_001281971.2 53 NM_014513.2 53 NM_001360171.1 52 NM_014512.1","title":"Important considerations: RefSeq"},{"location":"se_human_genomes/#canonical-transcripts","text":"You need to be careful because the definition of \"Canonical trnascript\" changes for each data source and sometimes for each genome version. The definition used by SnpEff is: \u201cThe canonical transcript is defined as either the longest CDS, if the gene has translated transcripts, or the longest cDNA.\u201d (Ref: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2686571) Just to show that there are subtle differences, here some of the definitions Canonical from some prominent genomic sources: Ensembl (Ref: http://useast.ensembl.org/Help/Glossary) Longest CCDS translation with no stop codons longest Ensembl/Havana merged translation with no stop codons longest translation with no stop codons. If no translation, choose the longest non-protein-coding transcript. Note: \u201c\u2026does not necessarily reflect the most biologically relevant transcript of a gene\u201d UCSC (Ref: https://genome.ucsc.edu/FAQ/FAQgenes.html) hg19: \u201cGenerally, this is the longest isoform.\u201d hg38: \u201cThe canonical transcript is chosen using the APPRIS principal transcript when available. If no APPRIS tag exists for any transcript associated with the cluster, then a transcript in the BASIC set is chosen. If no BASIC transcript exists, then the longest isoform is used\u201d. UniProt (Ref: https://www.uniprot.org/help/canonical_and_isoforms) It is the most prevalent. It is the most similar to orthologous sequences found in other species. By virtue of its length or amino acid composition, it allows the clearest description of domains, isoforms, genetic variation, post-translational modifications, etc. In the absence of any information, we choose the longest sequence. As you can see these definitions do not match and obviously these differences could affect your analysis.","title":"Canonical transcripts"},{"location":"se_human_genomes/#mane","text":"MANE stands for \"Matched Annotation from NCBI and EMBL-EBI\". Both NCBI and ENSEMBL have been joining efforts in this new initiative to provide a joint transcript set compatible with both. MANE started in 2018, to converge into a common set of transcripts that has desirable characteristics: contains one well-supported transcript per protein-coding locus, perfectly align to the reference genome, has 100\\% match between RefSeq and ENSEMBL (including coding sequence and UTRs), has been manually curated by both groups, is versioned and largely stable. includes additional transcripts (i.e. more than one per gene) required to report variants of clinical interest, and will become the default transcripts shown in Genome Browsers. As of this writing, version 0.93 was released in January 2021. Furthermore, the upcoming ENSEMBL release 104 is expected to switch the definition of \"Canonical Transcript\" to favor MANE transcripts. References: https://www.ncbi.nlm.nih.gov/refseq/MANE/ https://www.ensembl.info/tag/mane/ https://useast.ensembl.org/info/genome/genebuild/mane.html","title":"MANE"},{"location":"se_inputoutput/","text":"Input & output files Files used as input to SnpEff must comply with standard formats. Here we describe supported input data formats. VCF files As we mentioned before, Variant Call Format (VCF) is the recommended format for input files. This is the format used by the \"1000 Genomes Project\", and is currently considered the de facto standard for genomic variants. It is also the default format used in SnpEff. In a nutshell, VCF format is tab-separated text file having the following columns: Chromosome name Position Variant's ID Reference genome Alternative (i.e. variant) Quality score Filter (whether or not the variant passed quality filters) INFO : Generic information about this variant. SnpEff adds annotation information in this column. Here is an example of a few lines in a VCF file: #CHROM POS ID REF ALT QUAL FILTER INFO 20 14370 rs6054257 G A 29 PASS NS=3;DP=14;AF=0.5;DB;H2 20 17330 . T A 3 q10 NS=3;DP=11;AF=0.017 Note that the first line is header information. Header lines start with '#' VCF output As we mentioned in the previous chapter, VCF is SnpEff's default input and output format. It is highly recommended to use VCF as input and output format, since it is a standard format that can be also used by other tools and software packages. Thus VCF makes it much easier to integrate genomic data processing pipelines. SnpEff adds annotation information to the INFO field of a VCF file. The INFO field is the eight column of a VCF file, see previous section for a quick example or take a look at the VCF specification for details. Here is an example of a file before and after being annotated using SnpEff: VCF file before annotations #CHROM POS ID REF ALT QUAL FILTER INFO 1 889455 . G A 100.0 PASS AF=0.0005 1 897062 . C T 100.0 PASS AF=0.0005 VCF file after being annotated using SnpEff #CHROM POS ID REF ALT QUAL FILTER INFO 1 889455 . G A 100.0 PASS AF=0.0005;EFF=STOP_GAINED(HIGH|NONSENSE|Cag/Tag|Q236*|749|NOC2L||CODING|NM_015658|) 1 897062 . C T 100.0 PASS AF=0.0005;EFF=STOP_GAINED(HIGH|NONSENSE|Cag/Tag|Q141*|642|KLHL17||CODING|NM_198317|) A you can see, SnpEff added an 'EFF' tag to the INFO field (eight column). VCF Header lines SnpEff updates the header of the VCF file to reflect additional fields. This is required by the VCF specification. SnpEff also adds the command line options used to annotate the file as well as SnpEff's version, so you can keep track of what exactly was done. Here is an example of some header lines added to an annotated file: ##SnpEffVersion=\"SnpEff 3.1m (build 2013-02-08)\" ##SnpEffCmd=\"SnpEff hg19 demo.1kg.vcf \" ##INFO=<ID=EFF,Number=.,Type=String,Description=\"Predicted effects for this variant.Format: 'Effect ( Effect_Impact | Functional_Class | Codon_Change | Amino_Acid_change| Amino_Acid_length | Gene_Name | Gene_BioType | Coding | Transcript | Exon [ | ERRORS | WARNINGS ] )' \\\"> ANN field (VCF output files) Functional annotations information is added to the INFO field using an ANN tag. NOTE: field. SnpEff implements the VCF annotation standard 'ANN' field. This format specification has been created by the developers of the most widely used variant annotation programs (SnpEff, ANNOVAR and ENSEMBL's VEP) and attempts to: provide a common framework for variant annotation, make pipeline development easier, facilitate benchmarking, and improve some known problems in variant annotations. Obviously this 'ANN' field broke compatibility with the old 'EFF' field from old SnpEff versions. In order to use the old 'EFF' field, you can use the -formatEff command line option. The annotation 'ANN' field looks like this (the full annotation standard specification can be found here ). ANN=T|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.1406G>A|p.Gly469Glu|1666/2034|1406/1674|469/557||,T|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397G>A|||||3944| A variant can have (and usually has) more than one annotation. Multiple annotations are separated by commas. In the previous example there were two annotations corresponding to different genes (CCT8L2 and FABP5P11). Each annotation consists of multiple sub-fields separated by the pipe character \"|\" (fields 15 and 16 are empty in this example): Annotation : T|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.1406G>A|p.Gly469Glu|1666/2034|1406/1674|469/557| | SubField number : 1| 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 |15| 16 Here is a description of the meaning of each sub-field: Allele (or ALT): In case of multiple ALT fields, this helps to identify which ALT we are referring to. E.g.: # CHROM POS ID REF ALT QUAL FILTER INFO chr1 123456 . C A . . ANN=A|... chr1 234567 . A G,T . . ANN=G|... , T|... In case of cancer sample, when comparing somatic versus germline using a non-standard reference (e.g. one of the ALTs is the reference) the format should be ALT-REFERENCE. E.g.: #CHROM POS ID REF ALT QUAL FILTER INFO chr1 123456 . A C,G . . ANN=G-C|... Compound variants: two or more variants affecting the annotations (e.g. two consecutive SNPs conforming a MNP, two consecutive frame_shift variants that \"recover\" the frame). In this case, the Allele field should include a reference to the other variant/s included in the annotation: #CHROM POS ID REF ALT QUAL FILTER INFO chr1 123456 . A T . . ANN=T|... chr1 123457 . C G . . ANN=C-chr1:123456_A>T|... Annotation (a.k.a. effect): Annotated using Sequence Ontology terms. Multiple effects can be concatenated using '&'. #CHROM POS ID REF ALT QUAL FILTER INFO chr1 123456 . C A . . ANN=A|intron_variant&nc_transcript_variant|... Putative_impact: A simple estimation of putative impact / deleteriousness : {HIGH, MODERATE, LOW, MODIFIER} Gene Name: Common gene name (HGNC). Optional: use closest gene when the variant is \"intergenic\". Gene ID: Gene ID Feature type: Which type of feature is in the next field (e.g. transcript, motif, miRNA, etc.). It is preferred to use Sequence Ontology (SO) terms, but 'custom' (user defined) are allowed. ANN=A|stop_gained|HIGH|||transcript|... Tissue specific features may include cell type / tissue information separated by semicolon e.g.: ANN=A|histone_binding_site|LOW|||H3K4me3:HeLa-S3| Feature ID: Depending on the annotation, this may be: Transcript ID (preferably using version number), Motif ID, miRNA, ChipSeq peak, Histone mark, etc. Note: Some features may not have ID (e.g. histone marks from custom Chip-Seq experiments may not have a unique ID). Transcript biotype: The bare minimum is at least a description on whether the transcript is {\"Coding\", \"Noncoding\"}. Whenever possible, use ENSEMBL biotypes. Rank / total: Exon or Intron rank / total number of exons or introns. HGVS.c: Variant using HGVS notation (DNA level) HGVS.p: If variant is coding, this field describes the variant using HGVS notation (Protein level). Since transcript ID is already mentioned in 'feature ID', it may be omitted here. cDNA_position / cDNA_len: Position in cDNA and trancript's cDNA length (one based). CDS_position / CDS_len: Position and number of coding bases (one based includes START and STOP codons). Protein_position / Protein_len: Position and number of AA (one based, including START, but not STOP). Distance to feature: All items in this field are options, so the field could be empty. Up/Downstream: Distance to first / last codon Intergenic: Distance to closest gene Distance to closest Intron boundary in exon (+/- up/downstream). If same, use positive number. Distance to closest exon boundary in Intron (+/- up/downstream) Distance to first base in MOTIF Distance to first base in miRNA Distance to exon-intron boundary in splice_site or splice _region ChipSeq peak: Distance to summit (or peak center) Histone mark / Histone state: Distance to summit (or peak center) Errors, Warnings or Information messages: Add errors, warnings or informative message that can affect annotation accuracy. It can be added using either 'codes' (as shown in column 1, e.g. W1) or 'message types' (as shown in column 2, e.g. WARNING_REF_DOES_NOT_MATCH_GENOME). All these errors, warnings or information messages messages are optional. Code Message type Description / Notes E1 ERROR_CHROMOSOME_NOT_FOUND Chromosome does not exists in reference genome database. Typically indicates a mismatch between the chromosome names in the input file and the chromosome names used in the reference genome. E2 ERROR_OUT_OF_CHROMOSOME_RANGE The variant's genomic coordinate is greater than chromosome's length. W1 WARNING_REF_DOES_NOT_MATCH_GENOME This means that the 'REF' field in the input VCF file does not match the reference genome. This warning may indicate a conflict between input data and data from reference genome (for instance is the input VCF was aligned to a different reference genome). W2 WARNING_SEQUENCE_NOT_AVAILABLE Reference sequence is not available, thus no inference could be performed. W3 WARNING_TRANSCRIPT_INCOMPLETE A protein coding transcript having a non-multiple of 3 length. It indicates that the reference genome has missing information about this particular transcript. W4 WARNING_TRANSCRIPT_MULTIPLE_STOP_CODONS A protein coding transcript has two or more STOP codons in the middle of the coding sequence (CDS). This should not happen and it usually means the reference genome may have an error in this transcript. W5 WARNING_TRANSCRIPT_NO_START_CODON A protein coding transcript does not have a proper START codon. It is rare that a real transcript does not have a START codon, so this probably indicates an error or missing information in the reference genome. I1 INFO_REALIGN_3_PRIME Variant has been realigned to the most 3-prime position within the transcript. This is usually done to to comply with HGVS specification to always report the most 3-prime annotation. I2 INFO_COMPOUND_ANNOTATION This effect is a result of combining more than one variants (e.g. two consecutive SNPs that conform an MNP, or two consecutive frame_shift variants that compensate frame). I3 INFO_NON_REFERENCE_ANNOTATION An alternative reference sequence was used to calculate this annotation (e.g. cancer sample comparing somatic vs. germline). Consistency between HGVS and functional annotations: In some cases there might be inconsistent reporting between 'annotation' and HGVS. This is due to the fact that VCF recommends aligning to the leftmost coordinate, whereas HGSV recommends aligning to the \"most 3-prime coordinate\". For instance, an InDel on the edge of an exon, which has an 'intronic' annotation according to VCF alignment recommendation, can lead to a 'stop_gained' when aligned using HGVS's recommendation (using the most 3-prime possible alignment). So the 'annotation' sub-field will report 'intron' whereas HGVS sub-field will report a 'stop_gained'. This is obviously inconsistent and must be avoided. In order to report annotations that are consistent with HGVS notation, variants must be re-aligned according to each transcript's strand (i.e. align the variant according to the transcript's most 3-prime coordinate). Then annotations are calculated, thus the reported annotations will be consistent with HGVS notation. Annotation software should have a command line option to override this behaviour (e.g. -no_shift_hgvs ) EFF field (VCF output files) Effects information is added to the INFO field using an 'EFF' tag. Warning This section refers the obsolete annotation format using the 'EFF' tag which can be activated using the -formatEff command line option. As of version 4.1 SnpEff uses the 'ANN' field by default. Notes: As of version 4.0, the default output uses Sequence Ontology for 'Effect' names. You can output \"old\" style effect names by using the -classic command line option. When multiple effects are available, they are sorted first by \"Effect_Impact\", then by \"Effect\" and finally by \"marker's genomic coordinates\" (e.g. affected transcript's genomic coordinates). Staring from version 4.0, SnpEff outputs HGVS notation in the 'AA' sub-field by default. There can be multiple effects separated by comma. The format for each effect is: EFF= Effect ( Effect_Impact | Functional_Class | Codon_Change | Amino_Acid_Change| Amino_Acid_Length | Gene_Name | Transcript_BioType | Gene_Coding | Transcript_ID | Exon_Rank | Genotype_Number [ | ERRORS | WARNINGS ] ) EFF Sub-field Meaning Effect Effect of this variant. See details here . Effect impact Effect impact {High, Moderate, Low, Modifier}. See details here . Functional Class Functional class {NONE, SILENT, MISSENSE, NONSENSE}. Codon_Change / Distance Codon change: old_codon/new_codon OR distance to transcript (in case of upstream / downstream) Amino_Acid_Change Amino acid change: old_AA AA_position/new_AA (e.g. 'E30K') Amino_Acid_Length Length of protein in amino acids (actually, transcription length divided by 3). Gene_Name Gene name Transcript_BioType Transcript bioType, if available. Gene_Coding [CODING | NON_CODING] . This field is 'CODING' if any transcript of the gene is marked as protein coding. Transcript_ID Transcript ID (usually ENSEMBL IDs) Exon/Intron Rank Exon rank or Intron rank (e.g. '1' for the first exon, '2' for the second exon, etc.) Genotype_Number Genotype number corresponding to this effect (e.g. '2' if the effect corresponds to the second ALT) Warnings / Errors Any warnings or errors (not shown if empty). Multiple annotations per VCF line Usually there is more than one annotation reported in each ANN (or EFF ) field. There are several reasons for this: A variant can affect multiple genes. E.g a variant can be DOWNSTREAM from one gene and UPSTREAM from another gene. E.g.: In complex organisms, genes usually have multiple transcripts. So SnpEff reports the effect of a variant on each transcript. E.g.: #CHROM POS ID REF ALT QUAL FILTER INFO 1 889455 . G A . . . In this case SnpEff will report the effect of each variant on each gene and each transcript (output edited for readability): #CHROM POS ID REF ALT QUAL FILTER INFO 1 889455 . G A . . ANN=A|stop_gained|HIGH|NOC2L|ENSG00000188976|transcript|ENST00000327044|protein_coding|7/19|c.706C>T|p.Gln236*|756/2790|706/2250|236/749|| ,A|downstream_gene_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000487214|processed_transcript||n.*865C>T|||||351| ,A|downstream_gene_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000469563|retained_intron||n.*878C>T|||||4171| ,A|non_coding_exon_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000477976|retained_intron|5/17|n.2153C>T||||||;LOF=(NOC2L|ENSG00000188976|6|0.17);NMD=(NOC2L|ENSG00000188976|6|0.17) A VCF line can have more then one variant. E.g. If reference genome is 'G', but the sample has either 'A' or 'T' (non-biallelic variant), then this will be reported as one VCF line, having multiple alternative variants (notice that there are two ALTs): #CHROM POS ID REF ALT QUAL FILTER INFO 1 889455 . G A,T . . . In this case SnpEff will report the effect of each ALT on each gene and each transcript. Notice that ENST00000327044 has a stop_gained variant (ALT = 'A') and a missense_variant (ALT = 'T') #CHROM POS ID REF ALT QUAL FILTER INFO 1 889455 . G A,T . . ANN=A|stop_gained|HIGH|NOC2L|ENSG00000188976|transcript|ENST00000327044|protein_coding|7/19|c.706C>T|p.Gln236*|756/2790|706/2250|236/749|| ,T|missense_variant|MODERATE|NOC2L|ENSG00000188976|transcript|ENST00000327044|protein_coding|7/19|c.706C>A|p.Gln236Lys|756/2790|706/2250|236/749|| ,A|downstream_gene_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000487214|processed_transcript||n.*865C>T|||||351| ,T|downstream_gene_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000487214|processed_transcript||n.*865C>A|||||351| ,A|downstream_gene_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000469563|retained_intron||n.*878C>T|||||4171| ,T|downstream_gene_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000469563|retained_intron||n.*878C>A|||||4171| ,A|non_coding_exon_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000477976|retained_intron|5/17|n.2153C>T|||||| ,T|non_coding_exon_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000477976|retained_intron|5/17|n.2153C>A||||||;LOF=(NOC2L|ENSG00000188976|6|0.17);NMD=(NOC2L|ENSG00000188976|6|0. Effect sort order . When multiple effects are reported, SnpEff sorts the effects the following way: Putative impact: Effects having higher putative impact are first. Effect type: Effects assumed to be more deleterious effects first. Canonical transcript before non-canonical. Marker genomic coordinates (e.g. genes starting before first). Effect prediction details Detailed description of the effect predicted by SnpEff in the Effect and Effect_Impact sub-fields. Notes: Effect (Sequence Ontology) Sequence ontology ( SO ) allows to standardize terminology used for assessing sequence changes and impact. This allows for a common language across all variant annotation programs and makes it easier to communicate using a uniform terminology. Starting from version 4.0 VCF output uses SO terms by default. Effect (Classic) This are the \"classic\" effect names usd by SnpEff, these can be accessed using the -classic command line option. Effect impact Effects are categorized by 'impact': {High, Moderate, Low, Modifier}. This are pre-defined categories to help users find more significant variants. Warning Impact categories must be used with care, they were created only to help and simplify the filtering process. Obviously, there is no way to predict whether a \"high impact\" or a \"low impact\" variant is the one producing a phenotype of interest. Here is a list of effects and some brief explanations: Effect Seq. Ontology Effect Classic Note & Example Impact coding_sequence_variant CDS The variant hits a CDS. MODIFIER chromosome CHROMOSOME_LARGE DELETION A large parte (over 1%) of the chromosome was deleted. HIGH duplication CHROMOSOME_LARGE_DUPLICATION Duplication of a large chromosome segment (over 1% or 1,000,000 bases) HIGH inversion CHROMOSOME_LARGE_INVERSION Inversion of a large chromosome segment (over 1% or 1,000,000 bases). HIGH coding_sequence_variant CODON_CHANGE One or many codons are changed e.g.: An MNP of size multiple of 3 LOW inframe_insertion CODON_INSERTION One or many codons are inserted e.g.: An insert multiple of three in a codon boundary MODERATE disruptive_inframe_insertion CODON_CHANGE_PLUS CODON_INSERTION One codon is changed and one or many codons are inserted e.g.: An insert of size multiple of three, not at codon boundary MODERATE inframe_deletion CODON_DELETION One or many codons are deleted e.g.: A deletion multiple of three at codon boundary MODERATE disruptive_inframe_deletion CODON_CHANGE_PLUS CODON_DELETION One codon is changed and one or more codons are deleted e.g.: A deletion of size multiple of three, not at codon boundary MODERATE downstream_gene_variant DOWNSTREAM Downstream of a gene (default length: 5K bases) MODIFIER exon_variant EXON The variant hits an exon (from a non-coding transcript) or a retained intron. MODIFIER exon_loss_variant EXON_DELETED A deletion removes the whole exon. HIGH exon_loss_variant EXON_DELETED_PARTIAL Deletion affecting part of an exon. HIGH duplication EXON_DUPLICATION Duplication of an exon. HIGH duplication EXON_DUPLICATION_PARTIAL Duplication affecting part of an exon. HIGH inversion EXON_INVERSION Inversion of an exon. HIGH inversion EXON_INVERSION_PARTIAL Inversion affecting part of an exon. HIGH frameshift_variant FRAME_SHIFT Insertion or deletion causes a frame shift e.g.: An indel size is not multple of 3 HIGH gene_variant GENE The variant hits a gene. MODIFIER feature_ablation GENE_DELETED Deletion of a gene. HIGH duplication GENE_DUPLICATION Duplication of a gene. MODIFIER gene_fusion GENE_FUSION Fusion of two genes. HIGH gene_fusion GENE_FUSION_HALF Fusion of one gene and an intergenic region. HIGH bidirectional_gene_fusion GENE_FUSION_REVERSE Fusion of two genes in opposite directions. HIGH rearranged_at_DNA_level GENE_REARRANGEMENT Rearrangement affecting one or more genes. HIGH intergenic_region INTERGENIC The variant is in an intergenic region MODIFIER conserved_intergenic_variant INTERGENIC_CONSERVED The variant is in a highly conserved intergenic region MODIFIER intragenic_variant INTRAGENIC The variant hits a gene, but no transcripts within the gene MODIFIER intron_variant INTRON Variant hits and intron. Technically, hits no exon in the transcript. MODIFIER conserved_intron_variant INTRON_CONSERVED The variant is in a highly conserved intronic region MODIFIER miRNA MICRO_RNA Variant affects an miRNA MODIFIER missense_variant NON_SYNONYMOUS_CODING Variant causes a codon that produces a different amino acid e.g.: Tgg/Cgg, W/R MODERATE initiator_codon_variant NON_SYNONYMOUS_START Variant causes start codon to be mutated into another start codon (the new codon produces a different AA). e.g.: Atg/Ctg, M/L (ATG and CTG can be START codons) LOW stop_retained_variant NON_SYNONYMOUS_STOP Variant causes stop codon to be mutated into another stop codon (the new codon produces a different AA). e.g.: Atg/Ctg, M/L (ATG and CTG can be START codons) LOW protein_protein_contact PROTEIN_PROTEIN_INTERACTION_LOCUS Protein-Protein interaction loci. HIGH structural_interaction_variant PROTEIN_STRUCTURAL_INTERACTION_LOCUS Within protein interacion loci (e.g. two AA that are in contact within the same protein, prossibly helping structural conformation). HIGH rare_amino_acid_variant RARE_AMINO_ACID The variant hits a rare amino acid thus is likely to produce protein loss of function HIGH splice_acceptor_variant SPLICE_SITE_ACCEPTOR The variant hits a splice acceptor site (defined as two bases before exon start, except for the first exon). HIGH splice_donor_variant SPLICE_SITE_DONOR The variant hits a Splice donor site (defined as two bases after coding exon end, except for the last exon). HIGH splice_region_variant SPLICE_SITE_REGION A sequence variant in which a change has occurred within the region of the splice site, either within 1-3 bases of the exon or 3-8 bases of the intron. LOW splice_region_variant SPLICE_SITE_BRANCH A varaint affective putative (Lariat) branch point, located in the intron. LOW splice_region_variant SPLICE_SITE_BRANCH_U12 A varaint affective putative (Lariat) branch point from U12 splicing machinery, located in the intron. MODERATE stop_lost STOP_LOST Variant causes stop codon to be mutated into a non-stop codon e.g.: Tga/Cga, */R HIGH 5_prime_UTR_premature_ start_codon_gain_variant START_GAINED A variant in 5'UTR region produces a three base sequence that can be a START codon. LOW start_lost START_LOST Variant causes start codon to be mutated into a non-start codon. e.g.: aTg/aGg, M/R HIGH stop_gained STOP_GAINED Variant causes a STOP codon e.g.: Cag/Tag, Q/* HIGH synonymous_variant SYNONYMOUS_CODING Variant causes a codon that produces the same amino acid e.g.: Ttg/Ctg, L/L LOW start_retained SYNONYMOUS_START Variant causes start codon to be mutated into another start codon. e.g.: Ttg/Ctg, L/L (TTG and CTG can be START codons) LOW stop_retained_variant SYNONYMOUS_STOP Variant causes stop codon to be mutated into another stop codon. e.g.: taA/taG, */* LOW transcript_variant TRANSCRIPT The variant hits a transcript. MODIFIER feature_ablation TRANSCRIPT_DELETED Deletion of a transcript. HIGH regulatory_region_variant REGULATION The variant hits a known regulatory feature (non-coding). MODIFIER upstream_gene_variant UPSTREAM Upstream of a gene (default length: 5K bases) MODIFIER 3_prime_UTR_variant UTR_3_PRIME Variant hits 3'UTR region MODIFIER 3_prime_UTR_truncation + exon_loss UTR_3_DELETED The variant deletes an exon which is in the 3'UTR of the transcript MODERATE 5_prime_UTR_variant UTR_5_PRIME Variant hits 5'UTR region MODIFIER 5_prime_UTR_truncation + exon_loss_variant UTR_5_DELETED The variant deletes an exon which is in the 5'UTR of the transcript MODERATE sequence_feature + exon_loss_variant NEXT_PROT A 'NextProt' based annotation. Details are provided in the 'feature type' sub-field (ANN), or in the effect details (EFF). MODERATE Details about Rare amino acid effect These are amino acids that occurs very rarely in an organism. For instance, humans are supposed to use 20 amino acids, but there is also one rare AA. Selenocysteine, single letter code 'U', appears roughly 100 times in the whole genome. The amino acid is so rare that usually it does not appear in codon translation tables. It is encoded as UGA, which usually means a STOP codon. Secondary RNA structures are assumed to enable this special translation. A variant in one of these sites is likely to cause a loss of function in the protein. E.g. in case of a Selenocysteine, a loss of a selenium molecule is likely to cause loss of function. Put it simply, the assumption is that there is a great deal of trouble to get that non-standard amino acid there, so it must be important. RARE_AMINO_ACID mark is used to show that special attention should be paid in these cases. Warning When the variant hits a RARE_AMINO_ACID mark, it is likely that the 'old_AA/new_AA' field will be incorrect. This may happen because the amino acid is not predictable using a codon table. Details about Protein interaction effects Protein interactions are calculated from PDB . There are two main types of interactions: protein_protein_contact: These are \"protein-protein\" interaction loci. They are calculated from PDB's co-crystalized structures by inferring pairs of amino acids in different proteins that have atoms closer than 3 Angstrom from each other. structural_interaction_variant: These are \"within protein\" interaction loci, which are likely to be supporting the protein structure. They are calculated from single protein PDB entries, by selecting amino acids that are: a) atom within 3 Angstrom of each other; and b) are far away in the AA sequence (over 20 AA distance). The assumption is that, since they are very close in distance, they must be \"interacting\" and thus important for protein structure. Impact prediction SnpEff reports putative variant impact in order to make it easier quickly to categorize and prioritize variants. Warning Impact categories must be used with care, they were created only to help and simplify the filtering process. Obviously, there is no way to predict whether a HIGH impact or a LOW impact variant is the one producing a phenotype of interest. Impact Meaning Example HIGH The variant is assumed to have high (disruptive) impact in the protein, probably causing protein truncation, loss of function or triggering nonsense mediated decay. stop_gained, frameshift_variant MODERATE A non-disruptive variant that might change protein effectiveness. missense_variant, inframe_deletion LOW Assumed to be mostly harmless or unlikely to change protein behavior. synonymous_variant MODIFIER Usually non-coding variants or variants affecting non-coding genes, where predictions are difficult or there is no evidence of impact. exon_variant, downstream_gene_variant Loss of function (LOF) and nonsense-mediated decay (NMD) predictions Loss of function ('LOF') and nonsense-mediated decay ('NMD') predictions. In older versions, this prediction was activated using command line option -lof , but as of version 4.0, it is activated by default. Some details on how these variants work, can be found in these slides . Info Starting from version 4.0, this option is activated by default. Analyze if a set of effects are can create a \"Loss Of Function\" and \"Nonsense mediated decays\" effects. Needless to say, this is a prediction based on analysis of groups of \"putative effects\". Proper wet-lab validation is required to infer \"real\" LOF. References: I used the LOF definition used in the following paper A Systematic Survey of Loss-of-Function Variants in Human Protein-Coding Genes . From the paper: We adopted a definition for LoF variants expected to correlate with complete loss of function of the affected transcripts: stop codon-introducing (nonsense) or splice site-disrupting single-nucleotide variants (SNVs), insertion/deletion (indel) variants predicted to disrupt a transcript's reading frame, or larger deletions removing either the first exon or more than 50% of the protein-coding sequence of the affected transcript. Both nonsense SNVs and frameshift indels are enriched toward the 3' end of the affected gene, consistent with a greater tolerance to truncation close to the end of the coding sequence; putative LoF variants identified in the last 5% of the coding region were thus systematically removed from our high-confidence set. Other parameters used for LOF/NMD calculations: Number of bases before last exon-exon junction that nonsense mediated decay is supposed to occur: 50 It is assumed that even with a protein coding change at the last 5% of the protein, the protein could still be functional. It is assumed that even with a protein coding change at the first 5% of the protein: \"..suggesting some disrupted transcripts are rescued by transcriptional reinitiation at an alternative start codon.\" Larger deletions removing either the first exon or more than 50% of the protein-coding sequence of the affected transcript Usage example: # Note: Form version 4.0 onwards, the '-lof' command line option is not required java -Xmx8g -jar snpEff.jar -v \\ -lof \\ GRCh37.75 \\ test.chr22.vcf > test.chr22.ann.vcf SnpEff adds 'LOF' and 'NMD' tags to INFO fields (column 8 in VCF format). LOF and NMD tags have the following format: Gene | ID | num_transcripts | percent_affected Where: Field Description Gene Gene name ID Gene ID (usually ENSEMBL) Num_transcripts Number of transcripts in this gene percent_affected Percentage of transcripts affected by this variant. Example: If we have this effect EFF=stop_gained(LOW|NONSENSE|Gga/Tga|p.Gly163*/c.487G>T|574|GAB4|protein_coding|CODING|ENST00000400588|3|1),... and the corresponding LOF and NMD tags are LOF=(GAB4|ENSG00000215568|4|0.25);NMD=(GAB4|ENSG00000215568|4|0.25) The meaning of the LOF tag is: Field Description Gene GAB4 ID ENSG00000215568 Num_transcripts There are 4 transcripts in this gene percent_affected 25% of transcripts are affected by this variant. Errors and Warnings As mentioned int the previous section, the last sub-field in EFF field shows errors or warnings (if any). Here is a description of the errors and warnings: Error Meaning and possible solutions ERROR_CHROMOSOME_NOT_FOUND Chromosome does not exits in reference database. See this FAQ for more details. ERROR_OUT_OF_CHROMOSOME_RANGE This means that the position is higher than chromosome's length. Probably an indicator that your data is not from this reference genome. ERROR_OUT_OF_EXON Exonic information not matching the coordinates. Indicates a problem (or even a bug?) in the database ERROR_MISSING_CDS_SEQUENCE Transcript has no CDS info. Indicates a problem (or even a bug?) in the database Warning Meaning and possible solutions WARNING_REF_DOES_NOT_MATCH_GENOME This means that the REF field does not match the reference genome. Warning! This warning probably indicated there is something really wrong with your data! This happens when your data was aligned to a different reference genome than the one used to create SnpEff's database. If there are many of these warnings, it's a strong indicator that the data doesn't match and all the annotations will be garbage (because you are using the wrong database). Solution: Use the right database to annotate! Due to performance and memory optimizations, SnpEff only checks reference sequence on Exons. WARNING_SEQUENCE_NOT_AVAILABLE For some reason the exon sequence is not available, so we cannot calculate effects. WARNING_TRANSCRIPT_INCOMPLETE A protein coding transcript whose length is non-multiple of 3. This means that information is missing for one or more amino acids. This is usually due to errors in the genomic information (e.g. the genomic databases provided by UCSC or ENSEMBL). Genomic information databases are constantly being improved and are getting more accurate, but some errors still remain. WARNING_TRANSCRIPT_MULTIPLE_STOP_CODONS A protein coding transcript has two or more STOP codons in the middle of the coding sequence (CDS). This should not happen and it usually means the genomic information may have an error in this transcript. This is usually due to errors in the genomic information (e.g. the genomic databases provided by UCSC or ENSEMBL). Genomic information databases are constantly being improved and are getting more accurate, but some errors still remain. WARNING_TRANSCRIPT_NO_START_CODON A protein coding transcript does not have a proper START codon. It is rare that a real transcript does not have a START codon, so this probably indicates errors in genomic information for this transcript (e.g. the genomic databases provided by UCSC or ENSEMBL). Genomic information databases are constantly being improved and are getting more accurate, but some errors still remain. BED files In an enrichment experiment, such as ChIP-Seq, the results are enrichment regions, usually called \"peaks\". It is common for \"peak callers\" (algorithms that detect enrichment), write the results in a BED file. SnpEff can annotate BED files in order to facilitate interpretation of enrichment experiments. Warning Column fifth onwards are ignored when using BED file format and they will be lost in the output file. SnpEff can annotate BED files in order to facilitate interpretation of enrichment experiments. Annotations are added to the fourth column of the BED file. E.g.: $ java -Xmx8g -jar snpEff.jar -i bed BDGP5.69 chipSeq_peaks.bed # SnpEff version 3.3 (build 2013-05-15), by Pablo Cingolani # Command line: SnpEff -i bed BDGP5.69 /home/pcingola/fly_pvuseq/chipSeq/Sample_w1118_IP_w_5hmC/w1118_IP_w_5hmC_peaks.bed # Chromo Start End Name;Effect|Gene|BioType Score 2L 189463 190154 MACS_peak_1;Exon|exon_6_12_RETAINED|FBtr0078122|protein_coding|spen|protein_coding;Exon|exon_5_10_RETAINED|FBtr0078123|protein_coding|spen|protein_coding;Exon|exon_7_13_RETAINED|FBtr0306341|protein_coding|spen|protein_coding;Exon|exon_6_11_RETAINED|FBtr0078121|protein_coding|spen|protein_coding 245.41 2L 195607 196120 MACS_peak_2;Exon|exon_6_12_RETAINED|FBtr0078122|protein_coding|spen|protein_coding;Exon|exon_5_10_RETAINED|FBtr0078123|protein_coding|spen|protein_coding;Exon|exon_7_13_RETAINED|FBtr0306341|protein_coding|spen|protein_coding;Exon|exon_6_11_RETAINED|FBtr0078121|protein_coding|spen|protein_coding 51.22 2L 527253 527972 MACS_peak_3;Intron|intron_2_RETAINED-RETAINED|FBtr0078063|protein_coding|ush|protein_coding 55.97 2L 711439 711764 MACS_peak_4;Intron|intron_1_RETAINED-RETAINED|FBtr0078045|protein_coding|ds|protein_coding 61.16 2L 1365255 1365556 MACS_peak_5;Upstream|FBtr0077927|protein_coding|CG14346|protein_coding;Upstream|FBtr0077926|protein_coding|CG14346|protein_coding;Intergenic|NLaz...CG14346;Upstream|FBtr0077942|protein_coding|NLaz|protein_coding 62.78 2L 1970199 1970405 MACS_peak_6;Upstream|FBtr0077813|protein_coding|Der-1|protein_coding;Intergenic|tRNA:CR31942...Der-1;Downstream|FBtr0077812|tRNA|tRNA:CR31942|tRNA 110.34 2L 3345637 3346152 MACS_peak_7;Intron|intron_2_ALTTENATIVE_3SS-ALTTENATIVE_3SS|FBtr0089979|protein_coding|E23|protein_coding;Intron|intron_3_ALTTENATIVE_3SS-ALTTENATIVE_3SS|FBtr0089981|protein_coding|E23|protein_coding 65.49 2L 4154734 4155027 MACS_peak_8;Intergenic|CG2955...Or24a;Downstream|FBtr0077468|protein_coding|CG2955|protein_coding 76.92 2L 4643232 4643531 MACS_peak_9;Downstream|FBtr0110769|protein_coding|BG642163|protein_coding;Exon|exon_2_2_RETAINED|FBtr0300354|protein_coding|CG15635|protein_coding 76.92 When a peak intersects multiple transcripts or even multiple genes, each annotation is separated by a semicolon. So if you look into the previous results in more detail, the first line looks like this (format edited for readability purposes): 2L 189463 190154 MACS_peak_1;Exon|exon_6_12_RETAINED|FBtr0078122|protein_coding|spen|protein_coding ;Exon|exon_5_10_RETAINED|FBtr0078123|protein_coding|spen|protein_coding ;Exon|exon_7_13_RETAINED|FBtr0306341|protein_coding|spen|protein_coding ;Exon|exon_6_11_RETAINED|FBtr0078121|protein_coding|spen|protein_coding This peak is hitting four transcripts (FBtr0078122, FBtr0078123, FBtr0306341, FBtr0078121) in gene 'spen'. Exon naming convention The format for the exon identifier is exon_Rank_Total_Type , where: rank is the exon rank in the transcript (position in the transcript) total is the total number of exons in that transcript type is the exon splice type. For instance exon_5_10_RETAINED would be the fifth exon in a 10 exon transcript. This exon is type \"RETAINED\", which means it is not spliced out. Exons are categorized by splicing as follows: NONE : Not spliced RETAINED : All transcripts have this exon SKIPPED : Some transcripts skip it ALTTENATIVE_3SS : Some transcripts have and alternative 3' exon start ALTTENATIVE_5SS : Some transcripts have and alternative 5' exon end MUTUALLY_EXCLUSIVE : Mutually exclusive (respect to other exon) ALTTENATIVE_PROMOMOTER : The first exon is different in some transcripts. ALTTENATIVE_POLY_A : The last exon. See this Wikipedia entry for more information on exon splice types. Intron naming convention Similarly to exons, introns are named as intron_Rank_ExonTypeBefore-ExonTypeAfter , where: Rank : the rank number for this intron in the transcript ExonTypeBefore : the splicing type of the exon preceding this intron (see exon naming convention for details). ExonTypeAfter : the splicing type of the after this intron (see exon naming convention for details). For instance intron_9_SKIPPED-RETAINED would be the ninth intron of the transcript. The intron is preceded by a SKIPPED exon and followed by a RETAINED exon.","title":"Input &amp; output files"},{"location":"se_inputoutput/#input-output-files","text":"Files used as input to SnpEff must comply with standard formats. Here we describe supported input data formats.","title":"Input &amp; output files"},{"location":"se_inputoutput/#vcf-files","text":"As we mentioned before, Variant Call Format (VCF) is the recommended format for input files. This is the format used by the \"1000 Genomes Project\", and is currently considered the de facto standard for genomic variants. It is also the default format used in SnpEff. In a nutshell, VCF format is tab-separated text file having the following columns: Chromosome name Position Variant's ID Reference genome Alternative (i.e. variant) Quality score Filter (whether or not the variant passed quality filters) INFO : Generic information about this variant. SnpEff adds annotation information in this column. Here is an example of a few lines in a VCF file: #CHROM POS ID REF ALT QUAL FILTER INFO 20 14370 rs6054257 G A 29 PASS NS=3;DP=14;AF=0.5;DB;H2 20 17330 . T A 3 q10 NS=3;DP=11;AF=0.017 Note that the first line is header information. Header lines start with '#'","title":"VCF files"},{"location":"se_inputoutput/#vcf-output","text":"As we mentioned in the previous chapter, VCF is SnpEff's default input and output format. It is highly recommended to use VCF as input and output format, since it is a standard format that can be also used by other tools and software packages. Thus VCF makes it much easier to integrate genomic data processing pipelines. SnpEff adds annotation information to the INFO field of a VCF file. The INFO field is the eight column of a VCF file, see previous section for a quick example or take a look at the VCF specification for details. Here is an example of a file before and after being annotated using SnpEff: VCF file before annotations #CHROM POS ID REF ALT QUAL FILTER INFO 1 889455 . G A 100.0 PASS AF=0.0005 1 897062 . C T 100.0 PASS AF=0.0005 VCF file after being annotated using SnpEff #CHROM POS ID REF ALT QUAL FILTER INFO 1 889455 . G A 100.0 PASS AF=0.0005;EFF=STOP_GAINED(HIGH|NONSENSE|Cag/Tag|Q236*|749|NOC2L||CODING|NM_015658|) 1 897062 . C T 100.0 PASS AF=0.0005;EFF=STOP_GAINED(HIGH|NONSENSE|Cag/Tag|Q141*|642|KLHL17||CODING|NM_198317|) A you can see, SnpEff added an 'EFF' tag to the INFO field (eight column).","title":"VCF output"},{"location":"se_inputoutput/#vcf-header-lines","text":"SnpEff updates the header of the VCF file to reflect additional fields. This is required by the VCF specification. SnpEff also adds the command line options used to annotate the file as well as SnpEff's version, so you can keep track of what exactly was done. Here is an example of some header lines added to an annotated file: ##SnpEffVersion=\"SnpEff 3.1m (build 2013-02-08)\" ##SnpEffCmd=\"SnpEff hg19 demo.1kg.vcf \" ##INFO=<ID=EFF,Number=.,Type=String,Description=\"Predicted effects for this variant.Format: 'Effect ( Effect_Impact | Functional_Class | Codon_Change | Amino_Acid_change| Amino_Acid_length | Gene_Name | Gene_BioType | Coding | Transcript | Exon [ | ERRORS | WARNINGS ] )' \\\">","title":"VCF Header lines"},{"location":"se_inputoutput/#ann-field-vcf-output-files","text":"Functional annotations information is added to the INFO field using an ANN tag. NOTE: field. SnpEff implements the VCF annotation standard 'ANN' field. This format specification has been created by the developers of the most widely used variant annotation programs (SnpEff, ANNOVAR and ENSEMBL's VEP) and attempts to: provide a common framework for variant annotation, make pipeline development easier, facilitate benchmarking, and improve some known problems in variant annotations. Obviously this 'ANN' field broke compatibility with the old 'EFF' field from old SnpEff versions. In order to use the old 'EFF' field, you can use the -formatEff command line option. The annotation 'ANN' field looks like this (the full annotation standard specification can be found here ). ANN=T|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.1406G>A|p.Gly469Glu|1666/2034|1406/1674|469/557||,T|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397G>A|||||3944| A variant can have (and usually has) more than one annotation. Multiple annotations are separated by commas. In the previous example there were two annotations corresponding to different genes (CCT8L2 and FABP5P11). Each annotation consists of multiple sub-fields separated by the pipe character \"|\" (fields 15 and 16 are empty in this example): Annotation : T|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.1406G>A|p.Gly469Glu|1666/2034|1406/1674|469/557| | SubField number : 1| 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 |15| 16 Here is a description of the meaning of each sub-field: Allele (or ALT): In case of multiple ALT fields, this helps to identify which ALT we are referring to. E.g.: # CHROM POS ID REF ALT QUAL FILTER INFO chr1 123456 . C A . . ANN=A|... chr1 234567 . A G,T . . ANN=G|... , T|... In case of cancer sample, when comparing somatic versus germline using a non-standard reference (e.g. one of the ALTs is the reference) the format should be ALT-REFERENCE. E.g.: #CHROM POS ID REF ALT QUAL FILTER INFO chr1 123456 . A C,G . . ANN=G-C|... Compound variants: two or more variants affecting the annotations (e.g. two consecutive SNPs conforming a MNP, two consecutive frame_shift variants that \"recover\" the frame). In this case, the Allele field should include a reference to the other variant/s included in the annotation: #CHROM POS ID REF ALT QUAL FILTER INFO chr1 123456 . A T . . ANN=T|... chr1 123457 . C G . . ANN=C-chr1:123456_A>T|... Annotation (a.k.a. effect): Annotated using Sequence Ontology terms. Multiple effects can be concatenated using '&'. #CHROM POS ID REF ALT QUAL FILTER INFO chr1 123456 . C A . . ANN=A|intron_variant&nc_transcript_variant|... Putative_impact: A simple estimation of putative impact / deleteriousness : {HIGH, MODERATE, LOW, MODIFIER} Gene Name: Common gene name (HGNC). Optional: use closest gene when the variant is \"intergenic\". Gene ID: Gene ID Feature type: Which type of feature is in the next field (e.g. transcript, motif, miRNA, etc.). It is preferred to use Sequence Ontology (SO) terms, but 'custom' (user defined) are allowed. ANN=A|stop_gained|HIGH|||transcript|... Tissue specific features may include cell type / tissue information separated by semicolon e.g.: ANN=A|histone_binding_site|LOW|||H3K4me3:HeLa-S3| Feature ID: Depending on the annotation, this may be: Transcript ID (preferably using version number), Motif ID, miRNA, ChipSeq peak, Histone mark, etc. Note: Some features may not have ID (e.g. histone marks from custom Chip-Seq experiments may not have a unique ID). Transcript biotype: The bare minimum is at least a description on whether the transcript is {\"Coding\", \"Noncoding\"}. Whenever possible, use ENSEMBL biotypes. Rank / total: Exon or Intron rank / total number of exons or introns. HGVS.c: Variant using HGVS notation (DNA level) HGVS.p: If variant is coding, this field describes the variant using HGVS notation (Protein level). Since transcript ID is already mentioned in 'feature ID', it may be omitted here. cDNA_position / cDNA_len: Position in cDNA and trancript's cDNA length (one based). CDS_position / CDS_len: Position and number of coding bases (one based includes START and STOP codons). Protein_position / Protein_len: Position and number of AA (one based, including START, but not STOP). Distance to feature: All items in this field are options, so the field could be empty. Up/Downstream: Distance to first / last codon Intergenic: Distance to closest gene Distance to closest Intron boundary in exon (+/- up/downstream). If same, use positive number. Distance to closest exon boundary in Intron (+/- up/downstream) Distance to first base in MOTIF Distance to first base in miRNA Distance to exon-intron boundary in splice_site or splice _region ChipSeq peak: Distance to summit (or peak center) Histone mark / Histone state: Distance to summit (or peak center) Errors, Warnings or Information messages: Add errors, warnings or informative message that can affect annotation accuracy. It can be added using either 'codes' (as shown in column 1, e.g. W1) or 'message types' (as shown in column 2, e.g. WARNING_REF_DOES_NOT_MATCH_GENOME). All these errors, warnings or information messages messages are optional. Code Message type Description / Notes E1 ERROR_CHROMOSOME_NOT_FOUND Chromosome does not exists in reference genome database. Typically indicates a mismatch between the chromosome names in the input file and the chromosome names used in the reference genome. E2 ERROR_OUT_OF_CHROMOSOME_RANGE The variant's genomic coordinate is greater than chromosome's length. W1 WARNING_REF_DOES_NOT_MATCH_GENOME This means that the 'REF' field in the input VCF file does not match the reference genome. This warning may indicate a conflict between input data and data from reference genome (for instance is the input VCF was aligned to a different reference genome). W2 WARNING_SEQUENCE_NOT_AVAILABLE Reference sequence is not available, thus no inference could be performed. W3 WARNING_TRANSCRIPT_INCOMPLETE A protein coding transcript having a non-multiple of 3 length. It indicates that the reference genome has missing information about this particular transcript. W4 WARNING_TRANSCRIPT_MULTIPLE_STOP_CODONS A protein coding transcript has two or more STOP codons in the middle of the coding sequence (CDS). This should not happen and it usually means the reference genome may have an error in this transcript. W5 WARNING_TRANSCRIPT_NO_START_CODON A protein coding transcript does not have a proper START codon. It is rare that a real transcript does not have a START codon, so this probably indicates an error or missing information in the reference genome. I1 INFO_REALIGN_3_PRIME Variant has been realigned to the most 3-prime position within the transcript. This is usually done to to comply with HGVS specification to always report the most 3-prime annotation. I2 INFO_COMPOUND_ANNOTATION This effect is a result of combining more than one variants (e.g. two consecutive SNPs that conform an MNP, or two consecutive frame_shift variants that compensate frame). I3 INFO_NON_REFERENCE_ANNOTATION An alternative reference sequence was used to calculate this annotation (e.g. cancer sample comparing somatic vs. germline). Consistency between HGVS and functional annotations: In some cases there might be inconsistent reporting between 'annotation' and HGVS. This is due to the fact that VCF recommends aligning to the leftmost coordinate, whereas HGSV recommends aligning to the \"most 3-prime coordinate\". For instance, an InDel on the edge of an exon, which has an 'intronic' annotation according to VCF alignment recommendation, can lead to a 'stop_gained' when aligned using HGVS's recommendation (using the most 3-prime possible alignment). So the 'annotation' sub-field will report 'intron' whereas HGVS sub-field will report a 'stop_gained'. This is obviously inconsistent and must be avoided. In order to report annotations that are consistent with HGVS notation, variants must be re-aligned according to each transcript's strand (i.e. align the variant according to the transcript's most 3-prime coordinate). Then annotations are calculated, thus the reported annotations will be consistent with HGVS notation. Annotation software should have a command line option to override this behaviour (e.g. -no_shift_hgvs )","title":"ANN field (VCF output files)"},{"location":"se_inputoutput/#eff-field-vcf-output-files","text":"Effects information is added to the INFO field using an 'EFF' tag. Warning This section refers the obsolete annotation format using the 'EFF' tag which can be activated using the -formatEff command line option. As of version 4.1 SnpEff uses the 'ANN' field by default. Notes: As of version 4.0, the default output uses Sequence Ontology for 'Effect' names. You can output \"old\" style effect names by using the -classic command line option. When multiple effects are available, they are sorted first by \"Effect_Impact\", then by \"Effect\" and finally by \"marker's genomic coordinates\" (e.g. affected transcript's genomic coordinates). Staring from version 4.0, SnpEff outputs HGVS notation in the 'AA' sub-field by default. There can be multiple effects separated by comma. The format for each effect is: EFF= Effect ( Effect_Impact | Functional_Class | Codon_Change | Amino_Acid_Change| Amino_Acid_Length | Gene_Name | Transcript_BioType | Gene_Coding | Transcript_ID | Exon_Rank | Genotype_Number [ | ERRORS | WARNINGS ] ) EFF Sub-field Meaning Effect Effect of this variant. See details here . Effect impact Effect impact {High, Moderate, Low, Modifier}. See details here . Functional Class Functional class {NONE, SILENT, MISSENSE, NONSENSE}. Codon_Change / Distance Codon change: old_codon/new_codon OR distance to transcript (in case of upstream / downstream) Amino_Acid_Change Amino acid change: old_AA AA_position/new_AA (e.g. 'E30K') Amino_Acid_Length Length of protein in amino acids (actually, transcription length divided by 3). Gene_Name Gene name Transcript_BioType Transcript bioType, if available. Gene_Coding [CODING | NON_CODING] . This field is 'CODING' if any transcript of the gene is marked as protein coding. Transcript_ID Transcript ID (usually ENSEMBL IDs) Exon/Intron Rank Exon rank or Intron rank (e.g. '1' for the first exon, '2' for the second exon, etc.) Genotype_Number Genotype number corresponding to this effect (e.g. '2' if the effect corresponds to the second ALT) Warnings / Errors Any warnings or errors (not shown if empty).","title":"EFF field (VCF output files)"},{"location":"se_inputoutput/#multiple-annotations-per-vcf-line","text":"Usually there is more than one annotation reported in each ANN (or EFF ) field. There are several reasons for this: A variant can affect multiple genes. E.g a variant can be DOWNSTREAM from one gene and UPSTREAM from another gene. E.g.: In complex organisms, genes usually have multiple transcripts. So SnpEff reports the effect of a variant on each transcript. E.g.: #CHROM POS ID REF ALT QUAL FILTER INFO 1 889455 . G A . . . In this case SnpEff will report the effect of each variant on each gene and each transcript (output edited for readability): #CHROM POS ID REF ALT QUAL FILTER INFO 1 889455 . G A . . ANN=A|stop_gained|HIGH|NOC2L|ENSG00000188976|transcript|ENST00000327044|protein_coding|7/19|c.706C>T|p.Gln236*|756/2790|706/2250|236/749|| ,A|downstream_gene_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000487214|processed_transcript||n.*865C>T|||||351| ,A|downstream_gene_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000469563|retained_intron||n.*878C>T|||||4171| ,A|non_coding_exon_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000477976|retained_intron|5/17|n.2153C>T||||||;LOF=(NOC2L|ENSG00000188976|6|0.17);NMD=(NOC2L|ENSG00000188976|6|0.17) A VCF line can have more then one variant. E.g. If reference genome is 'G', but the sample has either 'A' or 'T' (non-biallelic variant), then this will be reported as one VCF line, having multiple alternative variants (notice that there are two ALTs): #CHROM POS ID REF ALT QUAL FILTER INFO 1 889455 . G A,T . . . In this case SnpEff will report the effect of each ALT on each gene and each transcript. Notice that ENST00000327044 has a stop_gained variant (ALT = 'A') and a missense_variant (ALT = 'T') #CHROM POS ID REF ALT QUAL FILTER INFO 1 889455 . G A,T . . ANN=A|stop_gained|HIGH|NOC2L|ENSG00000188976|transcript|ENST00000327044|protein_coding|7/19|c.706C>T|p.Gln236*|756/2790|706/2250|236/749|| ,T|missense_variant|MODERATE|NOC2L|ENSG00000188976|transcript|ENST00000327044|protein_coding|7/19|c.706C>A|p.Gln236Lys|756/2790|706/2250|236/749|| ,A|downstream_gene_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000487214|processed_transcript||n.*865C>T|||||351| ,T|downstream_gene_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000487214|processed_transcript||n.*865C>A|||||351| ,A|downstream_gene_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000469563|retained_intron||n.*878C>T|||||4171| ,T|downstream_gene_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000469563|retained_intron||n.*878C>A|||||4171| ,A|non_coding_exon_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000477976|retained_intron|5/17|n.2153C>T|||||| ,T|non_coding_exon_variant|MODIFIER|NOC2L|ENSG00000188976|transcript|ENST00000477976|retained_intron|5/17|n.2153C>A||||||;LOF=(NOC2L|ENSG00000188976|6|0.17);NMD=(NOC2L|ENSG00000188976|6|0. Effect sort order . When multiple effects are reported, SnpEff sorts the effects the following way: Putative impact: Effects having higher putative impact are first. Effect type: Effects assumed to be more deleterious effects first. Canonical transcript before non-canonical. Marker genomic coordinates (e.g. genes starting before first).","title":"Multiple annotations per VCF line"},{"location":"se_inputoutput/#effect-prediction-details","text":"Detailed description of the effect predicted by SnpEff in the Effect and Effect_Impact sub-fields. Notes: Effect (Sequence Ontology) Sequence ontology ( SO ) allows to standardize terminology used for assessing sequence changes and impact. This allows for a common language across all variant annotation programs and makes it easier to communicate using a uniform terminology. Starting from version 4.0 VCF output uses SO terms by default. Effect (Classic) This are the \"classic\" effect names usd by SnpEff, these can be accessed using the -classic command line option. Effect impact Effects are categorized by 'impact': {High, Moderate, Low, Modifier}. This are pre-defined categories to help users find more significant variants. Warning Impact categories must be used with care, they were created only to help and simplify the filtering process. Obviously, there is no way to predict whether a \"high impact\" or a \"low impact\" variant is the one producing a phenotype of interest. Here is a list of effects and some brief explanations: Effect Seq. Ontology Effect Classic Note & Example Impact coding_sequence_variant CDS The variant hits a CDS. MODIFIER chromosome CHROMOSOME_LARGE DELETION A large parte (over 1%) of the chromosome was deleted. HIGH duplication CHROMOSOME_LARGE_DUPLICATION Duplication of a large chromosome segment (over 1% or 1,000,000 bases) HIGH inversion CHROMOSOME_LARGE_INVERSION Inversion of a large chromosome segment (over 1% or 1,000,000 bases). HIGH coding_sequence_variant CODON_CHANGE One or many codons are changed e.g.: An MNP of size multiple of 3 LOW inframe_insertion CODON_INSERTION One or many codons are inserted e.g.: An insert multiple of three in a codon boundary MODERATE disruptive_inframe_insertion CODON_CHANGE_PLUS CODON_INSERTION One codon is changed and one or many codons are inserted e.g.: An insert of size multiple of three, not at codon boundary MODERATE inframe_deletion CODON_DELETION One or many codons are deleted e.g.: A deletion multiple of three at codon boundary MODERATE disruptive_inframe_deletion CODON_CHANGE_PLUS CODON_DELETION One codon is changed and one or more codons are deleted e.g.: A deletion of size multiple of three, not at codon boundary MODERATE downstream_gene_variant DOWNSTREAM Downstream of a gene (default length: 5K bases) MODIFIER exon_variant EXON The variant hits an exon (from a non-coding transcript) or a retained intron. MODIFIER exon_loss_variant EXON_DELETED A deletion removes the whole exon. HIGH exon_loss_variant EXON_DELETED_PARTIAL Deletion affecting part of an exon. HIGH duplication EXON_DUPLICATION Duplication of an exon. HIGH duplication EXON_DUPLICATION_PARTIAL Duplication affecting part of an exon. HIGH inversion EXON_INVERSION Inversion of an exon. HIGH inversion EXON_INVERSION_PARTIAL Inversion affecting part of an exon. HIGH frameshift_variant FRAME_SHIFT Insertion or deletion causes a frame shift e.g.: An indel size is not multple of 3 HIGH gene_variant GENE The variant hits a gene. MODIFIER feature_ablation GENE_DELETED Deletion of a gene. HIGH duplication GENE_DUPLICATION Duplication of a gene. MODIFIER gene_fusion GENE_FUSION Fusion of two genes. HIGH gene_fusion GENE_FUSION_HALF Fusion of one gene and an intergenic region. HIGH bidirectional_gene_fusion GENE_FUSION_REVERSE Fusion of two genes in opposite directions. HIGH rearranged_at_DNA_level GENE_REARRANGEMENT Rearrangement affecting one or more genes. HIGH intergenic_region INTERGENIC The variant is in an intergenic region MODIFIER conserved_intergenic_variant INTERGENIC_CONSERVED The variant is in a highly conserved intergenic region MODIFIER intragenic_variant INTRAGENIC The variant hits a gene, but no transcripts within the gene MODIFIER intron_variant INTRON Variant hits and intron. Technically, hits no exon in the transcript. MODIFIER conserved_intron_variant INTRON_CONSERVED The variant is in a highly conserved intronic region MODIFIER miRNA MICRO_RNA Variant affects an miRNA MODIFIER missense_variant NON_SYNONYMOUS_CODING Variant causes a codon that produces a different amino acid e.g.: Tgg/Cgg, W/R MODERATE initiator_codon_variant NON_SYNONYMOUS_START Variant causes start codon to be mutated into another start codon (the new codon produces a different AA). e.g.: Atg/Ctg, M/L (ATG and CTG can be START codons) LOW stop_retained_variant NON_SYNONYMOUS_STOP Variant causes stop codon to be mutated into another stop codon (the new codon produces a different AA). e.g.: Atg/Ctg, M/L (ATG and CTG can be START codons) LOW protein_protein_contact PROTEIN_PROTEIN_INTERACTION_LOCUS Protein-Protein interaction loci. HIGH structural_interaction_variant PROTEIN_STRUCTURAL_INTERACTION_LOCUS Within protein interacion loci (e.g. two AA that are in contact within the same protein, prossibly helping structural conformation). HIGH rare_amino_acid_variant RARE_AMINO_ACID The variant hits a rare amino acid thus is likely to produce protein loss of function HIGH splice_acceptor_variant SPLICE_SITE_ACCEPTOR The variant hits a splice acceptor site (defined as two bases before exon start, except for the first exon). HIGH splice_donor_variant SPLICE_SITE_DONOR The variant hits a Splice donor site (defined as two bases after coding exon end, except for the last exon). HIGH splice_region_variant SPLICE_SITE_REGION A sequence variant in which a change has occurred within the region of the splice site, either within 1-3 bases of the exon or 3-8 bases of the intron. LOW splice_region_variant SPLICE_SITE_BRANCH A varaint affective putative (Lariat) branch point, located in the intron. LOW splice_region_variant SPLICE_SITE_BRANCH_U12 A varaint affective putative (Lariat) branch point from U12 splicing machinery, located in the intron. MODERATE stop_lost STOP_LOST Variant causes stop codon to be mutated into a non-stop codon e.g.: Tga/Cga, */R HIGH 5_prime_UTR_premature_ start_codon_gain_variant START_GAINED A variant in 5'UTR region produces a three base sequence that can be a START codon. LOW start_lost START_LOST Variant causes start codon to be mutated into a non-start codon. e.g.: aTg/aGg, M/R HIGH stop_gained STOP_GAINED Variant causes a STOP codon e.g.: Cag/Tag, Q/* HIGH synonymous_variant SYNONYMOUS_CODING Variant causes a codon that produces the same amino acid e.g.: Ttg/Ctg, L/L LOW start_retained SYNONYMOUS_START Variant causes start codon to be mutated into another start codon. e.g.: Ttg/Ctg, L/L (TTG and CTG can be START codons) LOW stop_retained_variant SYNONYMOUS_STOP Variant causes stop codon to be mutated into another stop codon. e.g.: taA/taG, */* LOW transcript_variant TRANSCRIPT The variant hits a transcript. MODIFIER feature_ablation TRANSCRIPT_DELETED Deletion of a transcript. HIGH regulatory_region_variant REGULATION The variant hits a known regulatory feature (non-coding). MODIFIER upstream_gene_variant UPSTREAM Upstream of a gene (default length: 5K bases) MODIFIER 3_prime_UTR_variant UTR_3_PRIME Variant hits 3'UTR region MODIFIER 3_prime_UTR_truncation + exon_loss UTR_3_DELETED The variant deletes an exon which is in the 3'UTR of the transcript MODERATE 5_prime_UTR_variant UTR_5_PRIME Variant hits 5'UTR region MODIFIER 5_prime_UTR_truncation + exon_loss_variant UTR_5_DELETED The variant deletes an exon which is in the 5'UTR of the transcript MODERATE sequence_feature + exon_loss_variant NEXT_PROT A 'NextProt' based annotation. Details are provided in the 'feature type' sub-field (ANN), or in the effect details (EFF). MODERATE","title":"Effect prediction details"},{"location":"se_inputoutput/#details-about-rare-amino-acid-effect","text":"These are amino acids that occurs very rarely in an organism. For instance, humans are supposed to use 20 amino acids, but there is also one rare AA. Selenocysteine, single letter code 'U', appears roughly 100 times in the whole genome. The amino acid is so rare that usually it does not appear in codon translation tables. It is encoded as UGA, which usually means a STOP codon. Secondary RNA structures are assumed to enable this special translation. A variant in one of these sites is likely to cause a loss of function in the protein. E.g. in case of a Selenocysteine, a loss of a selenium molecule is likely to cause loss of function. Put it simply, the assumption is that there is a great deal of trouble to get that non-standard amino acid there, so it must be important. RARE_AMINO_ACID mark is used to show that special attention should be paid in these cases. Warning When the variant hits a RARE_AMINO_ACID mark, it is likely that the 'old_AA/new_AA' field will be incorrect. This may happen because the amino acid is not predictable using a codon table.","title":"Details about Rare amino acid effect"},{"location":"se_inputoutput/#details-about-protein-interaction-effects","text":"Protein interactions are calculated from PDB . There are two main types of interactions: protein_protein_contact: These are \"protein-protein\" interaction loci. They are calculated from PDB's co-crystalized structures by inferring pairs of amino acids in different proteins that have atoms closer than 3 Angstrom from each other. structural_interaction_variant: These are \"within protein\" interaction loci, which are likely to be supporting the protein structure. They are calculated from single protein PDB entries, by selecting amino acids that are: a) atom within 3 Angstrom of each other; and b) are far away in the AA sequence (over 20 AA distance). The assumption is that, since they are very close in distance, they must be \"interacting\" and thus important for protein structure.","title":"Details about Protein interaction effects"},{"location":"se_inputoutput/#impact-prediction","text":"SnpEff reports putative variant impact in order to make it easier quickly to categorize and prioritize variants. Warning Impact categories must be used with care, they were created only to help and simplify the filtering process. Obviously, there is no way to predict whether a HIGH impact or a LOW impact variant is the one producing a phenotype of interest. Impact Meaning Example HIGH The variant is assumed to have high (disruptive) impact in the protein, probably causing protein truncation, loss of function or triggering nonsense mediated decay. stop_gained, frameshift_variant MODERATE A non-disruptive variant that might change protein effectiveness. missense_variant, inframe_deletion LOW Assumed to be mostly harmless or unlikely to change protein behavior. synonymous_variant MODIFIER Usually non-coding variants or variants affecting non-coding genes, where predictions are difficult or there is no evidence of impact. exon_variant, downstream_gene_variant","title":"Impact prediction"},{"location":"se_inputoutput/#loss-of-function-lof-and-nonsense-mediated-decay-nmd-predictions","text":"Loss of function ('LOF') and nonsense-mediated decay ('NMD') predictions. In older versions, this prediction was activated using command line option -lof , but as of version 4.0, it is activated by default. Some details on how these variants work, can be found in these slides . Info Starting from version 4.0, this option is activated by default. Analyze if a set of effects are can create a \"Loss Of Function\" and \"Nonsense mediated decays\" effects. Needless to say, this is a prediction based on analysis of groups of \"putative effects\". Proper wet-lab validation is required to infer \"real\" LOF. References: I used the LOF definition used in the following paper A Systematic Survey of Loss-of-Function Variants in Human Protein-Coding Genes . From the paper: We adopted a definition for LoF variants expected to correlate with complete loss of function of the affected transcripts: stop codon-introducing (nonsense) or splice site-disrupting single-nucleotide variants (SNVs), insertion/deletion (indel) variants predicted to disrupt a transcript's reading frame, or larger deletions removing either the first exon or more than 50% of the protein-coding sequence of the affected transcript. Both nonsense SNVs and frameshift indels are enriched toward the 3' end of the affected gene, consistent with a greater tolerance to truncation close to the end of the coding sequence; putative LoF variants identified in the last 5% of the coding region were thus systematically removed from our high-confidence set. Other parameters used for LOF/NMD calculations: Number of bases before last exon-exon junction that nonsense mediated decay is supposed to occur: 50 It is assumed that even with a protein coding change at the last 5% of the protein, the protein could still be functional. It is assumed that even with a protein coding change at the first 5% of the protein: \"..suggesting some disrupted transcripts are rescued by transcriptional reinitiation at an alternative start codon.\" Larger deletions removing either the first exon or more than 50% of the protein-coding sequence of the affected transcript Usage example: # Note: Form version 4.0 onwards, the '-lof' command line option is not required java -Xmx8g -jar snpEff.jar -v \\ -lof \\ GRCh37.75 \\ test.chr22.vcf > test.chr22.ann.vcf SnpEff adds 'LOF' and 'NMD' tags to INFO fields (column 8 in VCF format). LOF and NMD tags have the following format: Gene | ID | num_transcripts | percent_affected Where: Field Description Gene Gene name ID Gene ID (usually ENSEMBL) Num_transcripts Number of transcripts in this gene percent_affected Percentage of transcripts affected by this variant. Example: If we have this effect EFF=stop_gained(LOW|NONSENSE|Gga/Tga|p.Gly163*/c.487G>T|574|GAB4|protein_coding|CODING|ENST00000400588|3|1),... and the corresponding LOF and NMD tags are LOF=(GAB4|ENSG00000215568|4|0.25);NMD=(GAB4|ENSG00000215568|4|0.25) The meaning of the LOF tag is: Field Description Gene GAB4 ID ENSG00000215568 Num_transcripts There are 4 transcripts in this gene percent_affected 25% of transcripts are affected by this variant.","title":"Loss of function (LOF) and nonsense-mediated decay (NMD) predictions"},{"location":"se_inputoutput/#errors-and-warnings","text":"As mentioned int the previous section, the last sub-field in EFF field shows errors or warnings (if any). Here is a description of the errors and warnings: Error Meaning and possible solutions ERROR_CHROMOSOME_NOT_FOUND Chromosome does not exits in reference database. See this FAQ for more details. ERROR_OUT_OF_CHROMOSOME_RANGE This means that the position is higher than chromosome's length. Probably an indicator that your data is not from this reference genome. ERROR_OUT_OF_EXON Exonic information not matching the coordinates. Indicates a problem (or even a bug?) in the database ERROR_MISSING_CDS_SEQUENCE Transcript has no CDS info. Indicates a problem (or even a bug?) in the database Warning Meaning and possible solutions WARNING_REF_DOES_NOT_MATCH_GENOME This means that the REF field does not match the reference genome. Warning! This warning probably indicated there is something really wrong with your data! This happens when your data was aligned to a different reference genome than the one used to create SnpEff's database. If there are many of these warnings, it's a strong indicator that the data doesn't match and all the annotations will be garbage (because you are using the wrong database). Solution: Use the right database to annotate! Due to performance and memory optimizations, SnpEff only checks reference sequence on Exons. WARNING_SEQUENCE_NOT_AVAILABLE For some reason the exon sequence is not available, so we cannot calculate effects. WARNING_TRANSCRIPT_INCOMPLETE A protein coding transcript whose length is non-multiple of 3. This means that information is missing for one or more amino acids. This is usually due to errors in the genomic information (e.g. the genomic databases provided by UCSC or ENSEMBL). Genomic information databases are constantly being improved and are getting more accurate, but some errors still remain. WARNING_TRANSCRIPT_MULTIPLE_STOP_CODONS A protein coding transcript has two or more STOP codons in the middle of the coding sequence (CDS). This should not happen and it usually means the genomic information may have an error in this transcript. This is usually due to errors in the genomic information (e.g. the genomic databases provided by UCSC or ENSEMBL). Genomic information databases are constantly being improved and are getting more accurate, but some errors still remain. WARNING_TRANSCRIPT_NO_START_CODON A protein coding transcript does not have a proper START codon. It is rare that a real transcript does not have a START codon, so this probably indicates errors in genomic information for this transcript (e.g. the genomic databases provided by UCSC or ENSEMBL). Genomic information databases are constantly being improved and are getting more accurate, but some errors still remain.","title":"Errors and Warnings"},{"location":"se_inputoutput/#bed-files","text":"In an enrichment experiment, such as ChIP-Seq, the results are enrichment regions, usually called \"peaks\". It is common for \"peak callers\" (algorithms that detect enrichment), write the results in a BED file. SnpEff can annotate BED files in order to facilitate interpretation of enrichment experiments. Warning Column fifth onwards are ignored when using BED file format and they will be lost in the output file. SnpEff can annotate BED files in order to facilitate interpretation of enrichment experiments. Annotations are added to the fourth column of the BED file. E.g.: $ java -Xmx8g -jar snpEff.jar -i bed BDGP5.69 chipSeq_peaks.bed # SnpEff version 3.3 (build 2013-05-15), by Pablo Cingolani # Command line: SnpEff -i bed BDGP5.69 /home/pcingola/fly_pvuseq/chipSeq/Sample_w1118_IP_w_5hmC/w1118_IP_w_5hmC_peaks.bed # Chromo Start End Name;Effect|Gene|BioType Score 2L 189463 190154 MACS_peak_1;Exon|exon_6_12_RETAINED|FBtr0078122|protein_coding|spen|protein_coding;Exon|exon_5_10_RETAINED|FBtr0078123|protein_coding|spen|protein_coding;Exon|exon_7_13_RETAINED|FBtr0306341|protein_coding|spen|protein_coding;Exon|exon_6_11_RETAINED|FBtr0078121|protein_coding|spen|protein_coding 245.41 2L 195607 196120 MACS_peak_2;Exon|exon_6_12_RETAINED|FBtr0078122|protein_coding|spen|protein_coding;Exon|exon_5_10_RETAINED|FBtr0078123|protein_coding|spen|protein_coding;Exon|exon_7_13_RETAINED|FBtr0306341|protein_coding|spen|protein_coding;Exon|exon_6_11_RETAINED|FBtr0078121|protein_coding|spen|protein_coding 51.22 2L 527253 527972 MACS_peak_3;Intron|intron_2_RETAINED-RETAINED|FBtr0078063|protein_coding|ush|protein_coding 55.97 2L 711439 711764 MACS_peak_4;Intron|intron_1_RETAINED-RETAINED|FBtr0078045|protein_coding|ds|protein_coding 61.16 2L 1365255 1365556 MACS_peak_5;Upstream|FBtr0077927|protein_coding|CG14346|protein_coding;Upstream|FBtr0077926|protein_coding|CG14346|protein_coding;Intergenic|NLaz...CG14346;Upstream|FBtr0077942|protein_coding|NLaz|protein_coding 62.78 2L 1970199 1970405 MACS_peak_6;Upstream|FBtr0077813|protein_coding|Der-1|protein_coding;Intergenic|tRNA:CR31942...Der-1;Downstream|FBtr0077812|tRNA|tRNA:CR31942|tRNA 110.34 2L 3345637 3346152 MACS_peak_7;Intron|intron_2_ALTTENATIVE_3SS-ALTTENATIVE_3SS|FBtr0089979|protein_coding|E23|protein_coding;Intron|intron_3_ALTTENATIVE_3SS-ALTTENATIVE_3SS|FBtr0089981|protein_coding|E23|protein_coding 65.49 2L 4154734 4155027 MACS_peak_8;Intergenic|CG2955...Or24a;Downstream|FBtr0077468|protein_coding|CG2955|protein_coding 76.92 2L 4643232 4643531 MACS_peak_9;Downstream|FBtr0110769|protein_coding|BG642163|protein_coding;Exon|exon_2_2_RETAINED|FBtr0300354|protein_coding|CG15635|protein_coding 76.92 When a peak intersects multiple transcripts or even multiple genes, each annotation is separated by a semicolon. So if you look into the previous results in more detail, the first line looks like this (format edited for readability purposes): 2L 189463 190154 MACS_peak_1;Exon|exon_6_12_RETAINED|FBtr0078122|protein_coding|spen|protein_coding ;Exon|exon_5_10_RETAINED|FBtr0078123|protein_coding|spen|protein_coding ;Exon|exon_7_13_RETAINED|FBtr0306341|protein_coding|spen|protein_coding ;Exon|exon_6_11_RETAINED|FBtr0078121|protein_coding|spen|protein_coding This peak is hitting four transcripts (FBtr0078122, FBtr0078123, FBtr0306341, FBtr0078121) in gene 'spen'.","title":"BED files"},{"location":"se_inputoutput/#exon-naming-convention","text":"The format for the exon identifier is exon_Rank_Total_Type , where: rank is the exon rank in the transcript (position in the transcript) total is the total number of exons in that transcript type is the exon splice type. For instance exon_5_10_RETAINED would be the fifth exon in a 10 exon transcript. This exon is type \"RETAINED\", which means it is not spliced out. Exons are categorized by splicing as follows: NONE : Not spliced RETAINED : All transcripts have this exon SKIPPED : Some transcripts skip it ALTTENATIVE_3SS : Some transcripts have and alternative 3' exon start ALTTENATIVE_5SS : Some transcripts have and alternative 5' exon end MUTUALLY_EXCLUSIVE : Mutually exclusive (respect to other exon) ALTTENATIVE_PROMOMOTER : The first exon is different in some transcripts. ALTTENATIVE_POLY_A : The last exon. See this Wikipedia entry for more information on exon splice types.","title":"Exon naming convention"},{"location":"se_inputoutput/#intron-naming-convention","text":"Similarly to exons, introns are named as intron_Rank_ExonTypeBefore-ExonTypeAfter , where: Rank : the rank number for this intron in the transcript ExonTypeBefore : the splicing type of the exon preceding this intron (see exon naming convention for details). ExonTypeAfter : the splicing type of the after this intron (see exon naming convention for details). For instance intron_9_SKIPPED-RETAINED would be the ninth intron of the transcript. The intron is preceded by a SKIPPED exon and followed by a RETAINED exon.","title":"Intron naming convention"},{"location":"se_integration/","text":"Integration: GATK and Galaxy SnpEff is integrated with other tools commonly used in sequencing data analysis pipelines. Most notably Galaxy and Broad Institute's Genome Analysis Toolkit ( GATK ) projects support SnpEff. By using standards, such as VCF, SnpEff makes it easy to integrate with other programs. Integration: GATK In order to make sure SnpEff and GATK understand each other, you must activate GATK compatibility in SnpEff by using the -o gatk command line option. The reason for using '-o gatk' is that, even though both GATK and SnpEff use VCF format, SnpEff has recently updated the EFF sub-field format and this might cause some trouble (since GATK still uses the original version). Warning GATK only picks one effect. Indeed, the GATK team decided to only report the effect having the highest impact. This was done intentionally for the sake of brevity, in a 'less is more' spirit. You can get the full effect by using snpEff independently, instead of using it within GATK framework. Script example: In this example we combine SnpEff and GATK's VariantAnnotator (you can find this script in snpEff/scripts/ directory of the distribution) #!/bin/sh #------------------------------------------------------------------------------- # Files #------------------------------------------------------------------------------- in=$1 # Input VCF file eff=`dirname $in`/`basename $in .vcf`.ann.vcf # SnpEff annotated VCF file out=`dirname $in`/`basename $in .vcf`.gatk.vcf # Output VCF file (annotated by GATK) ref=$HOME/snpEff/data/genomes/hg19.fa # Reference genome file dict=`dirname $ref`/`basename $ref .fa`.dict # Reference genome: Dictionary file #------------------------------------------------------------------------------- # Path to programs and libraries #------------------------------------------------------------------------------- gatk=$HOME/tools/gatk/GenomeAnalysisTK.jar picard=$HOME/tools/picard/ snpeff=$HOME/snpEff/snpEff.jar #------------------------------------------------------------------------------- # Main #------------------------------------------------------------------------------- # Create genome index file echo echo \"Indexing Genome reference FASTA file: $ref\" samtools faidx $ref # Create dictionary echo echo \"Creating Genome reference dictionary file: $dict\" java -jar $picard/CreateSequenceDictionary.jar R= $ref O= $dict # Annotate echo echo \"Annotate using SnpEff\" echo \" Input file : $in\" echo \" Output file : $eff\" java -Xmx8g -jar $snpeff -c $HOME/snpEff/snpEff.config -v -o gatk hg19 $in > $eff # Use GATK echo echo \"Annotating using GATK's VariantAnnotator:\" echo \" Input file : $in\" echo \" Output file : $out\" java -Xmx8g -jar $gatk \\ -T VariantAnnotator \\ -R $ref \\ -A SnpEff \\ --variant $in \\ --snpEffFile $eff \\ -L $in \\ -o $out Warning Important: In order for this to work, GATK requires that the Genome Reference file should have the chromosomes in karotyping order (largest to smallest chromosomes, followed by the X, Y, and MT). Your VCF file should also respect that order. Now we can use the script: $ ~/snpEff/scripts/gatk.sh zzz.vcf Indexing Genome reference FASTA file: /home/pcingola/snpEff/data/genomes/hg19.fa Creating Genome reference dictionary file: /home/pcingola/snpEff/data/genomes/hg19.dict [Fri Apr 12 11:23:12 EDT 2013] net.sf.picard.sam.CreateSequenceDictionary REFERENCE=/home/pcingola/snpEff/data/genomes/hg19.fa OUTPUT=/home/pcingola/snpEff/data/genomes/hg19.dict TRUNCATE_NAMES_AT_WHITESPACE=true NUM_SEQUENCES=2147483647 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false [Fri Apr 12 11:23:12 EDT 2013] Executing as pcingola@localhost.localdomain on Linux 3.6.11-4.fc16.x86_64 amd64; OpenJDK 64-Bit Server VM 1.6.0_24-b24; Picard version: 1.89(1408) [Fri Apr 12 11:23:12 EDT 2013] net.sf.picard.sam.CreateSequenceDictionary done. Elapsed time: 0.00 minutes. Runtime.totalMemory()=141164544 To get help, see http://picard.sourceforge.net/index.shtml#GettingHelp Exception in thread \"main\" net.sf.picard.PicardException: /home/pcingola/snpEff/data/genomes/hg19.dict already exists. Delete this file and try again, or specify a different output file. at net.sf.picard.sam.CreateSequenceDictionary.doWork(CreateSequenceDictionary.java:114) at net.sf.picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:177) at net.sf.picard.sam.CreateSequenceDictionary.main(CreateSequenceDictionary.java:93) Annotate using SnpEff Input file : zzz.vcf Output file : ./zzz.ann.vcf 00:00:00.000 Reading configuration file '/home/pcingola/snpEff/snpEff.config' 00:00:00.173 done 00:00:00.173 Reading database for genome version 'hg19' from file '/home/pcingola//snpEff/data/hg19/snpEffectPredictor.bin' (this might take a while) 00:00:11.860 done 00:00:11.885 Building interval forest 00:00:17.755 done. 00:00:18.391 Genome stats : # Genome name : 'Homo_sapiens (USCS)' # Genome version : 'hg19' # Has protein coding info : true # Genes : 25933 # Protein coding genes : 20652 # Transcripts : 44253 # Avg. transcripts per gene : 1.71 # Protein coding transcripts : 36332 # Cds : 365442 # Exons : 429543 # Exons with sequence : 409789 # Exons without sequence : 19754 # Avg. exons per transcript : 9.71 # Number of chromosomes : 50 # Chromosomes names [sizes] : '1' [249250621] '2' [243199373] '3' [198022430] '4' [191154276] '5' [180915260] '6' [171115067] '7' [159138663] 'X' [155270560] '8' [146364022] '9' [141213431] '10' [135534747] '11' [135006516] '12' [133851895] '13' [115169878] '14' [107349540] '15' [102531392] '16' [90354753] '17' [81195210] '18' [78077248] '20' [63025520] 'Y' [59373566] '19' [59128983] '22' [51304566] '21' [48129895] '6_ssto_hap7' [4905564] '6_mcf_hap5' [4764535] '6_cox_hap2' [4734611] '6_mann_hap4' [4679971] '6_qbl_hap6' [4609904] '6_dbb_hap3' [4572120] '6_apd_hap1' [4383650] '17_ctg5_hap1' [1574839] '4_ctg9_hap1' [582546] 'Un_gl000220' [156152] '19_gl000209_random' [145745] 'Un_gl000213' [139339] '17_gl000205_random' [119732] 'Un_gl000223' [119730] '4_gl000194_random' [115071] 'Un_gl000228' [114676] 'Un_gl000219' [99642] 'Un_gl000218' [97454] 'Un_gl000211' [93165] 'Un_gl000222' [89310] '4_gl000193_random' [88375] '7_gl000195_random' [86719] '1_gl000192_random' [79327] 'Un_gl000212' [60768] '1_gl000191_random' [50281] 'M' [16571] 00:00:18.391 Predicting variants 00:00:20.267 Creating summary file: snpEff_summary.html 00:00:20.847 Creating genes file: snpEff_genes.txt 00:00:25.026 done. 00:00:25.036 Logging 00:00:26.037 Checking for updates... Annotating using GATK's VariantAnnotator: Input file : zzz.vcf Output file : ./zzz.gatk.vcf INFO 11:23:41,316 ArgumentTypeDescriptor - Dynamically determined type of zzz.vcf to be VCF INFO 11:23:41,343 HelpFormatter - -------------------------------------------------------------------------------- INFO 11:23:41,344 HelpFormatter - The Genome Analysis Toolkit (GATK) v2.4-9-g532efad, Compiled 2013/03/19 07:35:36 INFO 11:23:41,344 HelpFormatter - Copyright (c) 2010 The Broad Institute INFO 11:23:41,344 HelpFormatter - For support and documentation go to http://www.broadinstitute.org/gatk INFO 11:23:41,347 HelpFormatter - Program Args: -T VariantAnnotator -R /home/pcingola/snpEff/data/genomes/hg19.fa -A SnpEff --variant zzz.vcf --snpEffFile ./zzz.ann.vcf -L zzz.vcf -o ./zzz.gatk.vcf INFO 11:23:41,347 HelpFormatter - Date/Time: 2013/04/12 11:23:41 INFO 11:23:41,348 HelpFormatter - -------------------------------------------------------------------------------- INFO 11:23:41,348 HelpFormatter - -------------------------------------------------------------------------------- INFO 11:23:41,353 ArgumentTypeDescriptor - Dynamically determined type of zzz.vcf to be VCF INFO 11:23:41,356 ArgumentTypeDescriptor - Dynamically determined type of ./zzz.ann.vcf to be VCF INFO 11:23:41,399 GenomeAnalysisEngine - Strictness is SILENT INFO 11:23:41,466 GenomeAnalysisEngine - Downsampling Settings: Method: BY_SAMPLE, Target Coverage: 1000 INFO 11:23:41,480 RMDTrackBuilder - Loading Tribble index from disk for file zzz.vcf INFO 11:23:41,503 RMDTrackBuilder - Loading Tribble index from disk for file ./zzz.ann.vcf WARN 11:23:41,505 RMDTrackBuilder - Index file /data/pcingola/Documents/projects/snpEff/gatk_test/./zzz.ann.vcf.idx is out of date (index older than input file), deleting and updating the index file INFO 11:23:41,506 RMDTrackBuilder - Creating Tribble index in memory for file ./zzz.ann.vcf INFO 11:23:41,914 RMDTrackBuilder - Writing Tribble index to disk for file /data/pcingola/Documents/projects/snpEff/gatk_test/./zzz.ann.vcf.idx INFO 11:23:42,076 IntervalUtils - Processing 33411 bp from intervals INFO 11:23:42,125 GenomeAnalysisEngine - Creating shard strategy for 0 BAM files INFO 11:23:42,134 GenomeAnalysisEngine - Done creating shard strategy INFO 11:23:42,134 ProgressMeter - [INITIALIZATION COMPLETE; STARTING PROCESSING] INFO 11:23:42,135 ProgressMeter - Location processed.sites runtime per.1M.sites completed total.runtime remaining INFO 11:23:49,268 VariantAnnotator - Processed 9966 loci. INFO 11:23:49,280 ProgressMeter - done 3.34e+04 7.0 s 3.6 m 100.0% 7.0 s 0.0 s INFO 11:23:49,280 ProgressMeter - Total runtime 7.15 secs, 0.12 min, 0.00 hours INFO 11:23:49,953 GATKRunReport - Uploaded run statistics report to AWS S3 Integration: Galaxy In order to install SnpEff in your own Galaxy server, you can use the galaxy/*.xml files provided in the main distribution. This is a screen capture from a Galaxy server (click to enlarge): Installing SnpEff in a Galaxy server: # Set variable to snpEff install dir (we only use it for this install script) export snpEffDir=\"$HOME/snpEff\" # Go to your galaxy 'tools' dir cd galaxy-dist/tools # Create a directory and copy the XML config files from SnpEff's distribution mkdir snpEff cd snpEff/ cp $snpEffDir/galaxy/* . # Create links to JAR files ln -s $snpEffDir/snpEff.jar ln -s $snpEffDir/SnpSift.jar # Link to config file ln -s $snpEffDir/snpEff.config # Allow scripts execution chmod a+x *.{pl,sh} # Copy genomes information cd ../.. cp $snpEffDir/galaxy/tool-data/snpEff_genomes.loc tool-data/ # Edit Galaxy's tool_conf.xml and add all the tools vi tool_conf.xml -------------------- Begin: Edit tool_conf.xml -------------------- <!-- Add this section to tool_conf.xml file in your galaxy distribution Note: The following lines should be added at the end of the file, right before \"</toolbox>\" line --> <section name=\"snpEff tools\" id=\"snpEff_tools\"> <tool file=\"snpEff/snpEff.xml\" /> <tool file=\"snpEff/snpEff_download.xml\" /> <tool file=\"snpEff/snpSift_annotate.xml\" /> <tool file=\"snpEff/snpSift_caseControl.xml\" /> <tool file=\"snpEff/snpSift_filter.xml\" /> <tool file=\"snpEff/snpSift_int.xml\" /> </section> -------------------- End: Edit tool_conf.xml -------------------- # Run galaxy and check that the new menus appear ./run.sh","title":"Integration. GATK and Galaxy"},{"location":"se_integration/#integration-gatk-and-galaxy","text":"SnpEff is integrated with other tools commonly used in sequencing data analysis pipelines. Most notably Galaxy and Broad Institute's Genome Analysis Toolkit ( GATK ) projects support SnpEff. By using standards, such as VCF, SnpEff makes it easy to integrate with other programs.","title":"Integration: GATK and Galaxy"},{"location":"se_integration/#integration-gatk","text":"In order to make sure SnpEff and GATK understand each other, you must activate GATK compatibility in SnpEff by using the -o gatk command line option. The reason for using '-o gatk' is that, even though both GATK and SnpEff use VCF format, SnpEff has recently updated the EFF sub-field format and this might cause some trouble (since GATK still uses the original version). Warning GATK only picks one effect. Indeed, the GATK team decided to only report the effect having the highest impact. This was done intentionally for the sake of brevity, in a 'less is more' spirit. You can get the full effect by using snpEff independently, instead of using it within GATK framework. Script example: In this example we combine SnpEff and GATK's VariantAnnotator (you can find this script in snpEff/scripts/ directory of the distribution) #!/bin/sh #------------------------------------------------------------------------------- # Files #------------------------------------------------------------------------------- in=$1 # Input VCF file eff=`dirname $in`/`basename $in .vcf`.ann.vcf # SnpEff annotated VCF file out=`dirname $in`/`basename $in .vcf`.gatk.vcf # Output VCF file (annotated by GATK) ref=$HOME/snpEff/data/genomes/hg19.fa # Reference genome file dict=`dirname $ref`/`basename $ref .fa`.dict # Reference genome: Dictionary file #------------------------------------------------------------------------------- # Path to programs and libraries #------------------------------------------------------------------------------- gatk=$HOME/tools/gatk/GenomeAnalysisTK.jar picard=$HOME/tools/picard/ snpeff=$HOME/snpEff/snpEff.jar #------------------------------------------------------------------------------- # Main #------------------------------------------------------------------------------- # Create genome index file echo echo \"Indexing Genome reference FASTA file: $ref\" samtools faidx $ref # Create dictionary echo echo \"Creating Genome reference dictionary file: $dict\" java -jar $picard/CreateSequenceDictionary.jar R= $ref O= $dict # Annotate echo echo \"Annotate using SnpEff\" echo \" Input file : $in\" echo \" Output file : $eff\" java -Xmx8g -jar $snpeff -c $HOME/snpEff/snpEff.config -v -o gatk hg19 $in > $eff # Use GATK echo echo \"Annotating using GATK's VariantAnnotator:\" echo \" Input file : $in\" echo \" Output file : $out\" java -Xmx8g -jar $gatk \\ -T VariantAnnotator \\ -R $ref \\ -A SnpEff \\ --variant $in \\ --snpEffFile $eff \\ -L $in \\ -o $out Warning Important: In order for this to work, GATK requires that the Genome Reference file should have the chromosomes in karotyping order (largest to smallest chromosomes, followed by the X, Y, and MT). Your VCF file should also respect that order. Now we can use the script: $ ~/snpEff/scripts/gatk.sh zzz.vcf Indexing Genome reference FASTA file: /home/pcingola/snpEff/data/genomes/hg19.fa Creating Genome reference dictionary file: /home/pcingola/snpEff/data/genomes/hg19.dict [Fri Apr 12 11:23:12 EDT 2013] net.sf.picard.sam.CreateSequenceDictionary REFERENCE=/home/pcingola/snpEff/data/genomes/hg19.fa OUTPUT=/home/pcingola/snpEff/data/genomes/hg19.dict TRUNCATE_NAMES_AT_WHITESPACE=true NUM_SEQUENCES=2147483647 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false [Fri Apr 12 11:23:12 EDT 2013] Executing as pcingola@localhost.localdomain on Linux 3.6.11-4.fc16.x86_64 amd64; OpenJDK 64-Bit Server VM 1.6.0_24-b24; Picard version: 1.89(1408) [Fri Apr 12 11:23:12 EDT 2013] net.sf.picard.sam.CreateSequenceDictionary done. Elapsed time: 0.00 minutes. Runtime.totalMemory()=141164544 To get help, see http://picard.sourceforge.net/index.shtml#GettingHelp Exception in thread \"main\" net.sf.picard.PicardException: /home/pcingola/snpEff/data/genomes/hg19.dict already exists. Delete this file and try again, or specify a different output file. at net.sf.picard.sam.CreateSequenceDictionary.doWork(CreateSequenceDictionary.java:114) at net.sf.picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:177) at net.sf.picard.sam.CreateSequenceDictionary.main(CreateSequenceDictionary.java:93) Annotate using SnpEff Input file : zzz.vcf Output file : ./zzz.ann.vcf 00:00:00.000 Reading configuration file '/home/pcingola/snpEff/snpEff.config' 00:00:00.173 done 00:00:00.173 Reading database for genome version 'hg19' from file '/home/pcingola//snpEff/data/hg19/snpEffectPredictor.bin' (this might take a while) 00:00:11.860 done 00:00:11.885 Building interval forest 00:00:17.755 done. 00:00:18.391 Genome stats : # Genome name : 'Homo_sapiens (USCS)' # Genome version : 'hg19' # Has protein coding info : true # Genes : 25933 # Protein coding genes : 20652 # Transcripts : 44253 # Avg. transcripts per gene : 1.71 # Protein coding transcripts : 36332 # Cds : 365442 # Exons : 429543 # Exons with sequence : 409789 # Exons without sequence : 19754 # Avg. exons per transcript : 9.71 # Number of chromosomes : 50 # Chromosomes names [sizes] : '1' [249250621] '2' [243199373] '3' [198022430] '4' [191154276] '5' [180915260] '6' [171115067] '7' [159138663] 'X' [155270560] '8' [146364022] '9' [141213431] '10' [135534747] '11' [135006516] '12' [133851895] '13' [115169878] '14' [107349540] '15' [102531392] '16' [90354753] '17' [81195210] '18' [78077248] '20' [63025520] 'Y' [59373566] '19' [59128983] '22' [51304566] '21' [48129895] '6_ssto_hap7' [4905564] '6_mcf_hap5' [4764535] '6_cox_hap2' [4734611] '6_mann_hap4' [4679971] '6_qbl_hap6' [4609904] '6_dbb_hap3' [4572120] '6_apd_hap1' [4383650] '17_ctg5_hap1' [1574839] '4_ctg9_hap1' [582546] 'Un_gl000220' [156152] '19_gl000209_random' [145745] 'Un_gl000213' [139339] '17_gl000205_random' [119732] 'Un_gl000223' [119730] '4_gl000194_random' [115071] 'Un_gl000228' [114676] 'Un_gl000219' [99642] 'Un_gl000218' [97454] 'Un_gl000211' [93165] 'Un_gl000222' [89310] '4_gl000193_random' [88375] '7_gl000195_random' [86719] '1_gl000192_random' [79327] 'Un_gl000212' [60768] '1_gl000191_random' [50281] 'M' [16571] 00:00:18.391 Predicting variants 00:00:20.267 Creating summary file: snpEff_summary.html 00:00:20.847 Creating genes file: snpEff_genes.txt 00:00:25.026 done. 00:00:25.036 Logging 00:00:26.037 Checking for updates... Annotating using GATK's VariantAnnotator: Input file : zzz.vcf Output file : ./zzz.gatk.vcf INFO 11:23:41,316 ArgumentTypeDescriptor - Dynamically determined type of zzz.vcf to be VCF INFO 11:23:41,343 HelpFormatter - -------------------------------------------------------------------------------- INFO 11:23:41,344 HelpFormatter - The Genome Analysis Toolkit (GATK) v2.4-9-g532efad, Compiled 2013/03/19 07:35:36 INFO 11:23:41,344 HelpFormatter - Copyright (c) 2010 The Broad Institute INFO 11:23:41,344 HelpFormatter - For support and documentation go to http://www.broadinstitute.org/gatk INFO 11:23:41,347 HelpFormatter - Program Args: -T VariantAnnotator -R /home/pcingola/snpEff/data/genomes/hg19.fa -A SnpEff --variant zzz.vcf --snpEffFile ./zzz.ann.vcf -L zzz.vcf -o ./zzz.gatk.vcf INFO 11:23:41,347 HelpFormatter - Date/Time: 2013/04/12 11:23:41 INFO 11:23:41,348 HelpFormatter - -------------------------------------------------------------------------------- INFO 11:23:41,348 HelpFormatter - -------------------------------------------------------------------------------- INFO 11:23:41,353 ArgumentTypeDescriptor - Dynamically determined type of zzz.vcf to be VCF INFO 11:23:41,356 ArgumentTypeDescriptor - Dynamically determined type of ./zzz.ann.vcf to be VCF INFO 11:23:41,399 GenomeAnalysisEngine - Strictness is SILENT INFO 11:23:41,466 GenomeAnalysisEngine - Downsampling Settings: Method: BY_SAMPLE, Target Coverage: 1000 INFO 11:23:41,480 RMDTrackBuilder - Loading Tribble index from disk for file zzz.vcf INFO 11:23:41,503 RMDTrackBuilder - Loading Tribble index from disk for file ./zzz.ann.vcf WARN 11:23:41,505 RMDTrackBuilder - Index file /data/pcingola/Documents/projects/snpEff/gatk_test/./zzz.ann.vcf.idx is out of date (index older than input file), deleting and updating the index file INFO 11:23:41,506 RMDTrackBuilder - Creating Tribble index in memory for file ./zzz.ann.vcf INFO 11:23:41,914 RMDTrackBuilder - Writing Tribble index to disk for file /data/pcingola/Documents/projects/snpEff/gatk_test/./zzz.ann.vcf.idx INFO 11:23:42,076 IntervalUtils - Processing 33411 bp from intervals INFO 11:23:42,125 GenomeAnalysisEngine - Creating shard strategy for 0 BAM files INFO 11:23:42,134 GenomeAnalysisEngine - Done creating shard strategy INFO 11:23:42,134 ProgressMeter - [INITIALIZATION COMPLETE; STARTING PROCESSING] INFO 11:23:42,135 ProgressMeter - Location processed.sites runtime per.1M.sites completed total.runtime remaining INFO 11:23:49,268 VariantAnnotator - Processed 9966 loci. INFO 11:23:49,280 ProgressMeter - done 3.34e+04 7.0 s 3.6 m 100.0% 7.0 s 0.0 s INFO 11:23:49,280 ProgressMeter - Total runtime 7.15 secs, 0.12 min, 0.00 hours INFO 11:23:49,953 GATKRunReport - Uploaded run statistics report to AWS S3","title":"Integration: GATK"},{"location":"se_integration/#integration-galaxy","text":"In order to install SnpEff in your own Galaxy server, you can use the galaxy/*.xml files provided in the main distribution. This is a screen capture from a Galaxy server (click to enlarge): Installing SnpEff in a Galaxy server: # Set variable to snpEff install dir (we only use it for this install script) export snpEffDir=\"$HOME/snpEff\" # Go to your galaxy 'tools' dir cd galaxy-dist/tools # Create a directory and copy the XML config files from SnpEff's distribution mkdir snpEff cd snpEff/ cp $snpEffDir/galaxy/* . # Create links to JAR files ln -s $snpEffDir/snpEff.jar ln -s $snpEffDir/SnpSift.jar # Link to config file ln -s $snpEffDir/snpEff.config # Allow scripts execution chmod a+x *.{pl,sh} # Copy genomes information cd ../.. cp $snpEffDir/galaxy/tool-data/snpEff_genomes.loc tool-data/ # Edit Galaxy's tool_conf.xml and add all the tools vi tool_conf.xml -------------------- Begin: Edit tool_conf.xml -------------------- <!-- Add this section to tool_conf.xml file in your galaxy distribution Note: The following lines should be added at the end of the file, right before \"</toolbox>\" line --> <section name=\"snpEff tools\" id=\"snpEff_tools\"> <tool file=\"snpEff/snpEff.xml\" /> <tool file=\"snpEff/snpEff_download.xml\" /> <tool file=\"snpEff/snpSift_annotate.xml\" /> <tool file=\"snpEff/snpSift_caseControl.xml\" /> <tool file=\"snpEff/snpSift_filter.xml\" /> <tool file=\"snpEff/snpSift_int.xml\" /> </section> -------------------- End: Edit tool_conf.xml -------------------- # Run galaxy and check that the new menus appear ./run.sh","title":"Integration: Galaxy"},{"location":"se_introduction/","text":"SnpEff SnpEff is a variant annotation and effect prediction tool. It annotates and predicts the effects of genetic variants (such as amino acid changes). Download & Install Download and installing SnpEff it pretty easy, take a look at the download page . Building from source Take a look at the \"Source code\" section. SnpEff Summary A typical SnpEff use case would be: Input: The inputs are predicted variants (SNPs, insertions, deletions and MNPs). The input file is usually obtained as a result of a sequencing experiment, and it is usually in variant call format (VCF). Output: SnpEff analyzes the input variants. It annotates the variants and calculates the effects they produce on known genes (e.g. amino acid changes). A list of effects and annotations that SnpEff can calculate can be found here . Variants By genetic variant we mean difference between a genome and a \"reference\" genome. As an example, imagine we are sequencing a \"sample\". Here \"sample\" can mean anything that you are interested in studying, from a cell culture, to a mouse or a cancer patient. It is a standard procedure to compare your sample sequences against the corresponding \"reference genome\". For instance you may compare the cancer patient genome against the \"reference genome\". In a typical sequencing experiment, you will find many places in the genome where your sample differs from the reference genome. These are called \"genomic variants\" or just \"variants\". Typically, variants are categorized as follows: Type What is means Example SNP Single-Nucleotide Polymorphism Reference = 'A', Sample = 'C' Ins Insertion Reference = 'A', Sample = 'AGT' Del Deletion Reference = 'AC', Sample = 'C' MNP Multiple-nucleotide polymorphism Reference = 'ATA', Sample = 'GTC' MIXED Multiple-nucleotide and an InDel Reference = 'ATA', Sample = 'GTCAGT' This is not a comprehensive list, it is just to give you an idea. Annotations So, you have a huge file describing all the differences between your sample and the reference genome. But you want to know more about these variants than just their genetic coordinates. E.g.: Are they in a gene? In an exon? Do they change protein coding? Do they cause premature stop codons? SnpEff can help you answer all these questions. The process of adding this information about the variants is called \"Annotation\". SnpEff provides several degrees of annotations, from simple (e.g. which gene is each variant affecting) to extremely complex annotations (e.g. will this non-coding variant affect the expression of a gene?). It should be noted that the more complex the annotations, the more it relies in computational predictions. Such computational predictions can be incorrect, so results from SnpEff (or any prediction algorithm) cannot be trusted blindly, they must be analyzed and independently validated by corresponding wet-lab experiments. Citing If you are using SnpEff or SnpSift, please cite our work as shown here . Thank you! SnpEff Features The following table shows the main SnpEff features: Feature Comment Local install SnpEff can be installed in your local computer or servers. Local installations are preferred for processing genomic data. As opposed to remote web-based services, running a program locally has many advantages: There no need to upload huge genomic dataset. Processing doesn't depend on availability or processing capacity of remote servers. Service continuity: no need to worry if a remote service will be maintained in the future. Security and confidentiality issues of uploading data to third party servers are not a problem. Avoid legal problems of processing clinical data on \"outside\" servers. Multi platform SnpEff is written in Java. It runs on Unix / Linux, OS.X and Windows. Simple installation Installation is as simple as downloading a ZIP file and double clicking on it. Genomes Human genome, as well as all model organisms are supported. Over 2,500 genomes are supported, which includes most mammalian, plant, bacterial and fungal genomes with published genomic data. Speed SnpEff is really fast. It can annotate up to 1,000,000 variants per minute. GATK&Galaxy integration SnpEff can be easily integrated with GATK and Galaxy pipelines. GUI Web based user interface via Galaxy project Input and Output formats SnpEff accepts input files in the following format: VCF format, which is the de-facto standard for sequencing variants. BED format: To annotate enrichment experiments (e.g. ChIP-Seq peaks) or other genomic data. Variants supported SnpEff can annotate SNPs, MNPs, insertions and deletions. Support for mixed variants and structural variants is available (although sometimes limited). Effect supported Many effects are calculated: such as SYNONYMOUS_CODING, NON_SYNONYMOUS_CODING, FRAME_SHIFT, STOP_GAINED just to name a few. Variant impact SnpEff provides a simple assessment of the putative impact of the variant (e.g. HIGH, MODERATE or LOW impact). Cancer tissue analysis Somatic vs Germline mutations can be calculated on the fly. This is very useful for the cancer researcher community. Loss of Function (LOF) assessment SnpEff can estimate if a variant is deemed to have a loss of function on the protein. Nonsense mediate decay (NMD) assessment Some mutations may cause mRNA to be degraded thus not translated into a protein. NMD analysis marks mutations that are estimated to trigger nonsense mediated decay. HGVS notation SnpEff can provide output in HGVS notation, which is quite popular in clinical and translation research environments. User annotations A user can provide custom annotations (by means of BED files). Public databases SnpEff can annotate using publicly available data from well known databases, for instance: ENCODE datasets are supported by SnpEff (by means of BigWig files provided by ENCODE project). Epigenome Roadmap provides data-sets that can be used with SnpEff. TFBS Transcription factor binding site predictions can be annotated. Motif data used in this annotations is generates by Jaspar and ENSEBML projects NextProt database can be used to annotate protein domains as well as important functional sites in a protein (e.g. phosphorilation site) Common variants (dbSnp) Annotating \"common\" variants from dbSnp and 1,000 Genomes can be easily done (see SnpSift annotate ). Gwas catalog Support for GWAS catalog annotations (see SnpSift gwasCat ) Conservation scores PhastCons conservation score annotations support (see SnpSift phastCons ) DbNsfp A comprehensive database providing many annotations and scores, such as: SIFT , Polyphen2 , GERP++ , PhyloP , MutationTaster , SiPhy , Interpro , Haploinsufficiency , etc. (via SnpSift). See SnpSift dbnsfp for details. Non-coding annotations Regulatory and non-coding annotations are supported for different tissues and cell lines. Annotations supported include PolII,H3K27ac, H3K4me2, H3K4me3, H3K27me3, CTCF, H3K36me3, just to name a few. Gene Sets annotations Gene sets (MSigDb, GO, BioCarta, KEGG, Reactome, etc.) can be used to annotate via SnpSift geneSets command. Databases In order to produce the annotations, SnpEff requires a database. We build these databases using information from trusted resources. Info By default SnpEff downloads and installs databases automatically (since version 4.0) Currently, there are pre-built database for over 20,000 reference genomes. This means that most cases are covered. In some very rare occasions, people need to build a database for an organism not currently supported (e.g. the genome is not publicly available). In most cases, this can be done and there is a section of this manual teaching how to build your own SnpEff database. Which databases are supported? You can find out all the supported databases by running the databases command: $ java -jar snpEff.jar databases | less This command shows the database name, genome name and source data (where was the genome reference data obtained from). Keep in mind that many times I use ENSEMBL reference genomes, so the name would be GRCh37 instead of hg19 , or GRCm38 instead of mm10 , and so on. Example: Finding a database: So, let's say you want to find out the name of the latest mouse (Mus.Musculus) database. You can runs something like this: $ java -jar snpEff.jar databases | grep -i musculus 129S1_SvImJ_v1.99 Mus_musculus_129s1svimj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_129S1_SvImJ_v1.99.zip AKR_J_v1.99 Mus_musculus_akrj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AKR_J_v1.99.zip A_J_v1.99 Mus_musculus_aj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_A_J_v1.99.zip BALB_cJ_v1.99 Mus_musculus_balbcj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_BALB_cJ_v1.99.zip C3H_HeJ_v1.99 Mus_musculus_c3hhej https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_C3H_HeJ_v1.99.zip C57BL_6NJ_v1.99 Mus_musculus_c57bl6nj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_C57BL_6NJ_v1.99.zip CAST_EiJ_v1.99 Mus_musculus_casteij https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_CAST_EiJ_v1.99.zip CBA_J_v1.99 Mus_musculus_cbaj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_CBA_J_v1.99.zip DBA_2J_v1.99 Mus_musculus_dba2j https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_DBA_2J_v1.99.zip FVB_NJ_v1.99 Mus_musculus_fvbnj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_FVB_NJ_v1.99.zip GRCm38.75 Mus_musculus https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_GRCm38.75.zip GRCm38.99 Mus_musculus https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_GRCm38.99.zip LP_J_v1.99 Mus_musculus_lpj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_LP_J_v1.99.zip NOD_ShiLtJ_v1.99 Mus_musculus_nodshiltj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_NOD_ShiLtJ_v1.99.zip NZO_HlLtJ_v1.99 Mus_musculus_nzohlltj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_NZO_HlLtJ_v1.99.zip PWK_PhJ_v1.99 Mus_musculus_pwkphj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_PWK_PhJ_v1.99.zip WSB_EiJ_v1.99 Mus_musculus_wsbeij https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_WSB_EiJ_v1.99.zip testMm37.61 Mus_musculus https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_testMm37.61.zip At the time of writing this, you have 10 options (obviously this will change in the future). Some are databases are GRCm version 37 (i.e. mm9) and some are version 38 (i.e. mm10). Since it is generally better to use the latest release, you should probably pick GRCm38.74 . Again, this is an example of the version numbers at the time of writing this paragraph, in the future there will be other releases and you should update to the corresponding version. Unsupported reference genomes: If your reference genome of interest is not supported yet (i.e. there is no database available), you can build a database yourself (see Building databases ). If you have problems adding you own organism, send the issue to SnpEff repository and I'll do my best to help you out.","title":"Introduction"},{"location":"se_introduction/#snpeff","text":"SnpEff is a variant annotation and effect prediction tool. It annotates and predicts the effects of genetic variants (such as amino acid changes).","title":"SnpEff"},{"location":"se_introduction/#download-install","text":"Download and installing SnpEff it pretty easy, take a look at the download page .","title":"Download &amp; Install"},{"location":"se_introduction/#building-from-source","text":"Take a look at the \"Source code\" section.","title":"Building from source"},{"location":"se_introduction/#snpeff-summary","text":"A typical SnpEff use case would be: Input: The inputs are predicted variants (SNPs, insertions, deletions and MNPs). The input file is usually obtained as a result of a sequencing experiment, and it is usually in variant call format (VCF). Output: SnpEff analyzes the input variants. It annotates the variants and calculates the effects they produce on known genes (e.g. amino acid changes). A list of effects and annotations that SnpEff can calculate can be found here . Variants By genetic variant we mean difference between a genome and a \"reference\" genome. As an example, imagine we are sequencing a \"sample\". Here \"sample\" can mean anything that you are interested in studying, from a cell culture, to a mouse or a cancer patient. It is a standard procedure to compare your sample sequences against the corresponding \"reference genome\". For instance you may compare the cancer patient genome against the \"reference genome\". In a typical sequencing experiment, you will find many places in the genome where your sample differs from the reference genome. These are called \"genomic variants\" or just \"variants\". Typically, variants are categorized as follows: Type What is means Example SNP Single-Nucleotide Polymorphism Reference = 'A', Sample = 'C' Ins Insertion Reference = 'A', Sample = 'AGT' Del Deletion Reference = 'AC', Sample = 'C' MNP Multiple-nucleotide polymorphism Reference = 'ATA', Sample = 'GTC' MIXED Multiple-nucleotide and an InDel Reference = 'ATA', Sample = 'GTCAGT' This is not a comprehensive list, it is just to give you an idea. Annotations So, you have a huge file describing all the differences between your sample and the reference genome. But you want to know more about these variants than just their genetic coordinates. E.g.: Are they in a gene? In an exon? Do they change protein coding? Do they cause premature stop codons? SnpEff can help you answer all these questions. The process of adding this information about the variants is called \"Annotation\". SnpEff provides several degrees of annotations, from simple (e.g. which gene is each variant affecting) to extremely complex annotations (e.g. will this non-coding variant affect the expression of a gene?). It should be noted that the more complex the annotations, the more it relies in computational predictions. Such computational predictions can be incorrect, so results from SnpEff (or any prediction algorithm) cannot be trusted blindly, they must be analyzed and independently validated by corresponding wet-lab experiments.","title":"SnpEff Summary"},{"location":"se_introduction/#citing","text":"If you are using SnpEff or SnpSift, please cite our work as shown here . Thank you!","title":"Citing"},{"location":"se_introduction/#snpeff-features","text":"The following table shows the main SnpEff features: Feature Comment Local install SnpEff can be installed in your local computer or servers. Local installations are preferred for processing genomic data. As opposed to remote web-based services, running a program locally has many advantages: There no need to upload huge genomic dataset. Processing doesn't depend on availability or processing capacity of remote servers. Service continuity: no need to worry if a remote service will be maintained in the future. Security and confidentiality issues of uploading data to third party servers are not a problem. Avoid legal problems of processing clinical data on \"outside\" servers. Multi platform SnpEff is written in Java. It runs on Unix / Linux, OS.X and Windows. Simple installation Installation is as simple as downloading a ZIP file and double clicking on it. Genomes Human genome, as well as all model organisms are supported. Over 2,500 genomes are supported, which includes most mammalian, plant, bacterial and fungal genomes with published genomic data. Speed SnpEff is really fast. It can annotate up to 1,000,000 variants per minute. GATK&Galaxy integration SnpEff can be easily integrated with GATK and Galaxy pipelines. GUI Web based user interface via Galaxy project Input and Output formats SnpEff accepts input files in the following format: VCF format, which is the de-facto standard for sequencing variants. BED format: To annotate enrichment experiments (e.g. ChIP-Seq peaks) or other genomic data. Variants supported SnpEff can annotate SNPs, MNPs, insertions and deletions. Support for mixed variants and structural variants is available (although sometimes limited). Effect supported Many effects are calculated: such as SYNONYMOUS_CODING, NON_SYNONYMOUS_CODING, FRAME_SHIFT, STOP_GAINED just to name a few. Variant impact SnpEff provides a simple assessment of the putative impact of the variant (e.g. HIGH, MODERATE or LOW impact). Cancer tissue analysis Somatic vs Germline mutations can be calculated on the fly. This is very useful for the cancer researcher community. Loss of Function (LOF) assessment SnpEff can estimate if a variant is deemed to have a loss of function on the protein. Nonsense mediate decay (NMD) assessment Some mutations may cause mRNA to be degraded thus not translated into a protein. NMD analysis marks mutations that are estimated to trigger nonsense mediated decay. HGVS notation SnpEff can provide output in HGVS notation, which is quite popular in clinical and translation research environments. User annotations A user can provide custom annotations (by means of BED files). Public databases SnpEff can annotate using publicly available data from well known databases, for instance: ENCODE datasets are supported by SnpEff (by means of BigWig files provided by ENCODE project). Epigenome Roadmap provides data-sets that can be used with SnpEff. TFBS Transcription factor binding site predictions can be annotated. Motif data used in this annotations is generates by Jaspar and ENSEBML projects NextProt database can be used to annotate protein domains as well as important functional sites in a protein (e.g. phosphorilation site) Common variants (dbSnp) Annotating \"common\" variants from dbSnp and 1,000 Genomes can be easily done (see SnpSift annotate ). Gwas catalog Support for GWAS catalog annotations (see SnpSift gwasCat ) Conservation scores PhastCons conservation score annotations support (see SnpSift phastCons ) DbNsfp A comprehensive database providing many annotations and scores, such as: SIFT , Polyphen2 , GERP++ , PhyloP , MutationTaster , SiPhy , Interpro , Haploinsufficiency , etc. (via SnpSift). See SnpSift dbnsfp for details. Non-coding annotations Regulatory and non-coding annotations are supported for different tissues and cell lines. Annotations supported include PolII,H3K27ac, H3K4me2, H3K4me3, H3K27me3, CTCF, H3K36me3, just to name a few. Gene Sets annotations Gene sets (MSigDb, GO, BioCarta, KEGG, Reactome, etc.) can be used to annotate via SnpSift geneSets command.","title":"SnpEff Features"},{"location":"se_introduction/#databases","text":"In order to produce the annotations, SnpEff requires a database. We build these databases using information from trusted resources. Info By default SnpEff downloads and installs databases automatically (since version 4.0) Currently, there are pre-built database for over 20,000 reference genomes. This means that most cases are covered. In some very rare occasions, people need to build a database for an organism not currently supported (e.g. the genome is not publicly available). In most cases, this can be done and there is a section of this manual teaching how to build your own SnpEff database. Which databases are supported? You can find out all the supported databases by running the databases command: $ java -jar snpEff.jar databases | less This command shows the database name, genome name and source data (where was the genome reference data obtained from). Keep in mind that many times I use ENSEMBL reference genomes, so the name would be GRCh37 instead of hg19 , or GRCm38 instead of mm10 , and so on. Example: Finding a database: So, let's say you want to find out the name of the latest mouse (Mus.Musculus) database. You can runs something like this: $ java -jar snpEff.jar databases | grep -i musculus 129S1_SvImJ_v1.99 Mus_musculus_129s1svimj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_129S1_SvImJ_v1.99.zip AKR_J_v1.99 Mus_musculus_akrj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_AKR_J_v1.99.zip A_J_v1.99 Mus_musculus_aj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_A_J_v1.99.zip BALB_cJ_v1.99 Mus_musculus_balbcj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_BALB_cJ_v1.99.zip C3H_HeJ_v1.99 Mus_musculus_c3hhej https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_C3H_HeJ_v1.99.zip C57BL_6NJ_v1.99 Mus_musculus_c57bl6nj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_C57BL_6NJ_v1.99.zip CAST_EiJ_v1.99 Mus_musculus_casteij https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_CAST_EiJ_v1.99.zip CBA_J_v1.99 Mus_musculus_cbaj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_CBA_J_v1.99.zip DBA_2J_v1.99 Mus_musculus_dba2j https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_DBA_2J_v1.99.zip FVB_NJ_v1.99 Mus_musculus_fvbnj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_FVB_NJ_v1.99.zip GRCm38.75 Mus_musculus https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_GRCm38.75.zip GRCm38.99 Mus_musculus https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_GRCm38.99.zip LP_J_v1.99 Mus_musculus_lpj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_LP_J_v1.99.zip NOD_ShiLtJ_v1.99 Mus_musculus_nodshiltj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_NOD_ShiLtJ_v1.99.zip NZO_HlLtJ_v1.99 Mus_musculus_nzohlltj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_NZO_HlLtJ_v1.99.zip PWK_PhJ_v1.99 Mus_musculus_pwkphj https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_PWK_PhJ_v1.99.zip WSB_EiJ_v1.99 Mus_musculus_wsbeij https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_WSB_EiJ_v1.99.zip testMm37.61 Mus_musculus https://snpeff.blob.core.windows.net/databases/v5_0/snpEff_v5_0_testMm37.61.zip At the time of writing this, you have 10 options (obviously this will change in the future). Some are databases are GRCm version 37 (i.e. mm9) and some are version 38 (i.e. mm10). Since it is generally better to use the latest release, you should probably pick GRCm38.74 . Again, this is an example of the version numbers at the time of writing this paragraph, in the future there will be other releases and you should update to the corresponding version. Unsupported reference genomes: If your reference genome of interest is not supported yet (i.e. there is no database available), you can build a database yourself (see Building databases ). If you have problems adding you own organism, send the issue to SnpEff repository and I'll do my best to help you out.","title":"Databases"},{"location":"se_outputsummary/","text":"Output summary Files SnpEff creates an additional output file showing overall statistics. This \"stats\" file is an HTML file which can be opened using a web browser. You can find an example of a 'stats' file here . HTML summary (snpEff_summary.html) The program performs some statistics and saves them to the file 'snpEff_summary.html' on the directory where snpEff is being executed. You can see the file, by opening it in your browser. Info You can change the default location by using the -stats command line option. This also changes the location of the TXT summary file. Info Summary can be create in CSV format using command line option -csvStats . This allows easy downstream processing. E.g.: In the stats file, you can see coverage histogram plots like this one: \"Effects by type\" vs \"Effects by region\" SnpEff annotates variants. Variants produce effect of difference \"types\" (e.g. NON_SYNONYMOUS_CODING, STOP_GAINED). These variants affect regions of the genome (e.g. EXON, INTRON). The two tables count how many effects for each type and for each region exists. E.g.: In an EXON region, you can have all the following effect types: NON_SYNONYMOUS_CODING, SYNONYMOUS_CODING, FRAME_SHIFT, STOP_GAINED, etc. The complicated part is that some effect types affect a region that has the same name (yes, I know, this is confusing). E.g.: In a UTR_5_PRIME region you can have UTR_5_PRIME and START_GAINED effect type. This means that the number of both tables are not exactly the same, because the labels don't mean the same. See the next figure as an example: So the number of effects that affect a UTR_5_PRIME region is 206. Of those, 57 are effects type START_GAINED and 149 are effects type UTR_5_PRIME. How exactly are effect type and effect region related? See the following table: Effect Type Region NONE CHROMOSOME CUSTOM CDS NONE INTERGENIC INTERGENIC_CONSERVED INTERGENIC UPSTREAM UPSTREAM UTR_5_PRIME UTR_5_DELETED START_GAINED UTR_5_PRIME SPLICE_SITE_ACCEPTOR SPLICE_SITE_ACCEPTOR SPLICE_SITE_DONOR SPLICE_SITE_DONOR SPLICE_SITE_REGION SPLICE_SITE_REGION INTRAGENIC START_LOST SYNONYMOUS_START NON_SYNONYMOUS_START GENE TRANSCRIPT EXON or NONE EXON EXON_DELETED NON_SYNONYMOUS_CODING SYNONYMOUS_CODING FRAME_SHIFT CODON_CHANGE CODON_INSERTION CODON_CHANGE_PLUS_CODON_INSERTION CODON_DELETION CODON_CHANGE_PLUS_CODON_DELETION STOP_GAINED SYNONYMOUS_STOP STOP_LOST RARE_AMINO_ACID EXON INTRON INTRON_CONSERVED INTRON UTR_3_PRIME UTR_3_DELETED UTR_3_PRIME DOWNSTREAM DOWNSTREAM REGULATION REGULATION Gene counts summary (snpEff_genes.txt) SnpEff also generates a TXT (tab separated) file having counts of number of variants affecting each transcript and gene. By default, the file name is snpEff_genes.txt , but it can be changed using the -stats command line option. Here is an example of this file: $ head snpEff_genes.txt # The following table is formatted as tab separated values. #GeneName GeneId TranscriptId BioType variants_impact_HIGH variants_impact_LOW variants_impact_MODERATE variants_impact_MODIFIER variants_effect_3_prime_UTR_variant variants_effect_5_prime_UTR_premature_start_codon_gain_variant variants_effect_5_prime_UTR_variant variants_effect_downstream_gene_variant variants_effect_intron_variant variants_effect_missense_variant variants_effect_non_coding_exon_variant variants_effect_splice_acceptor_variant variants_effect_splice_donor_variant variants_effect_splice_region_variant variants_effect_start_lost variants_effect_stop_gained variants_effect_stop_lost variants_effect_synonymous_variant variants_effect_upstream_gene_variant bases_affected_DOWNSTREAM total_score_DOWNSTREAM length_DOWNSTREAM bases_affected_EXON total_score_EXON length_EXON bases_affected_INTRON total_score_INTRON length_INTRON bases_affected_SPLICE_SITE_ACCEPTOR total_score_SPLICE_SITE_ACCEPTOR length_SPLICE_SITE_ACCEPTOR bases_affected_SPLICE_SITE_DONOR total_score_SPLICE_SITE_DONOR length_SPLICE_SITE_DONOR bases_affected_SPLICE_SITE_REGION total_score_SPLICE_SITE_REGION length_SPLICE_SITE_REGION bases_affected_TRANSCRIPT total_score_TRANSCRIPT length_TRANSCRIPT bases_affected_UPSTREAM total_score_UPSTREAM length_UPSTREAM bases_affected_UTR_3_PRIME total_score_UTR_3_PRIME length_UTR_3_PRIME bases_affected_UTR_5_PRIME total_score_UTR_5_PRIME length_UTR_5_PRIME AC000029.1 ENSG00000221069 ENST00000408142 miRNA 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 5000 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 AC000068.5 ENSG00000185065 ENST00000431090 antisense 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 5000 0 0 0 0 0 0 AC000081.2 ENSG00000230194 ENST00000433141 processed_pseudogene 0 0 0 8 0 0 0 3 0 0 0 0 0 0 5000 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 5000 0 0 AC000089.3 ENSG00000235776 ENST00000424559 processed_pseudogene 0 0 0 1 0 0 0 0 0 0 0 0 0 0 5000 0 0 0 0 0 0 AC002472.1 ENSG00000269103 ENST00000547793 protein_coding 0 0 0 6 0 0 0 5 0 0 0 0 0 0 0 5000 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 5000 0 0 AC002472.11 ENSG00000226872 ENST00000450652 antisense 0 0 0 13 0 0 0 5 2 0 0 0 0 0 0 5000 0 0 0 2 0 11199 0 0 0 0 0 0 0 0 0 0 0 0 6 0 5000 0 0 AC002472.13 ENSG00000187905 ENST00000342608 protein_coding 0 1 6 1 0 0 0 0 1 6 0 0 0 1 0 116 1 0 934 0 0 0 0 0 0 1 0 3 0 0 0 0 0 0 0 0 0 0 0 AC002472.13 ENSG00000187905 ENST00000442047 protein_coding 0 1 6 1 0 0 0 0 1 6 0 0 0 1 0 116 1 0 934 0 0 0 0 0 0 1 0 3 0 0 0 0 0 0 0 0 0 0 0 The columns in this table are: Column name Meaning GeneName Gene name (usually HUGO) GeneId Gene's ID TranscriptId Transcript's ID BioType Transcript's bio-type (if available) The following column is repeated for each impact {HIGH, MODERATE, LOW, MODIFIER} variants_impact_* Count number of variants for each impact category The following column is repeated for each annotated effect (e.g. missense_variant, synonymous_variant, stop_lost, etc.) variants_effect_* Count number of variants for each effect type The following columns are repeated for several genomic regions (DOWNSTREAM, EXON, INTRON, UPSTREAM, etc.) bases_affected_* Number of bases that variants overlap genomic region total_score_* Sum of scores overlapping this genomic region. Note: Scores are only available when input files are type 'BED' (e.g. when annotating ChipSeq experiments) length_* Genomic region length","title":"Output summary files"},{"location":"se_outputsummary/#output-summary-files","text":"SnpEff creates an additional output file showing overall statistics. This \"stats\" file is an HTML file which can be opened using a web browser. You can find an example of a 'stats' file here .","title":"Output summary Files"},{"location":"se_outputsummary/#html-summary-snpeff_summaryhtml","text":"The program performs some statistics and saves them to the file 'snpEff_summary.html' on the directory where snpEff is being executed. You can see the file, by opening it in your browser. Info You can change the default location by using the -stats command line option. This also changes the location of the TXT summary file. Info Summary can be create in CSV format using command line option -csvStats . This allows easy downstream processing. E.g.: In the stats file, you can see coverage histogram plots like this one: \"Effects by type\" vs \"Effects by region\" SnpEff annotates variants. Variants produce effect of difference \"types\" (e.g. NON_SYNONYMOUS_CODING, STOP_GAINED). These variants affect regions of the genome (e.g. EXON, INTRON). The two tables count how many effects for each type and for each region exists. E.g.: In an EXON region, you can have all the following effect types: NON_SYNONYMOUS_CODING, SYNONYMOUS_CODING, FRAME_SHIFT, STOP_GAINED, etc. The complicated part is that some effect types affect a region that has the same name (yes, I know, this is confusing). E.g.: In a UTR_5_PRIME region you can have UTR_5_PRIME and START_GAINED effect type. This means that the number of both tables are not exactly the same, because the labels don't mean the same. See the next figure as an example: So the number of effects that affect a UTR_5_PRIME region is 206. Of those, 57 are effects type START_GAINED and 149 are effects type UTR_5_PRIME. How exactly are effect type and effect region related? See the following table: Effect Type Region NONE CHROMOSOME CUSTOM CDS NONE INTERGENIC INTERGENIC_CONSERVED INTERGENIC UPSTREAM UPSTREAM UTR_5_PRIME UTR_5_DELETED START_GAINED UTR_5_PRIME SPLICE_SITE_ACCEPTOR SPLICE_SITE_ACCEPTOR SPLICE_SITE_DONOR SPLICE_SITE_DONOR SPLICE_SITE_REGION SPLICE_SITE_REGION INTRAGENIC START_LOST SYNONYMOUS_START NON_SYNONYMOUS_START GENE TRANSCRIPT EXON or NONE EXON EXON_DELETED NON_SYNONYMOUS_CODING SYNONYMOUS_CODING FRAME_SHIFT CODON_CHANGE CODON_INSERTION CODON_CHANGE_PLUS_CODON_INSERTION CODON_DELETION CODON_CHANGE_PLUS_CODON_DELETION STOP_GAINED SYNONYMOUS_STOP STOP_LOST RARE_AMINO_ACID EXON INTRON INTRON_CONSERVED INTRON UTR_3_PRIME UTR_3_DELETED UTR_3_PRIME DOWNSTREAM DOWNSTREAM REGULATION REGULATION","title":"HTML summary (snpEff_summary.html)"},{"location":"se_outputsummary/#gene-counts-summary-snpeff_genestxt","text":"SnpEff also generates a TXT (tab separated) file having counts of number of variants affecting each transcript and gene. By default, the file name is snpEff_genes.txt , but it can be changed using the -stats command line option. Here is an example of this file: $ head snpEff_genes.txt # The following table is formatted as tab separated values. #GeneName GeneId TranscriptId BioType variants_impact_HIGH variants_impact_LOW variants_impact_MODERATE variants_impact_MODIFIER variants_effect_3_prime_UTR_variant variants_effect_5_prime_UTR_premature_start_codon_gain_variant variants_effect_5_prime_UTR_variant variants_effect_downstream_gene_variant variants_effect_intron_variant variants_effect_missense_variant variants_effect_non_coding_exon_variant variants_effect_splice_acceptor_variant variants_effect_splice_donor_variant variants_effect_splice_region_variant variants_effect_start_lost variants_effect_stop_gained variants_effect_stop_lost variants_effect_synonymous_variant variants_effect_upstream_gene_variant bases_affected_DOWNSTREAM total_score_DOWNSTREAM length_DOWNSTREAM bases_affected_EXON total_score_EXON length_EXON bases_affected_INTRON total_score_INTRON length_INTRON bases_affected_SPLICE_SITE_ACCEPTOR total_score_SPLICE_SITE_ACCEPTOR length_SPLICE_SITE_ACCEPTOR bases_affected_SPLICE_SITE_DONOR total_score_SPLICE_SITE_DONOR length_SPLICE_SITE_DONOR bases_affected_SPLICE_SITE_REGION total_score_SPLICE_SITE_REGION length_SPLICE_SITE_REGION bases_affected_TRANSCRIPT total_score_TRANSCRIPT length_TRANSCRIPT bases_affected_UPSTREAM total_score_UPSTREAM length_UPSTREAM bases_affected_UTR_3_PRIME total_score_UTR_3_PRIME length_UTR_3_PRIME bases_affected_UTR_5_PRIME total_score_UTR_5_PRIME length_UTR_5_PRIME AC000029.1 ENSG00000221069 ENST00000408142 miRNA 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 5000 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 AC000068.5 ENSG00000185065 ENST00000431090 antisense 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 5000 0 0 0 0 0 0 AC000081.2 ENSG00000230194 ENST00000433141 processed_pseudogene 0 0 0 8 0 0 0 3 0 0 0 0 0 0 5000 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 5000 0 0 AC000089.3 ENSG00000235776 ENST00000424559 processed_pseudogene 0 0 0 1 0 0 0 0 0 0 0 0 0 0 5000 0 0 0 0 0 0 AC002472.1 ENSG00000269103 ENST00000547793 protein_coding 0 0 0 6 0 0 0 5 0 0 0 0 0 0 0 5000 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 5000 0 0 AC002472.11 ENSG00000226872 ENST00000450652 antisense 0 0 0 13 0 0 0 5 2 0 0 0 0 0 0 5000 0 0 0 2 0 11199 0 0 0 0 0 0 0 0 0 0 0 0 6 0 5000 0 0 AC002472.13 ENSG00000187905 ENST00000342608 protein_coding 0 1 6 1 0 0 0 0 1 6 0 0 0 1 0 116 1 0 934 0 0 0 0 0 0 1 0 3 0 0 0 0 0 0 0 0 0 0 0 AC002472.13 ENSG00000187905 ENST00000442047 protein_coding 0 1 6 1 0 0 0 0 1 6 0 0 0 1 0 116 1 0 934 0 0 0 0 0 0 1 0 3 0 0 0 0 0 0 0 0 0 0 0 The columns in this table are: Column name Meaning GeneName Gene name (usually HUGO) GeneId Gene's ID TranscriptId Transcript's ID BioType Transcript's bio-type (if available) The following column is repeated for each impact {HIGH, MODERATE, LOW, MODIFIER} variants_impact_* Count number of variants for each impact category The following column is repeated for each annotated effect (e.g. missense_variant, synonymous_variant, stop_lost, etc.) variants_effect_* Count number of variants for each effect type The following columns are repeated for several genomic regions (DOWNSTREAM, EXON, INTRON, UPSTREAM, etc.) bases_affected_* Number of bases that variants overlap genomic region total_score_* Sum of scores overlapping this genomic region. Note: Scores are only available when input files are type 'BED' (e.g. when annotating ChipSeq experiments) length_* Genomic region length","title":"Gene counts summary (snpEff_genes.txt)"},{"location":"se_running/","text":"Running SnpEff We show some basic examples how to use SnpEff. Basic example: Installing SnpEff Obviously the first step to use the program is to install it (for details, take a look at the download page . You have to download the core program and then uncompress the ZIP file. In Windows systems, you can just double click and copy the contents of the ZIP file to wherever you want the program installed. If you have a Unix or a Mac system, the command line would be: # Download using wget $ wget https://snpeff.blob.core.windows.net/versions/snpEff_latest_core.zip # If you prefer to use 'curl' instead of 'wget', you can type: # curl -L https://snpeff.blob.core.windows.net/versions/snpEff_latest_core.zip > snpEff_latest_core.zip # Install $ unzip snpEff_latest_core.zip Basic example: Annotate using SnpEff Let's assume you have a VCF file and you want to annotate the variants in that file. An example file is provided in examples/test.chr22.vcf (this data is from the 1000 Genomes project, so the reference genome is the human genome GRCh37). You can annotate the file by running the following command (as an input, we use a Variant Call Format (VCF) file available in SnpEff's examples directory). $ java -Xmx8g -jar snpEff.jar GRCh37.75 examples/test.chr22.vcf > test.chr22.ann.vcf # Here is how the output looks like $ head examples/test.chr22.ann.vcf ##SnpEffVersion=\"4.1 (build 2015-01-07), by Pablo Cingolani\" ##SnpEffCmd=\"SnpEff GRCh37.75 examples/test.chr22.vcf \" ##INFO=<ID=ANN,Number=.,Type=String,Description=\"Functional annotations: 'Allele | Annotation | Annotation_Impact | Gene_Name | Gene_ID | Feature_Type | Feature_ID | Transcript_BioType | Rank | HGVS.c | HGVS.p | cDNA.pos / cDNA.length | CDS.pos / CDS.length | AA.pos / AA.length | Distance | ERRORS / WARNINGS / INFO' \"> ##INFO=<ID=LOF,Number=.,Type=String,Description=\"Predicted loss of function effects for this variant. Format: 'Gene_Name | Gene_ID | Number_of_transcripts_in_gene | Percent_of_transcripts_affected' \"> ##INFO=<ID=NMD,Number=.,Type=String,Description=\"Predicted nonsense mediated decay effects for this variant. Format: 'Gene_Name | Gene_ID | Number_of_transcripts_in_gene | Percent_of_transcripts_affected' \"> #CHROM POS ID REF ALT QUAL FILTER INFO 22 17071756 . T C . . ANN=C|3_prime_UTR_variant|MODIFIER|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.*11A>G|||||11|,C|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397A>G|||||4223| 22 17072035 . C T . . ANN=T|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.1406G>A|p.Gly469Glu|1666/2034|1406/1674|469/557||,T|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397G>A|||||3944| 22 17072258 . C A . . ANN=A|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.1183G>T|p.Gly395Cys|1443/2034|1183/1674|395/557||,A|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397G>T|||||3721| 22 17072674 . G A . . ANN=A|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.767C>T|p.Pro256Leu|1027/2034|767/1674|256/557||,A|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397C>T|||||3305| As you can see, SnpEff added functional annotations in the ANN info field (eigth column in the VCF output file). Details about the 'ANN' field format can be found in the ANN Field section and in VCF annotation about standard 'ANN' field . Note: Older SnpEff version used 'EFF' field (details about the 'EFF' field format can be found in the EFF Field section). You can also annotate using the \"verbose\" mode (command line option -v ), this makes SnpEff to show a lot of information which can be useful for debugging. Here output is edited for brevity: $ java -Xmx8g -jar snpEff.jar -v GRCh37.75 examples/test.chr22.vcf > test.chr22.ann.vcf 00:00:00.000 Reading configuration file 'snpEff.config'. Genome: 'GRCh37.75' 00:00:00.434 done 00:00:00.434 Reading database for genome version 'GRCh37.75' from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/snpEffectPredictor.bin' (this might take a while) 00:00:00.434 Database not installed Attempting to download and install database 'GRCh37.75' 00:00:00.435 Reading configuration file 'snpEff.config'. Genome: 'GRCh37.75' 00:00:00.653 done 00:00:00.654 Downloading database for 'GRCh37.75' 00:00:00.655 Connecting to http://downloads.sourceforge.net/project/snpeff/databases/v4_0/snpEff_v4_0_GRCh37.75.zip 00:00:01.721 Local file name: 'snpEff_v4_0_GRCh37.75.zip' ............................................. 00:01:31.595 Download finished. Total 177705174 bytes. 00:01:31.597 Extracting file 'data/GRCh37.75/motif.bin' to '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/motif.bin' 00:01:31.597 Creating local directory: '/home/pcingola/snpEff_v4_0/./data/GRCh37.75' 00:01:31.652 Extracting file 'data/GRCh37.75/nextProt.bin' 00:01:31.707 Extracting file 'data/GRCh37.75/pwms.bin' 00:01:31.707 Extracting file 'data/GRCh37.75/regulation_CD4.bin' ... 00:01:32.038 Extracting file 'data/GRCh37.75/snpEffectPredictor.bin' 00:01:32.881 Unzip: OK 00:01:32.881 Done 00:01:32.881 Database installed. 00:01:58.779 done 00:01:58.813 Reading NextProt database from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/nextProt.bin' 00:02:01.448 NextProt database: 523361 markers loaded. 00:02:01.448 Adding transcript info to NextProt markers. 00:02:02.180 NextProt database: 706289 markers added. 00:02:02.181 Loading Motifs and PWMs 00:02:02.181 Loading PWMs from : /home/pcingola/snpEff_v4_0/./data/GRCh37.75/pwms.bin 00:02:02.203 Loading Motifs from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/motif.bin' 00:02:02.973 Motif database: 284122 markers loaded. 00:02:02.973 Building interval forest 00:02:41.857 done. 00:02:41.858 Genome stats : #----------------------------------------------- # Genome name : 'Homo_sapiens' # Genome version : 'GRCh37.75' # Has protein coding info : true # Genes : 63677 # Protein coding genes : 23172 #----------------------------------------------- # Transcripts : 215170 # Avg. transcripts per gene : 3.38 #----------------------------------------------- # Checked transcripts : # AA sequences : 104254 ( 114.79% ) # DNA sequences : 179360 ( 83.36% ) #----------------------------------------------- # Protein coding transcripts : 90818 # Length errors : 14349 ( 15.80% ) # STOP codons in CDS errors : 39 ( 0.04% ) # START codon errors : 8721 ( 9.60% ) # STOP codon warnings : 21788 ( 23.99% ) # UTR sequences : 87724 ( 40.77% ) # Total Errors : 21336 ( 23.49% ) #----------------------------------------------- # Cds : 792087 # Exons : 1306656 # Exons with sequence : 1306656 # Exons without sequence : 0 # Avg. exons per transcript : 6.07 # WARNING! : Mitochondrion chromosome 'MT' does not have a mitochondrion codon table (codon table = 'Standard'). You should update the config file. #----------------------------------------------- # Number of chromosomes : 297 # Chromosomes names [sizes] : # 'HG1292_PATCH' [250051446] # 'HG1287_PATCH' [249964560] # 'HG1473_PATCH' [249272860] # 'HG1471_PATCH' [249269426] # 'HSCHR1_1_CTG31' [249267852] # 'HSCHR1_2_CTG31' [249266025] # 'HSCHR1_3_CTG31' [249262108] # 'HG999_2_PATCH' [249259300] # 'HG989_PATCH' [249257867] # 'HG999_1_PATCH' [249257505] # 'HG1472_PATCH' [249251918] # '1' [249250621] # 'HG1293_PATCH' [249140837] # 'HG686_PATCH' [243297375] # 'HSCHR2_1_CTG12' [243216362] # 'HSCHR2_2_CTG12' [243205453] # 'HSCHR2_1_CTG1' [243205406] # 'HG953_PATCH' [243199374] # '2' [243199373] ..... ..... #----------------------------------------------- 00:02:59.416 Predicting variants WARNINGS: Some warning were detected Warning type Number of warnings WARNING_TRANSCRIPT_INCOMPLETE 8215 WARNING_TRANSCRIPT_NO_START_CODON 3483 00:03:04.327 Creating summary file: snpEff_summary.html 00:03:04.891 Creating genes file: snpEff_genes.txt 00:03:17.334 done. 00:03:17.336 Logging 00:03:18.337 Checking for updates... Notice how SnpEff automatically downloads and installs the database. Next time SnpEff will use the local version, so the installation step is only done once. The annotated variants will be in the new file \"test.chr22.ann.vcf\". Warning SnpEff creates a file called \"snpEff_summary.html\" showing basic statistics about the analyzed variants. Take a quick look at it. Info We used the java parameter -Xmx8g to increase the memory available to the Java Virtual Machine to 4G. SnpEff's human genome database is large and it has to be loaded into memory. If your computer doesn't have at least 4G of memory, you probably won't be able to run this example. Info If you are running SnpEff from a directory different than the one it was installed, you will have to specify where the config file is. This is done using the '-c' command line option: java -Xmx8g -jar snpEff.jar -c path/to/snpEff/snpEff.config -v GRCh37.75 test.chr22.vcf > test.chr22.ann.vcf Detailed examples Take a look at several detailed examples in our examples page . Specify a configuration file Sometimes you need to specify the path to the config file. For instance, when you run SnpEff from a different directory than your install directory, you have to specify where the config file is located using the '-c' command line option. java -Xmx8g path/to/snpEff/snpEff.jar -c path/to/snpEff/snpEff.config GRCh37.75 path/to/snps.vcf Info Since version 4.1B, you can use the -configOption command line option to override any value in the config file Java memory options By default the amount of memory set by a java process is set too low. If you don't assign more memory to the process, you will most likely have an \"OutOfMemory\" error. You should set the amount of memory in your java virtual machine to, at least, 2 Gb. This can be easily done using the Java command line option -Xmx . E.g. In this example I use 4Gb: # Run using 4 Gb of memory java -Xmx8g snpEff.jar hg19 path/to/your/files/snps.vcf Note: There is no space between -Xmx and 4G . Running SnpEff in the Cloud You can run SnpEff in a \"the Cloud\" exactly the same way as running it on your local computer. You should not have any problems at all. Here is an example of installing it and running it on an Amazon EC2 instance (virtual machine): $ ssh -i ./aws_amazon/pcingola_aws.pem ec2-user@ec2-54-234-14-244.compute-1.amazonaws.com __| __|_ ) _| ( / Amazon Linux AMI ___|\\___|___| [ec2-user@ip-10-2-202-163 ~]$ wget https://snpeff.blob.core.windows.net/versions/snpEff_latest_core.zip [ec2-user@ip-10-2-202-163 ~]$ unzip snpEff_latest_core.zip [ec2-user@ip-10-2-202-163 ~]$ cd snpEff/ [ec2-user@ip-10-2-202-163 snpEff]$ java -jar snpEff.jar download -v hg19 00:00:00.000 Downloading database for 'hg19' ... 00:00:36.340 Done [ec2-user@ip-10-2-202-163 snpEff]$ java -Xmx8g -jar snpEff.jar dump -v hg19 > /dev/null 00:00:00.000 Reading database for genome 'hg19' (this might take a while) 00:00:20.688 done 00:00:20.688 Building interval forest 00:00:33.110 Done. As you can see, it's very simple. Loading the database One of the first thins SnpEff has to do is to load the database. Usually it takes from a few seconds to a couple of minutes, depending on database size. Complex databases, like human, require more time to load. After the database is loaded, SnpEff can analyze thousands of variants per second. Command line vs Web interface In order to run SnpEff you need to be comfortable running command from a command line terminal. If you are not, then it is probably a good idea to ask you systems administrator to install a Galaxy server and use the web interface. You can also use the open Galaxy server, but functionality may be limited and SnpEff versions may not be updated frequently.","title":"Running SnpEff"},{"location":"se_running/#running-snpeff","text":"We show some basic examples how to use SnpEff.","title":"Running SnpEff"},{"location":"se_running/#basic-example-installing-snpeff","text":"Obviously the first step to use the program is to install it (for details, take a look at the download page . You have to download the core program and then uncompress the ZIP file. In Windows systems, you can just double click and copy the contents of the ZIP file to wherever you want the program installed. If you have a Unix or a Mac system, the command line would be: # Download using wget $ wget https://snpeff.blob.core.windows.net/versions/snpEff_latest_core.zip # If you prefer to use 'curl' instead of 'wget', you can type: # curl -L https://snpeff.blob.core.windows.net/versions/snpEff_latest_core.zip > snpEff_latest_core.zip # Install $ unzip snpEff_latest_core.zip","title":"Basic example: Installing SnpEff"},{"location":"se_running/#basic-example-annotate-using-snpeff","text":"Let's assume you have a VCF file and you want to annotate the variants in that file. An example file is provided in examples/test.chr22.vcf (this data is from the 1000 Genomes project, so the reference genome is the human genome GRCh37). You can annotate the file by running the following command (as an input, we use a Variant Call Format (VCF) file available in SnpEff's examples directory). $ java -Xmx8g -jar snpEff.jar GRCh37.75 examples/test.chr22.vcf > test.chr22.ann.vcf # Here is how the output looks like $ head examples/test.chr22.ann.vcf ##SnpEffVersion=\"4.1 (build 2015-01-07), by Pablo Cingolani\" ##SnpEffCmd=\"SnpEff GRCh37.75 examples/test.chr22.vcf \" ##INFO=<ID=ANN,Number=.,Type=String,Description=\"Functional annotations: 'Allele | Annotation | Annotation_Impact | Gene_Name | Gene_ID | Feature_Type | Feature_ID | Transcript_BioType | Rank | HGVS.c | HGVS.p | cDNA.pos / cDNA.length | CDS.pos / CDS.length | AA.pos / AA.length | Distance | ERRORS / WARNINGS / INFO' \"> ##INFO=<ID=LOF,Number=.,Type=String,Description=\"Predicted loss of function effects for this variant. Format: 'Gene_Name | Gene_ID | Number_of_transcripts_in_gene | Percent_of_transcripts_affected' \"> ##INFO=<ID=NMD,Number=.,Type=String,Description=\"Predicted nonsense mediated decay effects for this variant. Format: 'Gene_Name | Gene_ID | Number_of_transcripts_in_gene | Percent_of_transcripts_affected' \"> #CHROM POS ID REF ALT QUAL FILTER INFO 22 17071756 . T C . . ANN=C|3_prime_UTR_variant|MODIFIER|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.*11A>G|||||11|,C|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397A>G|||||4223| 22 17072035 . C T . . ANN=T|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.1406G>A|p.Gly469Glu|1666/2034|1406/1674|469/557||,T|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397G>A|||||3944| 22 17072258 . C A . . ANN=A|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.1183G>T|p.Gly395Cys|1443/2034|1183/1674|395/557||,A|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397G>T|||||3721| 22 17072674 . G A . . ANN=A|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.767C>T|p.Pro256Leu|1027/2034|767/1674|256/557||,A|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397C>T|||||3305| As you can see, SnpEff added functional annotations in the ANN info field (eigth column in the VCF output file). Details about the 'ANN' field format can be found in the ANN Field section and in VCF annotation about standard 'ANN' field . Note: Older SnpEff version used 'EFF' field (details about the 'EFF' field format can be found in the EFF Field section). You can also annotate using the \"verbose\" mode (command line option -v ), this makes SnpEff to show a lot of information which can be useful for debugging. Here output is edited for brevity: $ java -Xmx8g -jar snpEff.jar -v GRCh37.75 examples/test.chr22.vcf > test.chr22.ann.vcf 00:00:00.000 Reading configuration file 'snpEff.config'. Genome: 'GRCh37.75' 00:00:00.434 done 00:00:00.434 Reading database for genome version 'GRCh37.75' from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/snpEffectPredictor.bin' (this might take a while) 00:00:00.434 Database not installed Attempting to download and install database 'GRCh37.75' 00:00:00.435 Reading configuration file 'snpEff.config'. Genome: 'GRCh37.75' 00:00:00.653 done 00:00:00.654 Downloading database for 'GRCh37.75' 00:00:00.655 Connecting to http://downloads.sourceforge.net/project/snpeff/databases/v4_0/snpEff_v4_0_GRCh37.75.zip 00:00:01.721 Local file name: 'snpEff_v4_0_GRCh37.75.zip' ............................................. 00:01:31.595 Download finished. Total 177705174 bytes. 00:01:31.597 Extracting file 'data/GRCh37.75/motif.bin' to '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/motif.bin' 00:01:31.597 Creating local directory: '/home/pcingola/snpEff_v4_0/./data/GRCh37.75' 00:01:31.652 Extracting file 'data/GRCh37.75/nextProt.bin' 00:01:31.707 Extracting file 'data/GRCh37.75/pwms.bin' 00:01:31.707 Extracting file 'data/GRCh37.75/regulation_CD4.bin' ... 00:01:32.038 Extracting file 'data/GRCh37.75/snpEffectPredictor.bin' 00:01:32.881 Unzip: OK 00:01:32.881 Done 00:01:32.881 Database installed. 00:01:58.779 done 00:01:58.813 Reading NextProt database from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/nextProt.bin' 00:02:01.448 NextProt database: 523361 markers loaded. 00:02:01.448 Adding transcript info to NextProt markers. 00:02:02.180 NextProt database: 706289 markers added. 00:02:02.181 Loading Motifs and PWMs 00:02:02.181 Loading PWMs from : /home/pcingola/snpEff_v4_0/./data/GRCh37.75/pwms.bin 00:02:02.203 Loading Motifs from file '/home/pcingola/snpEff_v4_0/./data/GRCh37.75/motif.bin' 00:02:02.973 Motif database: 284122 markers loaded. 00:02:02.973 Building interval forest 00:02:41.857 done. 00:02:41.858 Genome stats : #----------------------------------------------- # Genome name : 'Homo_sapiens' # Genome version : 'GRCh37.75' # Has protein coding info : true # Genes : 63677 # Protein coding genes : 23172 #----------------------------------------------- # Transcripts : 215170 # Avg. transcripts per gene : 3.38 #----------------------------------------------- # Checked transcripts : # AA sequences : 104254 ( 114.79% ) # DNA sequences : 179360 ( 83.36% ) #----------------------------------------------- # Protein coding transcripts : 90818 # Length errors : 14349 ( 15.80% ) # STOP codons in CDS errors : 39 ( 0.04% ) # START codon errors : 8721 ( 9.60% ) # STOP codon warnings : 21788 ( 23.99% ) # UTR sequences : 87724 ( 40.77% ) # Total Errors : 21336 ( 23.49% ) #----------------------------------------------- # Cds : 792087 # Exons : 1306656 # Exons with sequence : 1306656 # Exons without sequence : 0 # Avg. exons per transcript : 6.07 # WARNING! : Mitochondrion chromosome 'MT' does not have a mitochondrion codon table (codon table = 'Standard'). You should update the config file. #----------------------------------------------- # Number of chromosomes : 297 # Chromosomes names [sizes] : # 'HG1292_PATCH' [250051446] # 'HG1287_PATCH' [249964560] # 'HG1473_PATCH' [249272860] # 'HG1471_PATCH' [249269426] # 'HSCHR1_1_CTG31' [249267852] # 'HSCHR1_2_CTG31' [249266025] # 'HSCHR1_3_CTG31' [249262108] # 'HG999_2_PATCH' [249259300] # 'HG989_PATCH' [249257867] # 'HG999_1_PATCH' [249257505] # 'HG1472_PATCH' [249251918] # '1' [249250621] # 'HG1293_PATCH' [249140837] # 'HG686_PATCH' [243297375] # 'HSCHR2_1_CTG12' [243216362] # 'HSCHR2_2_CTG12' [243205453] # 'HSCHR2_1_CTG1' [243205406] # 'HG953_PATCH' [243199374] # '2' [243199373] ..... ..... #----------------------------------------------- 00:02:59.416 Predicting variants WARNINGS: Some warning were detected Warning type Number of warnings WARNING_TRANSCRIPT_INCOMPLETE 8215 WARNING_TRANSCRIPT_NO_START_CODON 3483 00:03:04.327 Creating summary file: snpEff_summary.html 00:03:04.891 Creating genes file: snpEff_genes.txt 00:03:17.334 done. 00:03:17.336 Logging 00:03:18.337 Checking for updates... Notice how SnpEff automatically downloads and installs the database. Next time SnpEff will use the local version, so the installation step is only done once. The annotated variants will be in the new file \"test.chr22.ann.vcf\". Warning SnpEff creates a file called \"snpEff_summary.html\" showing basic statistics about the analyzed variants. Take a quick look at it. Info We used the java parameter -Xmx8g to increase the memory available to the Java Virtual Machine to 4G. SnpEff's human genome database is large and it has to be loaded into memory. If your computer doesn't have at least 4G of memory, you probably won't be able to run this example. Info If you are running SnpEff from a directory different than the one it was installed, you will have to specify where the config file is. This is done using the '-c' command line option: java -Xmx8g -jar snpEff.jar -c path/to/snpEff/snpEff.config -v GRCh37.75 test.chr22.vcf > test.chr22.ann.vcf","title":"Basic example: Annotate using SnpEff"},{"location":"se_running/#detailed-examples","text":"Take a look at several detailed examples in our examples page .","title":"Detailed examples"},{"location":"se_running/#specify-a-configuration-file","text":"Sometimes you need to specify the path to the config file. For instance, when you run SnpEff from a different directory than your install directory, you have to specify where the config file is located using the '-c' command line option. java -Xmx8g path/to/snpEff/snpEff.jar -c path/to/snpEff/snpEff.config GRCh37.75 path/to/snps.vcf Info Since version 4.1B, you can use the -configOption command line option to override any value in the config file","title":"Specify a configuration file"},{"location":"se_running/#java-memory-options","text":"By default the amount of memory set by a java process is set too low. If you don't assign more memory to the process, you will most likely have an \"OutOfMemory\" error. You should set the amount of memory in your java virtual machine to, at least, 2 Gb. This can be easily done using the Java command line option -Xmx . E.g. In this example I use 4Gb: # Run using 4 Gb of memory java -Xmx8g snpEff.jar hg19 path/to/your/files/snps.vcf Note: There is no space between -Xmx and 4G .","title":"Java memory options"},{"location":"se_running/#running-snpeff-in-the-cloud","text":"You can run SnpEff in a \"the Cloud\" exactly the same way as running it on your local computer. You should not have any problems at all. Here is an example of installing it and running it on an Amazon EC2 instance (virtual machine): $ ssh -i ./aws_amazon/pcingola_aws.pem ec2-user@ec2-54-234-14-244.compute-1.amazonaws.com __| __|_ ) _| ( / Amazon Linux AMI ___|\\___|___| [ec2-user@ip-10-2-202-163 ~]$ wget https://snpeff.blob.core.windows.net/versions/snpEff_latest_core.zip [ec2-user@ip-10-2-202-163 ~]$ unzip snpEff_latest_core.zip [ec2-user@ip-10-2-202-163 ~]$ cd snpEff/ [ec2-user@ip-10-2-202-163 snpEff]$ java -jar snpEff.jar download -v hg19 00:00:00.000 Downloading database for 'hg19' ... 00:00:36.340 Done [ec2-user@ip-10-2-202-163 snpEff]$ java -Xmx8g -jar snpEff.jar dump -v hg19 > /dev/null 00:00:00.000 Reading database for genome 'hg19' (this might take a while) 00:00:20.688 done 00:00:20.688 Building interval forest 00:00:33.110 Done. As you can see, it's very simple.","title":"Running SnpEff in the Cloud"},{"location":"se_running/#loading-the-database","text":"One of the first thins SnpEff has to do is to load the database. Usually it takes from a few seconds to a couple of minutes, depending on database size. Complex databases, like human, require more time to load. After the database is loaded, SnpEff can analyze thousands of variants per second.","title":"Loading the database"},{"location":"se_running/#command-line-vs-web-interface","text":"In order to run SnpEff you need to be comfortable running command from a command line terminal. If you are not, then it is probably a good idea to ask you systems administrator to install a Galaxy server and use the web interface. You can also use the open Galaxy server, but functionality may be limited and SnpEff versions may not be updated frequently.","title":"Command line vs Web interface"},{"location":"se_troubleshooting/","text":"Troubleshooting Some common problems Chromosome not found Warning This is by far the most common problem. It means that the input VCF file has chromosome names that do not match SnpEff's database and don't match reference genome either, since SnpEff's database are created using reference genome chromosome names. The solution is simple: fix your VCF file to use standard chromosome names. You can see which chromosome names are used by SnpEff simply by using the -v (verbose) command line option. This shows all chromosome names and their respective lengths. Notice the last line (\"Chromosomes names [sizes]\"): $ java -Xmx8g -jar snpEff.jar -v GRCh37.75 examples/test.chr22.vcf > test.chr22.ann.vcf 00:00:00.000 Reading configuration file 'snpEff.config'. Genome: 'GRCh37.75' ... # Number of chromosomes : 297 # Chromosomes names [sizes] : # 'HG1292_PATCH' [250051446] # 'HG1287_PATCH' [249964560] # 'HG1473_PATCH' [249272860] # 'HG1471_PATCH' [249269426] # 'HSCHR1_1_CTG31' [249267852] # 'HSCHR1_2_CTG31' [249266025] # 'HSCHR1_3_CTG31' [249262108] # 'HG999_2_PATCH' [249259300] # 'HG989_PATCH' [249257867] # 'HG999_1_PATCH' [249257505] # 'HG1472_PATCH' [249251918] # '1' [249250621] # '2' [243199373] # '3' [198022430] # '4' [191154276] # '5' [180915260] # '6' [171115067] # '7' [159138663] # 'X' [155270560] ... Apparent inconsistencies when using UCSC genome browser Warning Usage of hg19 genome is deprecated and discouraged, you should use GRChXX.YY instead (e.g. the latest version at the time of writing is GRCh37.70) Reference sequence and annotations are made for an organism version and sub-version. For examples human genome, version 37, sub-version 70 would be called (GRCh37.70). UCSC doesn't specify sub-version. They just say hg19. This annoying sub-version problem appeared often and, having reproducibility of results in mind, I dropped UCSC annotations in favor of ENSEMBL ones (they have clear versioning). SnpEff reporting an effect that doesn't match ENSEMBL's web page Please remember that databases are updated often (e.g. by ENSEMBL), so if you are using an old database, you might get different effects. For example, this transcript ENST00000487462 changed from protein_coding in GRCh37.63 1 protein_coding exon 1655388 1655458 . - . gene_id \"ENSG00000008128\"; transcript_id \"ENST00000487462\"; exon_number \"1\"; gene_name \"CDK11A\"; transcript_name \"CDK11A-013\"; 1 protein_coding exon 1653905 1654270 . - . gene_id \"ENSG00000008128\"; transcript_id \"ENST00000487462\"; exon_number \"2\"; gene_name \"CDK11A\"; transcript_name \"CDK11A-013\"; ...to processed_transcript in GRCh37.64: 1 processed_transcript exon 1655388 1655458 . - . gene_id \"ENSG00000008128\"; transcript_id \"ENST00000487462\"; exon_number \"1\"; gene_name \"CDK11A\"; gene_biotype \"protein_coding\"; transcript_name \"CDK11A-013\"; 1 processed_transcript exon 1653905 1654270 . - . gene_id \"ENSG00000008128\"; transcript_id \"ENST00000487462\"; exon_number \"2\"; gene_name \"CDK11A\"; gene_biotype \"protein_coding\"; transcript_name \"CDK11A-013\"; This means that you'll get different results for this transcript using sub-version 63 or 64. I assume that latest versions are improved, so I always encourage to upgrade. Sometimes it might even be the case that latest released database and the one shown on the web interface may be out of sync. SnpEff reports a SYNONYMOUS and a NON_SYNONYMOUS effect on the same gene This is not a bug. It is not uncommon for a gene to have more than one transcript (e.g. in human most genes have multiple transcripts). A variant (e.g. a SNP) might affect different transcripts in different ways, as a result of different reading frames. For instance: chr5 137622242 . C T . . EFF=NON_SYNONYMOUS_CODING(MODERATE|MISSENSE|Gaa/Aaa|E/K|CDC25C|protein_coding|CODING|ENST00000514017|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000323760|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000348983|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000356505|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000357274|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000415130|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000513970|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000514555|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000534892|exon_5_137622186_137622319) in this example (it was divided into multiple lines for legibility), the first transcript ENST0000051401 has a NON_SYNONYMOUS effect, but all other transcripts have a SYNONYMOUS effect. Counting total number of effects of a given type Some people try to count the number of effects in a file by doing (assuming we want to count how many MODIFIER effects we have): grep -o MODIFIER output.ann.vcf | wc -l This is incorrect because a VCF line can have multiple effects (e.g. when there are multiple transcripts in a gene). A proper way to count effects would be: cat output.ann.vcf \\ | cut -f 8 \\ | tr \";\" \"\\n\" \\ | grep ^EFF= \\ | cut -f 2 -d = \\ | tr \",\" \"\\n\" \\ | grep MODIFIER \\ | wc -l Brief explanation: Command Meaning cut -f 8 Extract INFO fields tr \";\" \"\\n\" Expand each field into one line grep ^EFF= Only keep 'EFF' fields cut -f 2 -d = Keep only the effect data (drop the 'EFF=' part) tr \",\" \"\\n\" Expand effects to multiple lines grep MODIFIER | wc -l Count the ones you want (in this example 'MODIFIER')","title":"Troubleshooting"},{"location":"se_troubleshooting/#troubleshooting","text":"Some common problems","title":"Troubleshooting"},{"location":"se_troubleshooting/#chromosome-not-found","text":"Warning This is by far the most common problem. It means that the input VCF file has chromosome names that do not match SnpEff's database and don't match reference genome either, since SnpEff's database are created using reference genome chromosome names. The solution is simple: fix your VCF file to use standard chromosome names. You can see which chromosome names are used by SnpEff simply by using the -v (verbose) command line option. This shows all chromosome names and their respective lengths. Notice the last line (\"Chromosomes names [sizes]\"): $ java -Xmx8g -jar snpEff.jar -v GRCh37.75 examples/test.chr22.vcf > test.chr22.ann.vcf 00:00:00.000 Reading configuration file 'snpEff.config'. Genome: 'GRCh37.75' ... # Number of chromosomes : 297 # Chromosomes names [sizes] : # 'HG1292_PATCH' [250051446] # 'HG1287_PATCH' [249964560] # 'HG1473_PATCH' [249272860] # 'HG1471_PATCH' [249269426] # 'HSCHR1_1_CTG31' [249267852] # 'HSCHR1_2_CTG31' [249266025] # 'HSCHR1_3_CTG31' [249262108] # 'HG999_2_PATCH' [249259300] # 'HG989_PATCH' [249257867] # 'HG999_1_PATCH' [249257505] # 'HG1472_PATCH' [249251918] # '1' [249250621] # '2' [243199373] # '3' [198022430] # '4' [191154276] # '5' [180915260] # '6' [171115067] # '7' [159138663] # 'X' [155270560] ...","title":"Chromosome not found"},{"location":"se_troubleshooting/#apparent-inconsistencies-when-using-ucsc-genome-browser","text":"Warning Usage of hg19 genome is deprecated and discouraged, you should use GRChXX.YY instead (e.g. the latest version at the time of writing is GRCh37.70) Reference sequence and annotations are made for an organism version and sub-version. For examples human genome, version 37, sub-version 70 would be called (GRCh37.70). UCSC doesn't specify sub-version. They just say hg19. This annoying sub-version problem appeared often and, having reproducibility of results in mind, I dropped UCSC annotations in favor of ENSEMBL ones (they have clear versioning).","title":"Apparent inconsistencies when using UCSC genome browser"},{"location":"se_troubleshooting/#snpeff-reporting-an-effect-that-doesnt-match-ensembls-web-page","text":"Please remember that databases are updated often (e.g. by ENSEMBL), so if you are using an old database, you might get different effects. For example, this transcript ENST00000487462 changed from protein_coding in GRCh37.63 1 protein_coding exon 1655388 1655458 . - . gene_id \"ENSG00000008128\"; transcript_id \"ENST00000487462\"; exon_number \"1\"; gene_name \"CDK11A\"; transcript_name \"CDK11A-013\"; 1 protein_coding exon 1653905 1654270 . - . gene_id \"ENSG00000008128\"; transcript_id \"ENST00000487462\"; exon_number \"2\"; gene_name \"CDK11A\"; transcript_name \"CDK11A-013\"; ...to processed_transcript in GRCh37.64: 1 processed_transcript exon 1655388 1655458 . - . gene_id \"ENSG00000008128\"; transcript_id \"ENST00000487462\"; exon_number \"1\"; gene_name \"CDK11A\"; gene_biotype \"protein_coding\"; transcript_name \"CDK11A-013\"; 1 processed_transcript exon 1653905 1654270 . - . gene_id \"ENSG00000008128\"; transcript_id \"ENST00000487462\"; exon_number \"2\"; gene_name \"CDK11A\"; gene_biotype \"protein_coding\"; transcript_name \"CDK11A-013\"; This means that you'll get different results for this transcript using sub-version 63 or 64. I assume that latest versions are improved, so I always encourage to upgrade. Sometimes it might even be the case that latest released database and the one shown on the web interface may be out of sync.","title":"SnpEff reporting an effect that doesn't match ENSEMBL's web page"},{"location":"se_troubleshooting/#snpeff-reports-a-synonymous-and-a-non_synonymous-effect-on-the-same-gene","text":"This is not a bug. It is not uncommon for a gene to have more than one transcript (e.g. in human most genes have multiple transcripts). A variant (e.g. a SNP) might affect different transcripts in different ways, as a result of different reading frames. For instance: chr5 137622242 . C T . . EFF=NON_SYNONYMOUS_CODING(MODERATE|MISSENSE|Gaa/Aaa|E/K|CDC25C|protein_coding|CODING|ENST00000514017|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000323760|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000348983|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000356505|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000357274|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000415130|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000513970|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000514555|exon_5_137622186_137622319), SYNONYMOUS_CODING(LOW|SILENT|caG/caA|Q|CDC25C|protein_coding|CODING|ENST00000534892|exon_5_137622186_137622319) in this example (it was divided into multiple lines for legibility), the first transcript ENST0000051401 has a NON_SYNONYMOUS effect, but all other transcripts have a SYNONYMOUS effect.","title":"SnpEff reports a SYNONYMOUS and a NON_SYNONYMOUS effect on the same gene"},{"location":"se_troubleshooting/#counting-total-number-of-effects-of-a-given-type","text":"Some people try to count the number of effects in a file by doing (assuming we want to count how many MODIFIER effects we have): grep -o MODIFIER output.ann.vcf | wc -l This is incorrect because a VCF line can have multiple effects (e.g. when there are multiple transcripts in a gene). A proper way to count effects would be: cat output.ann.vcf \\ | cut -f 8 \\ | tr \";\" \"\\n\" \\ | grep ^EFF= \\ | cut -f 2 -d = \\ | tr \",\" \"\\n\" \\ | grep MODIFIER \\ | wc -l Brief explanation: Command Meaning cut -f 8 Extract INFO fields tr \";\" \"\\n\" Expand each field into one line grep ^EFF= Only keep 'EFF' fields cut -f 2 -d = Keep only the effect data (drop the 'EFF=' part) tr \",\" \"\\n\" Expand effects to multiple lines grep MODIFIER | wc -l Count the ones you want (in this example 'MODIFIER')","title":"Counting total number of effects of a given type"},{"location":"ss_annotate/","text":"SnpSift Annotate Annotate using fields from another VCF file (e.g. dbSnp, 1000 Genomes projects, ClinVar, ExAC, etc.). Typical usage This is typically used to annotate IDs and INFO fields from a 'database' VCF file (e.g. dbSnp). Here is an example: java -jar SnpSift.jar annotate dbSnp132.vcf variants.vcf > variants_annotated.vcf Important: SnpSift annotate command has different strategies depending on the input VCF file: Uncomressed VCF If the file is not compressed, it created an index in memory to optimize search. This assumes that both the database and the input VCF files are sorted by position, since it is required by the VCF standard (chromosome sort order can differ between files). Compressed, Tabix indexed It uses the tabix index to speed up annotations. Compressed, NOT Tabix indexed It loads the entire 'database' VCF file into memory, which may be slow or even impractical for large 'database' VCF files. This allows to annotate using unsorted VCF files. Note: By default it adds ALL database INFO fields. You can use the -info command line option if you only want select only a subset of fields from db.vcf file. You can use the -id command line option if you only want to add ID fields (no INFO fields will be added). Using the -exists command line option, you can annotate entries that exists in the 'database' file. Info DbSnp in VCF format can be downloaded here (GRCh38 coordinates). For other versions, check this link . Example 1: Annotating ID from dbSnp $ cat test.chr22.vcf #CHROM POS ID REF ALT QUAL FILTER INFO 22 16157571 . T G 0.0 FAIL NS=53 22 16346045 . T C 0.0 FAIL NS=244 22 16350245 . C A 0.0 FAIL NS=192 22 17054103 . G A 0.0 PASS NS=404 22 17071906 . A T 0.0 PASS NS=464 22 17072347 . C T 0.0 PASS NS=464 22 17072394 . C G 0.0 PASS NS=463 22 17072411 . G T 0.0 PASS NS=464 $ java -jar SnpSift.jar annotate -id db/dbSnp/dbSnp137.20120616.vcf test.chr22.vcf #CHROM POS ID REF ALT QUAL FILTER INFO 22 16157571 . T G 0.0 FAIL NS=53 22 16346045 rs56234788 T C 0.0 FAIL NS=244 22 16350245 rs2905295 C A 0.0 FAIL NS=192 22 17054103 rs4008588 G A 0.0 PASS NS=404 22 17071906 . A T 0.0 PASS NS=464 22 17072347 rs139948519 C T 0.0 PASS NS=464 22 17072394 . C G 0.0 PASS NS=463 22 17072411 rs41277596 G T 0.0 PASS NS=464 Example 2: Annotating ID and all INFO fields from dbSnp (VCF headers not shown for brevity): $ cat test.chr22.vcf #CHROM POS ID REF ALT QUAL FILTER INFO 22 16157571 . T G 0.0 FAIL NS=53 22 16346045 . T C 0.0 FAIL NS=244 22 16350245 . C A 0.0 FAIL NS=192 22 17054103 . G A 0.0 PASS NS=404 22 17071906 . A T 0.0 PASS NS=464 22 17072347 . C T 0.0 PASS NS=464 22 17072394 . C G 0.0 PASS NS=463 22 17072411 . G T 0.0 PASS NS=464 $ java -jar SnpSift.jar annotate db/dbSnp/dbSnp137.20120616.vcf test.chr22.vcf #CHROM POS ID REF ALT QUAL FILTER INFO 22 16157571 . T G 0.0 FAIL NS=53 22 16346045 rs56234788 T C 0.0 FAIL NS=244;RSPOS=16346045;GMAF=0.162248628884826;dbSNPBuildID=129;SSR=0;SAO=0;VP=050100000000000100000100;WGT=0;VC=SNV;SLO;GNO 22 16350245 rs2905295 C A 0.0 FAIL NS=192;RSPOS=16350245;GMAF=0.230804387568556;dbSNPBuildID=101;SSR=1;SAO=0;VP=050000000000000100000140;WGT=0;VC=SNV;GNO 22 17054103 rs4008588 G A 0.0 PASS NS=404;RSPOS=17054103;GMAF=0.123400365630713;dbSNPBuildID=108;SSR=0;SAO=0;VP=050100000000070010000100;WGT=0;VC=SNV;SLO;VLD;G5A;G5;KGPilot123 22 17071906 . A T 0.0 PASS NS=464 22 17072347 rs139948519 C T 0.0 PASS NS=464;RSPOS=17072347;dbSNPBuildID=134;SSR=0;SAO=0;VP=050200000004040010000100;WGT=0;VC=SNV;S3D;ASP;VLD;KGPilot123 22 17072394 . C G 0.0 PASS NS=463 22 17072411 rs41277596 G T 0.0 PASS NS=464;RSPOS=17072411;GMAF=0.00411334552102377;dbSNPBuildID=127;SSR=0;SAO=0;VP=050200000008040010000100;GENEINFO=CCT8L2:150160;WGT=0;VC=SNV;S3D;CFL;VLD;KGPilot123","title":"SnpSift Annotate"},{"location":"ss_annotate/#snpsift-annotate","text":"Annotate using fields from another VCF file (e.g. dbSnp, 1000 Genomes projects, ClinVar, ExAC, etc.).","title":"SnpSift Annotate"},{"location":"ss_annotate/#typical-usage","text":"This is typically used to annotate IDs and INFO fields from a 'database' VCF file (e.g. dbSnp). Here is an example: java -jar SnpSift.jar annotate dbSnp132.vcf variants.vcf > variants_annotated.vcf Important: SnpSift annotate command has different strategies depending on the input VCF file: Uncomressed VCF If the file is not compressed, it created an index in memory to optimize search. This assumes that both the database and the input VCF files are sorted by position, since it is required by the VCF standard (chromosome sort order can differ between files). Compressed, Tabix indexed It uses the tabix index to speed up annotations. Compressed, NOT Tabix indexed It loads the entire 'database' VCF file into memory, which may be slow or even impractical for large 'database' VCF files. This allows to annotate using unsorted VCF files. Note: By default it adds ALL database INFO fields. You can use the -info command line option if you only want select only a subset of fields from db.vcf file. You can use the -id command line option if you only want to add ID fields (no INFO fields will be added). Using the -exists command line option, you can annotate entries that exists in the 'database' file. Info DbSnp in VCF format can be downloaded here (GRCh38 coordinates). For other versions, check this link .","title":"Typical usage"},{"location":"ss_annotate/#example-1-annotating-id-from-dbsnp","text":"$ cat test.chr22.vcf #CHROM POS ID REF ALT QUAL FILTER INFO 22 16157571 . T G 0.0 FAIL NS=53 22 16346045 . T C 0.0 FAIL NS=244 22 16350245 . C A 0.0 FAIL NS=192 22 17054103 . G A 0.0 PASS NS=404 22 17071906 . A T 0.0 PASS NS=464 22 17072347 . C T 0.0 PASS NS=464 22 17072394 . C G 0.0 PASS NS=463 22 17072411 . G T 0.0 PASS NS=464 $ java -jar SnpSift.jar annotate -id db/dbSnp/dbSnp137.20120616.vcf test.chr22.vcf #CHROM POS ID REF ALT QUAL FILTER INFO 22 16157571 . T G 0.0 FAIL NS=53 22 16346045 rs56234788 T C 0.0 FAIL NS=244 22 16350245 rs2905295 C A 0.0 FAIL NS=192 22 17054103 rs4008588 G A 0.0 PASS NS=404 22 17071906 . A T 0.0 PASS NS=464 22 17072347 rs139948519 C T 0.0 PASS NS=464 22 17072394 . C G 0.0 PASS NS=463 22 17072411 rs41277596 G T 0.0 PASS NS=464","title":"Example 1: Annotating ID from dbSnp"},{"location":"ss_annotate/#example-2-annotating-id-and-all-info-fields-from-dbsnp","text":"(VCF headers not shown for brevity): $ cat test.chr22.vcf #CHROM POS ID REF ALT QUAL FILTER INFO 22 16157571 . T G 0.0 FAIL NS=53 22 16346045 . T C 0.0 FAIL NS=244 22 16350245 . C A 0.0 FAIL NS=192 22 17054103 . G A 0.0 PASS NS=404 22 17071906 . A T 0.0 PASS NS=464 22 17072347 . C T 0.0 PASS NS=464 22 17072394 . C G 0.0 PASS NS=463 22 17072411 . G T 0.0 PASS NS=464 $ java -jar SnpSift.jar annotate db/dbSnp/dbSnp137.20120616.vcf test.chr22.vcf #CHROM POS ID REF ALT QUAL FILTER INFO 22 16157571 . T G 0.0 FAIL NS=53 22 16346045 rs56234788 T C 0.0 FAIL NS=244;RSPOS=16346045;GMAF=0.162248628884826;dbSNPBuildID=129;SSR=0;SAO=0;VP=050100000000000100000100;WGT=0;VC=SNV;SLO;GNO 22 16350245 rs2905295 C A 0.0 FAIL NS=192;RSPOS=16350245;GMAF=0.230804387568556;dbSNPBuildID=101;SSR=1;SAO=0;VP=050000000000000100000140;WGT=0;VC=SNV;GNO 22 17054103 rs4008588 G A 0.0 PASS NS=404;RSPOS=17054103;GMAF=0.123400365630713;dbSNPBuildID=108;SSR=0;SAO=0;VP=050100000000070010000100;WGT=0;VC=SNV;SLO;VLD;G5A;G5;KGPilot123 22 17071906 . A T 0.0 PASS NS=464 22 17072347 rs139948519 C T 0.0 PASS NS=464;RSPOS=17072347;dbSNPBuildID=134;SSR=0;SAO=0;VP=050200000004040010000100;WGT=0;VC=SNV;S3D;ASP;VLD;KGPilot123 22 17072394 . C G 0.0 PASS NS=463 22 17072411 rs41277596 G T 0.0 PASS NS=464;RSPOS=17072411;GMAF=0.00411334552102377;dbSNPBuildID=127;SSR=0;SAO=0;VP=050200000008040010000100;GENEINFO=CCT8L2:150160;WGT=0;VC=SNV;S3D;CFL;VLD;KGPilot123","title":"Example 2: Annotating ID and all INFO fields from dbSnp"},{"location":"ss_casecontrol/","text":"SnpSift CaseControl Allows you to count how many samples are in 'case' and 'control' groups. Typical usage This command counts the number of 'homozygous', 'heterozygous' and 'total' variants in a case and control groups and performs some basic pValue calculation using Fisher exact test and Cochran-Armitage test. Case and Control groups can be defined either by a command line string or a TFAM file (see PLINK's documentation ). Case/Control command line string containing plus and minus symbols {'+', '-', '0'} where '+' is case, '-' is control and '0' is neutral (ignored). E.g. We have ten samples, which means ten genotype columns in the VCF file. The first four are 'cases', the fifth one is 'neutral', and the last five are 'control'. So the description string would be \"++++0-----\" (note that the following output has been edited, only counts are shown, no pValues): $ java -jar SnpSift.jar caseControl \"++++0-----\" cc.vcf #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Sample_01 Sample_02 Sample_03 Sample_04 Sample_05 Sample_06 Sample_07 Sample_08 Sample_09 Sample_10 1 69496 . G A . PASS AF=0.01;Cases=1,2,4;Controls=2,2,6 GT 0/1 1/1 1/0 0/0 0/0 0/1 1/1 1/1 1/0 0/0 Cases genotypes are samples 1 to 4 : 0/1, 1/1, 1/0 and 0/0. So there are 1 homozygous, 2 heterozygous, and a total of 4 variants (2 * 1 + 1 * 2 = 4). Thus the annotation is Cases=1,2,4 Control genotypes are samples 6 to 10 : 0/1, 1/1, 1/1, 1/0 and 0/0. So there are 2 homozygous, 2 heterozygous, and a total of 6 variants (2 * 2 + 1 * 2 = 6) Thus the annotation is Controls=2,2,6 Info You can use the -tfam command line option to specify a TFAM file. Case, control from are read from phenotype field of a TFAM file (6th column). Phenotype order in TFAM files do not need to match VCF sample order (sample IDs are used). Phenotype column should be coded as {0,1,2} meaning {Missing, Control, Case} respectively. See PLINK's reference for details about TFAM file format. Info You can use the -name nameString command line option to add name to the INFO tags. This can be used to count different case/control groups in the same dataset (e.g. multiple phenotypes) $ java -jar SnpSift.jar caseControl -name \"_MY_GROUP\" \"++++0-----\" cc.vcf \\ | java -jar SnpSift.jar caseControl -name \"_ANOTHER_GROUP\" \"+-+-+-+-+-\" - #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Sample_01 Sample_02 Sample_03 Sample_04 Sample_05 Sample_06 Sample_07 Sample_08 Sample_09 Sample_10 1 69496 . G A . PASS AF=0.01;Cases_MY_GROUP=1,2,4;Controls_MY_GROUP=2,2,6;Cases_ANOTHER_GROUP=1,3,5;Controls_ANOTHER_GROUP=2,1,5 GT 0/1 1/1 1/0 0/0 0/0 0/1 1/1 1/1 1/0 0/0 p-values SnpSift caseControl calculates the p-value using different models: dominant, recessive, allelic and co-dominant. Info When we say we use Fisher exact test, it means that we use the real Fisher exact test calculation, not approximations (like Chi-Square approximations). So the p-values should be correct even for low counts on any of the values in the contingency tables. Approximations tend to be wrong when any count in a contingency table is below 5. You should not see that problem here. Models: Dominant model ( CC_DOM ): A 2 by 2 contingency table is created: -- Alt (A/a + a/a) Ref (A/A) Cases N11 N12 Controls N21 N22 This means that the first column are the number of samples that have ANY non-reference: either 1 (heterozygous) or 2 (homozygous). Fisher exact test is used to calculate the p-value. Recessive model ( CC_REC ): A 2 by 2 contingency table is created: -- Alt (a/a) Ref + Het (A/A + A/a) Cases N11 N12 Controls N21 N22 This means that the first column are the number of samples that have both non-reference chromosomes: homozygous ALT. Fisher exact test is used to calculate the p-value. Allelic model ( CC_ALL ): A 2 by 2 contingency table is created: -- Variants References Cases N11 N12 Controls N21 N22 This means that the first column are the number of non-reference genotypes. For instance homozygous reference samples count as 0, heterozygous count as 1 and homozygous non-reference count as 2. Fisher exact test is used to calculate the p-value. Genotipic / Codominant model ( CC_GENO ): A 2 by 3 contingency table is created: -- A/A a/A a/a Cases N11 N12 N13 Controls N21 N22 N23 This means that the first column are the number of homozygous reference genotypes. The second column is the number of heterozygous. And the third column is the number of homozygous non-reference. Chi-Square distribution with two degrees of freedom is calculate the p-value. Cochran-Armitage trend model ( CC_TREND ): A 2 by 3 contingency table is created: -- A/A a/A a/a Cases N11 N12 N13 Controls N21 N22 N23 Weight 0.0 1.0 2.0 This means that the first column are the number of homozygous reference genotypes. The second column is the number of heterozygous. And the third column is the number of homozygous non-reference. Cochran-Armitage test is used to calculate the p-value, using the weights shown in the last row.","title":"SnpSift CaseControl"},{"location":"ss_casecontrol/#snpsift-casecontrol","text":"Allows you to count how many samples are in 'case' and 'control' groups.","title":"SnpSift CaseControl"},{"location":"ss_casecontrol/#typical-usage","text":"This command counts the number of 'homozygous', 'heterozygous' and 'total' variants in a case and control groups and performs some basic pValue calculation using Fisher exact test and Cochran-Armitage test. Case and Control groups can be defined either by a command line string or a TFAM file (see PLINK's documentation ). Case/Control command line string containing plus and minus symbols {'+', '-', '0'} where '+' is case, '-' is control and '0' is neutral (ignored). E.g. We have ten samples, which means ten genotype columns in the VCF file. The first four are 'cases', the fifth one is 'neutral', and the last five are 'control'. So the description string would be \"++++0-----\" (note that the following output has been edited, only counts are shown, no pValues): $ java -jar SnpSift.jar caseControl \"++++0-----\" cc.vcf #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Sample_01 Sample_02 Sample_03 Sample_04 Sample_05 Sample_06 Sample_07 Sample_08 Sample_09 Sample_10 1 69496 . G A . PASS AF=0.01;Cases=1,2,4;Controls=2,2,6 GT 0/1 1/1 1/0 0/0 0/0 0/1 1/1 1/1 1/0 0/0 Cases genotypes are samples 1 to 4 : 0/1, 1/1, 1/0 and 0/0. So there are 1 homozygous, 2 heterozygous, and a total of 4 variants (2 * 1 + 1 * 2 = 4). Thus the annotation is Cases=1,2,4 Control genotypes are samples 6 to 10 : 0/1, 1/1, 1/1, 1/0 and 0/0. So there are 2 homozygous, 2 heterozygous, and a total of 6 variants (2 * 2 + 1 * 2 = 6) Thus the annotation is Controls=2,2,6 Info You can use the -tfam command line option to specify a TFAM file. Case, control from are read from phenotype field of a TFAM file (6th column). Phenotype order in TFAM files do not need to match VCF sample order (sample IDs are used). Phenotype column should be coded as {0,1,2} meaning {Missing, Control, Case} respectively. See PLINK's reference for details about TFAM file format. Info You can use the -name nameString command line option to add name to the INFO tags. This can be used to count different case/control groups in the same dataset (e.g. multiple phenotypes) $ java -jar SnpSift.jar caseControl -name \"_MY_GROUP\" \"++++0-----\" cc.vcf \\ | java -jar SnpSift.jar caseControl -name \"_ANOTHER_GROUP\" \"+-+-+-+-+-\" - #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Sample_01 Sample_02 Sample_03 Sample_04 Sample_05 Sample_06 Sample_07 Sample_08 Sample_09 Sample_10 1 69496 . G A . PASS AF=0.01;Cases_MY_GROUP=1,2,4;Controls_MY_GROUP=2,2,6;Cases_ANOTHER_GROUP=1,3,5;Controls_ANOTHER_GROUP=2,1,5 GT 0/1 1/1 1/0 0/0 0/0 0/1 1/1 1/1 1/0 0/0","title":"Typical usage"},{"location":"ss_casecontrol/#p-values","text":"SnpSift caseControl calculates the p-value using different models: dominant, recessive, allelic and co-dominant. Info When we say we use Fisher exact test, it means that we use the real Fisher exact test calculation, not approximations (like Chi-Square approximations). So the p-values should be correct even for low counts on any of the values in the contingency tables. Approximations tend to be wrong when any count in a contingency table is below 5. You should not see that problem here. Models: Dominant model ( CC_DOM ): A 2 by 2 contingency table is created: -- Alt (A/a + a/a) Ref (A/A) Cases N11 N12 Controls N21 N22 This means that the first column are the number of samples that have ANY non-reference: either 1 (heterozygous) or 2 (homozygous). Fisher exact test is used to calculate the p-value. Recessive model ( CC_REC ): A 2 by 2 contingency table is created: -- Alt (a/a) Ref + Het (A/A + A/a) Cases N11 N12 Controls N21 N22 This means that the first column are the number of samples that have both non-reference chromosomes: homozygous ALT. Fisher exact test is used to calculate the p-value. Allelic model ( CC_ALL ): A 2 by 2 contingency table is created: -- Variants References Cases N11 N12 Controls N21 N22 This means that the first column are the number of non-reference genotypes. For instance homozygous reference samples count as 0, heterozygous count as 1 and homozygous non-reference count as 2. Fisher exact test is used to calculate the p-value. Genotipic / Codominant model ( CC_GENO ): A 2 by 3 contingency table is created: -- A/A a/A a/a Cases N11 N12 N13 Controls N21 N22 N23 This means that the first column are the number of homozygous reference genotypes. The second column is the number of heterozygous. And the third column is the number of homozygous non-reference. Chi-Square distribution with two degrees of freedom is calculate the p-value. Cochran-Armitage trend model ( CC_TREND ): A 2 by 3 contingency table is created: -- A/A a/A a/a Cases N11 N12 N13 Controls N21 N22 N23 Weight 0.0 1.0 2.0 This means that the first column are the number of homozygous reference genotypes. The second column is the number of heterozygous. And the third column is the number of homozygous non-reference. Cochran-Armitage test is used to calculate the p-value, using the weights shown in the last row.","title":"p-values"},{"location":"ss_concordance/","text":"SnpSift Concordance Calculate concordance between two VCF files. Typical usage This is typically used when you want to calculate concordance between a genotyping experiment and a sequencing experiment. For instance, you sequenced several samples and, as part of a related experiment or just as quality control, you also genotype the same samples using a genotyping array. Now you want to compare the two experiments. Ideally there would be no difference between the variants from genotyping and sequencing, but this is hardly the case in real world. You can use SnpSift concordance to measure the differences between the two experiments. Warning It is assumed that both VCF files are sorted by chromosome and position. Warning Sample names are defined in '#CHROM' line of the header section. Concordance is calculated only if sample label matches in both files. Example: $ java -Xmx1g -jar SnpSift.jar concordance -v genotype.vcf sequencing.vcf > concordance.txt 00:00:00.000 Indexing file 'genotype.vcf' index: MT 460030998 index: 1 19705 1 / 2 45170805 / 45174315 2 / 3 77052081 / 77055591 3 / 4 104065531 / 104069041 4 / 5 124098372 / 124101881 5 / 6 146535292 / 146538802 6 / 7 184793526 / 184797035 7 / 8 206156508 / 206160018 8 / 9 223072816 / 223076326 9 / 10 242315995 / 242319505 10 / 11 261053789 / 261057299 11 / 12 290190553 / 290194063 12 / 13 312869636 / 312873146 13 / 14 321966539 / 321970049 14 / 15 336131317 / 336134827 15 / 16 350871669 / 350875179 16 / 17 368900523 / 368904032 17 / 18 391305860 / 391309369 18 / 19 398932237 / 398935747 19 / 20 425219198 / 425222708 20 / 21 437022008 / 437025517 21 / 22 442563678 / 442567188 22 / X 451783418 / 451786927 X / Y 459553691 / 459557200 Y / MT 459588787 / 459592296 00:00:01.137 Open VCF file 'genotype.vcf' 00:00:01.141 Open VCF file 'sequencing.vcf' 00:00:01.176 Chromosome: '1' 00:00:02.127 1:1550992 1:1528859 00:00:02.739 1:2426313 1:2389636 ... 00:02:13.780 1:248487058 1:248471945 Output SnpSift's concordance output is written to STDOUT and two files. For instance the command java -jar SnpSift.jar concordance -v genotype.vcf sequencing.vcf will write: Concordance by variant: Written to STDOUT Concordance by sample: Written to concordance_genotyping_sequencing.by_sample.txt Summary: Written to concordance_genotyping_sequencing.summary.txt Concordance by variant This sections is a table showing concordance details for every entry (chr:position) that both files have in common. E.g.: chr pos ref alt change_0_0 change_0_1 change_0_2 change_1_0 change_1_1 change_1_2 change_2_0 change_2_1 change_2_2 missing_genotype_genotype missing_genotype_sequencing 1 865584 G A 508 0 0 0 2 0 0 0 0 0 5 1 865625 G A 512 0 0 0 1 0 0 0 0 0 1 1 865628 G A 511 0 0 0 2 0 0 0 0 0 1 1 865665 G A 495 0 0 0 4 0 0 0 0 0 17 1 865694 C T 428 0 0 0 82 0 0 0 4 0 0 Each genotype is coded according to the number of ALT variants. i.e.: '0/0' (homozygous reference) is coded as '0' '0/1' or '1/0' (heterozygous ALT) coded as '1' '1/1' (homozygous ALT) is coded as '1' So the column \"change_X_Y\" on the table shows how many genotypes coded 'X' in the first VCF, changed to 'Y' in the second VCF. For example, 'change_0_1' counts the number of \"homozygous reference in genotype.vcf\" that changed to \"heterozygous ALT in sequencing.vcf\". Or 'change_2_2' counts the number of \"homozygous ALT\" that did not change (in both files they are '2'). A few rules apply: If a VCF entry (chr:pos) is present in only one of the files, obviously we cannot calculate concordance, so it is ignored. If a VCF entry (chr:pos) has more than one ALT it is ignored. This means that non-biallelic variants are ignored. If, for the same chr:pos, REF field is different between the two files, then the entry is ignored. If, for the same chr:pos, ALT field is different between the two files, then the entry is ignored. Concordance by sample This section shows details in the same format as the previous section. Here, concordance metrics are shown aggregated for each sample. E.g.: # Totals by sample sample change_0_0 change_0_1 change_0_2 change_1_0 change_1_1 change_1_2 change_2_0 change_2_1 change_2_2 missing_genotype_genotype missing_genotype_sequencing ID_003 79 0 0 1 8 0 0 0 2 1 1 ID_004 83 0 0 1 2 0 0 0 5 0 1 ID_005 80 0 0 0 7 0 0 0 4 1 0 ID_006 79 0 0 0 5 0 0 0 6 0 2 ID_008 81 0 0 0 4 0 0 0 4 0 3 ID_009 80 0 0 0 7 0 0 0 3 0 2 ID_012 74 0 0 0 10 0 0 0 1 0 7 ID_013 79 1 0 0 4 0 0 0 5 0 3 ID_018 84 0 0 0 5 0 0 0 3 0 0 ... Summary Summary file contains overall information and errors. Here is an example of a summary file: $ cat concordance_genotyping_sequencing.summary.txt Number of samples: 929 File genotype.vcf 583 File sequencing.vcf 514 Both files Errors: ALT field does not match 19 The header indicates that one file ('genotype.vcf') has 929 samples, the other file has 583 and there are 514 matching sample IDs in both files. At the end of the file, a footer shows the total for each column followed by number of possible errors (or mismatches). In this case the were 19 ALT fields that did not match between 'genotype.vcf' and 'sequencing.vcf'. This can happen, for instance, when there are INDELs, which cannot be detected by genotyping arrays. Info Summary messages are shown to STDERR if you use verbose mode (command line option -v ).","title":"SnpSift Concordance"},{"location":"ss_concordance/#snpsift-concordance","text":"Calculate concordance between two VCF files.","title":"SnpSift Concordance"},{"location":"ss_concordance/#typical-usage","text":"This is typically used when you want to calculate concordance between a genotyping experiment and a sequencing experiment. For instance, you sequenced several samples and, as part of a related experiment or just as quality control, you also genotype the same samples using a genotyping array. Now you want to compare the two experiments. Ideally there would be no difference between the variants from genotyping and sequencing, but this is hardly the case in real world. You can use SnpSift concordance to measure the differences between the two experiments. Warning It is assumed that both VCF files are sorted by chromosome and position. Warning Sample names are defined in '#CHROM' line of the header section. Concordance is calculated only if sample label matches in both files. Example: $ java -Xmx1g -jar SnpSift.jar concordance -v genotype.vcf sequencing.vcf > concordance.txt 00:00:00.000 Indexing file 'genotype.vcf' index: MT 460030998 index: 1 19705 1 / 2 45170805 / 45174315 2 / 3 77052081 / 77055591 3 / 4 104065531 / 104069041 4 / 5 124098372 / 124101881 5 / 6 146535292 / 146538802 6 / 7 184793526 / 184797035 7 / 8 206156508 / 206160018 8 / 9 223072816 / 223076326 9 / 10 242315995 / 242319505 10 / 11 261053789 / 261057299 11 / 12 290190553 / 290194063 12 / 13 312869636 / 312873146 13 / 14 321966539 / 321970049 14 / 15 336131317 / 336134827 15 / 16 350871669 / 350875179 16 / 17 368900523 / 368904032 17 / 18 391305860 / 391309369 18 / 19 398932237 / 398935747 19 / 20 425219198 / 425222708 20 / 21 437022008 / 437025517 21 / 22 442563678 / 442567188 22 / X 451783418 / 451786927 X / Y 459553691 / 459557200 Y / MT 459588787 / 459592296 00:00:01.137 Open VCF file 'genotype.vcf' 00:00:01.141 Open VCF file 'sequencing.vcf' 00:00:01.176 Chromosome: '1' 00:00:02.127 1:1550992 1:1528859 00:00:02.739 1:2426313 1:2389636 ... 00:02:13.780 1:248487058 1:248471945","title":"Typical usage"},{"location":"ss_concordance/#output","text":"SnpSift's concordance output is written to STDOUT and two files. For instance the command java -jar SnpSift.jar concordance -v genotype.vcf sequencing.vcf will write: Concordance by variant: Written to STDOUT Concordance by sample: Written to concordance_genotyping_sequencing.by_sample.txt Summary: Written to concordance_genotyping_sequencing.summary.txt","title":"Output"},{"location":"ss_concordance/#concordance-by-variant","text":"This sections is a table showing concordance details for every entry (chr:position) that both files have in common. E.g.: chr pos ref alt change_0_0 change_0_1 change_0_2 change_1_0 change_1_1 change_1_2 change_2_0 change_2_1 change_2_2 missing_genotype_genotype missing_genotype_sequencing 1 865584 G A 508 0 0 0 2 0 0 0 0 0 5 1 865625 G A 512 0 0 0 1 0 0 0 0 0 1 1 865628 G A 511 0 0 0 2 0 0 0 0 0 1 1 865665 G A 495 0 0 0 4 0 0 0 0 0 17 1 865694 C T 428 0 0 0 82 0 0 0 4 0 0 Each genotype is coded according to the number of ALT variants. i.e.: '0/0' (homozygous reference) is coded as '0' '0/1' or '1/0' (heterozygous ALT) coded as '1' '1/1' (homozygous ALT) is coded as '1' So the column \"change_X_Y\" on the table shows how many genotypes coded 'X' in the first VCF, changed to 'Y' in the second VCF. For example, 'change_0_1' counts the number of \"homozygous reference in genotype.vcf\" that changed to \"heterozygous ALT in sequencing.vcf\". Or 'change_2_2' counts the number of \"homozygous ALT\" that did not change (in both files they are '2'). A few rules apply: If a VCF entry (chr:pos) is present in only one of the files, obviously we cannot calculate concordance, so it is ignored. If a VCF entry (chr:pos) has more than one ALT it is ignored. This means that non-biallelic variants are ignored. If, for the same chr:pos, REF field is different between the two files, then the entry is ignored. If, for the same chr:pos, ALT field is different between the two files, then the entry is ignored.","title":"Concordance by variant"},{"location":"ss_concordance/#concordance-by-sample","text":"This section shows details in the same format as the previous section. Here, concordance metrics are shown aggregated for each sample. E.g.: # Totals by sample sample change_0_0 change_0_1 change_0_2 change_1_0 change_1_1 change_1_2 change_2_0 change_2_1 change_2_2 missing_genotype_genotype missing_genotype_sequencing ID_003 79 0 0 1 8 0 0 0 2 1 1 ID_004 83 0 0 1 2 0 0 0 5 0 1 ID_005 80 0 0 0 7 0 0 0 4 1 0 ID_006 79 0 0 0 5 0 0 0 6 0 2 ID_008 81 0 0 0 4 0 0 0 4 0 3 ID_009 80 0 0 0 7 0 0 0 3 0 2 ID_012 74 0 0 0 10 0 0 0 1 0 7 ID_013 79 1 0 0 4 0 0 0 5 0 3 ID_018 84 0 0 0 5 0 0 0 3 0 0 ...","title":"Concordance by sample"},{"location":"ss_concordance/#summary","text":"Summary file contains overall information and errors. Here is an example of a summary file: $ cat concordance_genotyping_sequencing.summary.txt Number of samples: 929 File genotype.vcf 583 File sequencing.vcf 514 Both files Errors: ALT field does not match 19 The header indicates that one file ('genotype.vcf') has 929 samples, the other file has 583 and there are 514 matching sample IDs in both files. At the end of the file, a footer shows the total for each column followed by number of possible errors (or mismatches). In this case the were 19 ALT fields that did not match between 'genotype.vcf' and 'sequencing.vcf'. This can happen, for instance, when there are INDELs, which cannot be detected by genotyping arrays. Info Summary messages are shown to STDERR if you use verbose mode (command line option -v ).","title":"Summary"},{"location":"ss_dbnsfp/","text":"SnpSift dbNSFP The dbNSFP is an integrated database of functional predictions from multiple algorithms (SIFT, Polyphen2, LRT and MutationTaster, PhyloP and GERP++, etc.). Typical usage One of the main advantages is that you can annotate using multiple prediction tools with just one command. This allows for faster annotations. Here is the link to dbNSFP database website for more details. Database: In order to annotate using dbNSFP, you need to download the dbNSFP database and the index file. dbNSFP is large (several GB) so it might take a while to download it. The database is compressed (block-gzip) and tabix-indexed, so two files are required (the data .gz file and the .gz.tbi index file). You can download the files from SnpEff's site (remember that you need both the database and the index file): GRCh37 / hg19 (dbNSFP Academic): Database . Save file as dbNSFP.txt.gz Index . Save file as dbNSFP.txt.gz.tbi GRCh38 / hg38 (dbNSFP Academic): Database . Save file as dbNSFP.txt.gz Index . Save file as dbNSFP.txt.gz.tbi dbNSFP Annotation example Here is a full example how to perform annotations: # Annotate using dbNSFP # Note that the first time you run the command, it will attempt to download the dbNSFP database. java -jar SnpSift.jar dbnsfp -v myFile.vcf > myFile.annotated.vcf Info You can now specify which fields you want to use for annotation using the -f command line option followed by a comma separated list of field names. Defaults fields are shown when running the command without any arguments java -jar SnpSift.jar dbNSFP If your dbNSFP file is not in the 'default' path (where SnpEff expects it), you can specify the path to your dbNSFP file using the -db command line option: # Annotate using dbNSFP java -jar SnpSift.jar dbnsfp -v -db path/to/my/dbNSFP2.9.txt.gz myFile.vcf > myFile.annotated.vcf Building dbNSFP (for developers) Info Users do NOT need to do this, since a pre-indexed database can be downloaded from SnpSift's site (see previous sub-section). These instructions are mostly for developers. You can also create dbNSFP files yourself, downloading the files from DbNsfp site. Two files are required: A block-gzipped database file The corresponding tabix index for the database file. Creating a file that SnpSift can use is simple, just follow this guideline: # Download dbNSFP database $ wget http://dbnsfp.houstonbioinformatics.org/dbNSFPzip/dbNSFP2.9.zip # Uncompress $ unzip dbNSFP2.9.zip # Create a single file version $ (head -n 1 dbNSFP2.9_variant.chr1 ; cat dbNSFP2.9_variant.chr* | grep -v \"^#\" ) > dbNSFP2.9.txt # Compress using block-gzip algorithm bgzip dbNSFP2.9.txt # Create tabix index tabix -s 1 -b 2 -e 2 dbNSFP2.9.txt.gz Building dbNSFP for hg19/GRCh37 using dbNSFP 3.X: Latest dbNSFP versions (3.X) are based on GRCh38/hg38 genomic coordinates. In order to use the latest dbNSFP databses with GRCh37/hg19 genome versions you need to create a new dbNSFP file with the right coordinates. Fortunately, dbNSFP 3.X provides GRCh37/hg19 coordinates, so we only need to swap coordinates and sort by genomic position. You can easily do this by using the dbNSFP_sort.pl script ( you can find it here ) by running something like the following command lines: # Set to your downloaded dbNSFP version version=\"3.2a\" # Replace coordinates by columns 7 and 8 (hg19 coordinates) and sort by those coordinates cat dbNSFP${version}_variant.chr* \\ | $HOME/snpEff/scripts_build/dbNSFP_sort.pl 7 8 \\ > dbNSFP${version}_hg19.txt # Compress and index bgzip dbNSFP${version}_hg19.txt tabix -s 1 -b 2 -e 2 dbNSFP${version}_hg19.txt.gz","title":"SnpSift dbNSFP"},{"location":"ss_dbnsfp/#snpsift-dbnsfp","text":"The dbNSFP is an integrated database of functional predictions from multiple algorithms (SIFT, Polyphen2, LRT and MutationTaster, PhyloP and GERP++, etc.).","title":"SnpSift dbNSFP"},{"location":"ss_dbnsfp/#typical-usage","text":"One of the main advantages is that you can annotate using multiple prediction tools with just one command. This allows for faster annotations. Here is the link to dbNSFP database website for more details. Database: In order to annotate using dbNSFP, you need to download the dbNSFP database and the index file. dbNSFP is large (several GB) so it might take a while to download it. The database is compressed (block-gzip) and tabix-indexed, so two files are required (the data .gz file and the .gz.tbi index file). You can download the files from SnpEff's site (remember that you need both the database and the index file): GRCh37 / hg19 (dbNSFP Academic): Database . Save file as dbNSFP.txt.gz Index . Save file as dbNSFP.txt.gz.tbi GRCh38 / hg38 (dbNSFP Academic): Database . Save file as dbNSFP.txt.gz Index . Save file as dbNSFP.txt.gz.tbi","title":"Typical usage"},{"location":"ss_dbnsfp/#dbnsfp-annotation-example","text":"Here is a full example how to perform annotations: # Annotate using dbNSFP # Note that the first time you run the command, it will attempt to download the dbNSFP database. java -jar SnpSift.jar dbnsfp -v myFile.vcf > myFile.annotated.vcf Info You can now specify which fields you want to use for annotation using the -f command line option followed by a comma separated list of field names. Defaults fields are shown when running the command without any arguments java -jar SnpSift.jar dbNSFP If your dbNSFP file is not in the 'default' path (where SnpEff expects it), you can specify the path to your dbNSFP file using the -db command line option: # Annotate using dbNSFP java -jar SnpSift.jar dbnsfp -v -db path/to/my/dbNSFP2.9.txt.gz myFile.vcf > myFile.annotated.vcf","title":"dbNSFP Annotation example"},{"location":"ss_dbnsfp/#building-dbnsfp-for-developers","text":"Info Users do NOT need to do this, since a pre-indexed database can be downloaded from SnpSift's site (see previous sub-section). These instructions are mostly for developers. You can also create dbNSFP files yourself, downloading the files from DbNsfp site. Two files are required: A block-gzipped database file The corresponding tabix index for the database file. Creating a file that SnpSift can use is simple, just follow this guideline: # Download dbNSFP database $ wget http://dbnsfp.houstonbioinformatics.org/dbNSFPzip/dbNSFP2.9.zip # Uncompress $ unzip dbNSFP2.9.zip # Create a single file version $ (head -n 1 dbNSFP2.9_variant.chr1 ; cat dbNSFP2.9_variant.chr* | grep -v \"^#\" ) > dbNSFP2.9.txt # Compress using block-gzip algorithm bgzip dbNSFP2.9.txt # Create tabix index tabix -s 1 -b 2 -e 2 dbNSFP2.9.txt.gz Building dbNSFP for hg19/GRCh37 using dbNSFP 3.X: Latest dbNSFP versions (3.X) are based on GRCh38/hg38 genomic coordinates. In order to use the latest dbNSFP databses with GRCh37/hg19 genome versions you need to create a new dbNSFP file with the right coordinates. Fortunately, dbNSFP 3.X provides GRCh37/hg19 coordinates, so we only need to swap coordinates and sort by genomic position. You can easily do this by using the dbNSFP_sort.pl script ( you can find it here ) by running something like the following command lines: # Set to your downloaded dbNSFP version version=\"3.2a\" # Replace coordinates by columns 7 and 8 (hg19 coordinates) and sort by those coordinates cat dbNSFP${version}_variant.chr* \\ | $HOME/snpEff/scripts_build/dbNSFP_sort.pl 7 8 \\ > dbNSFP${version}_hg19.txt # Compress and index bgzip dbNSFP${version}_hg19.txt tabix -s 1 -b 2 -e 2 dbNSFP${version}_hg19.txt.gz","title":"Building dbNSFP (for developers)"},{"location":"ss_extractfields/","text":"SnpSift Extract Fields Extract fields from a VCF file to a TXT, tab separated format, that you can easily load in R, XLS, etc. Typical usage You can also use sub-fields and genotype fields / sub-fields such as: Standard VCF fields: CHROM POS ID REF ALT FILTER INFO fields: AF AC DP MQ etc. (any info field available) SnpEff 'ANN' fields: \"ANN[*].ALLELE\" (alias GENOTYPE) \"ANN[*].EFFECT\" (alias ANNOTATION): Effect in Sequence ontology terms (e.g. 'missense_variant', 'synonymous_variant', 'stop_gained', etc.) \"ANN[*].IMPACT:\" { HIGH, MODERATE, LOW, MODIFIER } \"ANN[*].GENE:\" Gene name (e.g. 'PSD3') \"ANN[*].GENEID:\" Gene ID \"ANN[*].FEATURE\" \"ANN[*].FEATUREID\" (alias TRID: Transcript ID) \"ANN[*].BIOTYPE:\" Biotype, as described by the annotations (e.g. 'protein_coding') \"ANN[*].RANK:\" Exon or Intron rank (i.e. exon number in a transcript) \"ANN[*].HGVS_C\" (alias HGVS_DNA, CODON): Variant in HGVS (DNA) notation \"ANN[*].HGVS_P\" (alias HGVS, HGVS_PROT, AA): Variant in HGVS (protein) notation \"ANN[*].CDNA_POS\" (alias POS_CDNA) \"ANN[*].CDNA_LEN\" (alias LEN_CDNA) \"ANN[*].CDS_POS\" (alias POS_CDS) \"ANN[*].CDS_LEN\" (alias LEN_CDS) \"ANN[*].AA_POS\" (alias POS_AA) \"ANN[*].AA_LEN\" (alias LEN_AA) \"ANN[*].DISTANCE\" \"ANN[*].ERRORS\" (alias WARNING, INFOS) SnpEff 'EFF' fields (this is for older SnpEff/SnpSift versions, new version use 'ANN' field): \"EFF[*].EFFECT\" \"EFF[*].IMPACT\" \"EFF[*].FUNCLASS\" \"EFF[*].CODON\" \"EFF[*].AA\" \"EFF[*].AA_LEN\" \"EFF[*].GENE\" \"EFF[*].BIOTYPE\" \"EFF[*].CODING\" \"EFF[*].TRID\" \"EFF[*].RANK\" Info You can combine vcfEffOnePerLine.pl script with SnpSift extractFields if you want to have each effect in a separate line. SnpEff 'LOF' fields: \"LOF[*].GENE\" \"LOF[*].GENEID\" \"LOF[*].NUMTR\" \"LOF[*].PERC\" SnpEff' NMD' fields: \"NMD[*].GENE\" \"NMD[*].GENEID\" \"NMD[*].NUMTR\" \"NMD[*].PERC\" Warning When using multiple indexes (e.g. \"ANN[*].EFFECT\") you must remember to use quotes the command line. Otherwise, the shell would parse the asterisk changing the expression and producing unexpected results. Info You can use command line option -s to specify multiple field separator and -e to specify how to represent empty fields. Example 1: Extracting chromosome, position, ID and allele frequency $ java -jar SnpSift.jar extractFields s.vcf CHROM POS ID AF | head #CHROM POS ID AF 1 69134 0.086 1 69496 rs150690004 0.001 1 69511 rs75062661 0.983 1 69569 0.538 1 721559 0.001 1 721757 0.011 1 846854 rs111957712 0.003 1 865584 rs148711625 0.001 1 865625 rs146327803 0.001 Example 2: Extracting genotype fields $ java -jar SnpSift.jar extractFields file.vcf \"CHROM\" \"POS\" \"ID\" \"THETA\" \"GEN[0].GL[1]\" \"GEN[1].GL\" \"GEN[3].GL[*]\" \"GEN[*].GT\" This means to extract: CHROM POS ID: regular fields (as in the previous example) THETA : This one is from INFO \"GEN[0].GL[1]\" : Second likelihood from first genotype \"GEN[1].GL\" : The whole GL fields (all entries without separating them) \"GEN[3].GL[*]\" : All likelihoods form genotype 3 (this time they will be tab separated, as opposed to the previous one). \"GEN[*].GT\" : Genotype subfields (GT) from ALL samples (tab separated). The result will look something like: #CHROM POS ID THETA GEN[0].GL[1] GEN[1].GL GEN[3].GL[*] GEN[*].GT 1 10583 rs58108140 0.0046 -0.47 -0.24,-0.44,-1.16 -0.48 -0.48 -0.48 0|0 0|0 0|0 0|1 0|0 0|1 0|0 0|0 0|1 1 10611 rs189107123 0.0077 -0.48 -0.24,-0.44,-1.16 -0.48 -0.48 -0.48 0|0 0|1 0|0 0|0 0|0 0|0 0|0 0|0 0|0 1 13302 rs180734498 0.0048 -0.58 -2.45,-0.00,-5.00 -0.48 -0.48 -0.48 0|0 0|1 0|0 0|0 0|0 1|0 0|0 0|1 0|0 1 13327 rs144762171 0.0204 -1.11 -1.97,-0.01,-2.51 -0.48 -0.48 -0.48 0|0 0|1 0|0 0|0 0|0 1|0 0|0 0|0 0|0 1 13957 rs201747181 0.0100 0 0,0,0 0 0 0 0|0 0|1 0|0 0|0 0|0 0|0 0|0 0|0 0|0 1 13980 rs151276478 0.0139 -0.48 -0.48,-0.48,-0.48 -0.48 -0.48 -0.48 0|0 0|0 0|0 0|0 0|0 0|0 0|0 0|0 0|0 1 30923 rs140337953 0.0162 -0.61 -0.10,-0.69,-2.81 -0.48 -0.48 -0.48 1|1 0|0 0|0 1|1 1|0 0|0 1|1 1|0 1|1 1 46402 rs199681827 0.0121 0 0,0,0 0 0 0 0|0 0|0 0|0 0|0 0|0 0|0 0|0 0|0 0|0 1 47190 rs200430748 0.0153 0 0,0,0 0 0 0 0|0 0|0 0|0 0|0 0|0 0|0 0|0 0|0 0|0 Example 3: Extracting fields with multiple values in a friendlier format You can use command line option -s to specify multiple field separator and -e to specify how to represent empty fields. $ java -jar SnpSift.jar extractFields -s \",\" -e \".\" test.chr22.ann.vcf CHROM POS REF ALT \"EFF[*].EFFECT\" \"EFF[*].AA\" Notice how we separate same fields using \",\" instead of the default tab using the option -s \",\" , and we use \".\" for empty fields (option -e \".\" ). The results is: $ java -jar SnpSift.jar extractFields -s \",\" -e \".\" examples/test.chr22.ann.vcf CHROM POS REF ALT \"ANN[*].EFFECT\" \"ANN[*].HGVS_P\" #CHROM POS REF ALT ANN[*].EFFECT ANN[*].HGVS_P 22 17071756 T C 3_prime_UTR_variant,downstream_gene_variant .,. 22 17072035 C T missense_variant,downstream_gene_variant p.Gly469Glu,. 22 17072258 C A missense_variant,downstream_gene_variant p.Gly395Cys,. 22 17072674 G A missense_variant,downstream_gene_variant p.Pro256Leu,. 22 17072747 T C missense_variant,downstream_gene_variant p.Met232Val,. 22 17072781 C T synonymous_variant,downstream_gene_variant p.Pro220Pro,. 22 17073043 C T missense_variant,downstream_gene_variant p.Arg133Gln,. 22 17073066 A G synonymous_variant,downstream_gene_variant p.Ala125Ala,. 22 17073119 C T missense_variant,downstream_gene_variant p.Val108Met,. Example 4: Extracting effects, one per line In order to extract effects, you can simply do something like this (notice that there are multiple columns per line because there are multiple effects per variant): $ java -jar SnpSift.jar extractFields examples/test.chr22.ann.vcf CHROM POS REF ALT \"ANN[*].EFFECT\" #CHROM POS REF ALT ANN[*].EFFECT 22 17071756 T C 3_prime_UTR_variant downstream_gene_variant 22 17072035 C T missense_variant downstream_gene_variant 22 17072258 C A missense_variant downstream_gene_variant 22 17072674 G A missense_variant downstream_gene_variant 22 17072747 T C missense_variant downstream_gene_variant 22 17072781 C T synonymous_variant downstream_gene_variant 22 17073043 C T missense_variant downstream_gene_variant 22 17073066 A G synonymous_variant downstream_gene_variant 22 17073119 C T missense_variant downstream_gene_variant Note that since some variant have more than one effect, there can be more than one \"EFFECT\" column. If we prefer to have one effect per line, then we can use the vcfEffOnePerLine.pl provided with SnpEff distribution $ cat examples/test.chr22.ann.vcf \\ | ./scripts/vcfEffOnePerLine.pl \\ | java -jar SnpSift.jar extractFields - CHROM POS REF ALT \"ANN[*].EFFECT\" \\ #CHROM POS REF ALT ANN[*].EFFECT 22 17071756 T C 3_prime_UTR_variant 22 17071756 T C downstream_gene_variant 22 17072035 C T missense_variant 22 17072035 C T downstream_gene_variant 22 17072258 C A missense_variant 22 17072258 C A downstream_gene_variant 22 17072674 G A missense_variant 22 17072674 G A downstream_gene_variant 22 17072747 T C missense_variant Now we obtain one effect per line, while all other parameters in the line are repeated across mutiple lines (e.g. there are two chr22:17071756 lines, one for each variant annotation). Info Note that in SnpSift, we used - as input file name, which denotes STDIN. Example 5: Extracting genotype using genotype name instead of genotype number As of SnpSift version 4.1A, you can use the genotype name in expressions: $ java -jar SnpSift.jar extractFields examples/1kg.head_chr1.vcf.gz CHROM POS REF ALT \"GEN[HG00096].DS\" \"GEN[HG00097].DS\" #CHROM POS REF ALT GEN[HG00096].DS GEN[HG00097].DS 1 10583 G A 0.2 0.15 1 10611 C G 0.05 0.75 1 13302 C T 0.05 1.0 1 13327 G C 0.0 0.95 1 13957 TC T 0.05 0.65 1 13980 T C 0.05 0.6 1 30923 G T 1.75 0.35 1 46402 C CTGT 0.05 0.15 1 47190 G GA 0.15 0.0 Example 6: Extracting non alphanumeric field names Warning SnpSift extractFields can get confused if the VCF field has non-alphanumeric charaters in the name (e.g. dbNSFP_GERP++_RS has two \"+\" signs). A quick fix, it so is to change the field names in the VCF file. Here is an example: # Change field names in VCF $ cat kath.vcf | sed \"s/dbNSFP_GERP++/dbNSFP_GERP/g\" > kath.gerp.vcf # Use new names to extract fields $ java -jar SnpSift.jar extractFields kath.gerp.vcf CHROM POS REF ALT dbNSFP_GERP_RS dbNSFP_GERP_NS #CHROM POS REF ALT dbNSFP_GERP_RS 1 142827044 G A 2 132914561 G A 7 151933217 C A 7 151933251 T C 7 151933302 T C 7 151945101 G C -0.892 7 151945167 G T 7 151962176 T A 7 151970672 A T 7 151970856 T A 3.71 18 14183638 G C 18 14183710 A G 18 14542909 G A 18 14543039 T C -0.942","title":"SnpSift Extract Fields"},{"location":"ss_extractfields/#snpsift-extract-fields","text":"Extract fields from a VCF file to a TXT, tab separated format, that you can easily load in R, XLS, etc.","title":"SnpSift Extract Fields"},{"location":"ss_extractfields/#typical-usage","text":"You can also use sub-fields and genotype fields / sub-fields such as: Standard VCF fields: CHROM POS ID REF ALT FILTER INFO fields: AF AC DP MQ etc. (any info field available) SnpEff 'ANN' fields: \"ANN[*].ALLELE\" (alias GENOTYPE) \"ANN[*].EFFECT\" (alias ANNOTATION): Effect in Sequence ontology terms (e.g. 'missense_variant', 'synonymous_variant', 'stop_gained', etc.) \"ANN[*].IMPACT:\" { HIGH, MODERATE, LOW, MODIFIER } \"ANN[*].GENE:\" Gene name (e.g. 'PSD3') \"ANN[*].GENEID:\" Gene ID \"ANN[*].FEATURE\" \"ANN[*].FEATUREID\" (alias TRID: Transcript ID) \"ANN[*].BIOTYPE:\" Biotype, as described by the annotations (e.g. 'protein_coding') \"ANN[*].RANK:\" Exon or Intron rank (i.e. exon number in a transcript) \"ANN[*].HGVS_C\" (alias HGVS_DNA, CODON): Variant in HGVS (DNA) notation \"ANN[*].HGVS_P\" (alias HGVS, HGVS_PROT, AA): Variant in HGVS (protein) notation \"ANN[*].CDNA_POS\" (alias POS_CDNA) \"ANN[*].CDNA_LEN\" (alias LEN_CDNA) \"ANN[*].CDS_POS\" (alias POS_CDS) \"ANN[*].CDS_LEN\" (alias LEN_CDS) \"ANN[*].AA_POS\" (alias POS_AA) \"ANN[*].AA_LEN\" (alias LEN_AA) \"ANN[*].DISTANCE\" \"ANN[*].ERRORS\" (alias WARNING, INFOS) SnpEff 'EFF' fields (this is for older SnpEff/SnpSift versions, new version use 'ANN' field): \"EFF[*].EFFECT\" \"EFF[*].IMPACT\" \"EFF[*].FUNCLASS\" \"EFF[*].CODON\" \"EFF[*].AA\" \"EFF[*].AA_LEN\" \"EFF[*].GENE\" \"EFF[*].BIOTYPE\" \"EFF[*].CODING\" \"EFF[*].TRID\" \"EFF[*].RANK\" Info You can combine vcfEffOnePerLine.pl script with SnpSift extractFields if you want to have each effect in a separate line. SnpEff 'LOF' fields: \"LOF[*].GENE\" \"LOF[*].GENEID\" \"LOF[*].NUMTR\" \"LOF[*].PERC\" SnpEff' NMD' fields: \"NMD[*].GENE\" \"NMD[*].GENEID\" \"NMD[*].NUMTR\" \"NMD[*].PERC\" Warning When using multiple indexes (e.g. \"ANN[*].EFFECT\") you must remember to use quotes the command line. Otherwise, the shell would parse the asterisk changing the expression and producing unexpected results. Info You can use command line option -s to specify multiple field separator and -e to specify how to represent empty fields.","title":"Typical usage"},{"location":"ss_extractfields/#example-1-extracting-chromosome-position-id-and-allele-frequency","text":"$ java -jar SnpSift.jar extractFields s.vcf CHROM POS ID AF | head #CHROM POS ID AF 1 69134 0.086 1 69496 rs150690004 0.001 1 69511 rs75062661 0.983 1 69569 0.538 1 721559 0.001 1 721757 0.011 1 846854 rs111957712 0.003 1 865584 rs148711625 0.001 1 865625 rs146327803 0.001","title":"Example 1: Extracting chromosome, position, ID and allele frequency"},{"location":"ss_extractfields/#example-2-extracting-genotype-fields","text":"$ java -jar SnpSift.jar extractFields file.vcf \"CHROM\" \"POS\" \"ID\" \"THETA\" \"GEN[0].GL[1]\" \"GEN[1].GL\" \"GEN[3].GL[*]\" \"GEN[*].GT\" This means to extract: CHROM POS ID: regular fields (as in the previous example) THETA : This one is from INFO \"GEN[0].GL[1]\" : Second likelihood from first genotype \"GEN[1].GL\" : The whole GL fields (all entries without separating them) \"GEN[3].GL[*]\" : All likelihoods form genotype 3 (this time they will be tab separated, as opposed to the previous one). \"GEN[*].GT\" : Genotype subfields (GT) from ALL samples (tab separated). The result will look something like: #CHROM POS ID THETA GEN[0].GL[1] GEN[1].GL GEN[3].GL[*] GEN[*].GT 1 10583 rs58108140 0.0046 -0.47 -0.24,-0.44,-1.16 -0.48 -0.48 -0.48 0|0 0|0 0|0 0|1 0|0 0|1 0|0 0|0 0|1 1 10611 rs189107123 0.0077 -0.48 -0.24,-0.44,-1.16 -0.48 -0.48 -0.48 0|0 0|1 0|0 0|0 0|0 0|0 0|0 0|0 0|0 1 13302 rs180734498 0.0048 -0.58 -2.45,-0.00,-5.00 -0.48 -0.48 -0.48 0|0 0|1 0|0 0|0 0|0 1|0 0|0 0|1 0|0 1 13327 rs144762171 0.0204 -1.11 -1.97,-0.01,-2.51 -0.48 -0.48 -0.48 0|0 0|1 0|0 0|0 0|0 1|0 0|0 0|0 0|0 1 13957 rs201747181 0.0100 0 0,0,0 0 0 0 0|0 0|1 0|0 0|0 0|0 0|0 0|0 0|0 0|0 1 13980 rs151276478 0.0139 -0.48 -0.48,-0.48,-0.48 -0.48 -0.48 -0.48 0|0 0|0 0|0 0|0 0|0 0|0 0|0 0|0 0|0 1 30923 rs140337953 0.0162 -0.61 -0.10,-0.69,-2.81 -0.48 -0.48 -0.48 1|1 0|0 0|0 1|1 1|0 0|0 1|1 1|0 1|1 1 46402 rs199681827 0.0121 0 0,0,0 0 0 0 0|0 0|0 0|0 0|0 0|0 0|0 0|0 0|0 0|0 1 47190 rs200430748 0.0153 0 0,0,0 0 0 0 0|0 0|0 0|0 0|0 0|0 0|0 0|0 0|0 0|0","title":"Example 2: Extracting genotype fields"},{"location":"ss_extractfields/#example-3-extracting-fields-with-multiple-values-in-a-friendlier-format","text":"You can use command line option -s to specify multiple field separator and -e to specify how to represent empty fields. $ java -jar SnpSift.jar extractFields -s \",\" -e \".\" test.chr22.ann.vcf CHROM POS REF ALT \"EFF[*].EFFECT\" \"EFF[*].AA\" Notice how we separate same fields using \",\" instead of the default tab using the option -s \",\" , and we use \".\" for empty fields (option -e \".\" ). The results is: $ java -jar SnpSift.jar extractFields -s \",\" -e \".\" examples/test.chr22.ann.vcf CHROM POS REF ALT \"ANN[*].EFFECT\" \"ANN[*].HGVS_P\" #CHROM POS REF ALT ANN[*].EFFECT ANN[*].HGVS_P 22 17071756 T C 3_prime_UTR_variant,downstream_gene_variant .,. 22 17072035 C T missense_variant,downstream_gene_variant p.Gly469Glu,. 22 17072258 C A missense_variant,downstream_gene_variant p.Gly395Cys,. 22 17072674 G A missense_variant,downstream_gene_variant p.Pro256Leu,. 22 17072747 T C missense_variant,downstream_gene_variant p.Met232Val,. 22 17072781 C T synonymous_variant,downstream_gene_variant p.Pro220Pro,. 22 17073043 C T missense_variant,downstream_gene_variant p.Arg133Gln,. 22 17073066 A G synonymous_variant,downstream_gene_variant p.Ala125Ala,. 22 17073119 C T missense_variant,downstream_gene_variant p.Val108Met,.","title":"Example 3: Extracting fields with multiple values in a friendlier format"},{"location":"ss_extractfields/#example-4-extracting-effects-one-per-line","text":"In order to extract effects, you can simply do something like this (notice that there are multiple columns per line because there are multiple effects per variant): $ java -jar SnpSift.jar extractFields examples/test.chr22.ann.vcf CHROM POS REF ALT \"ANN[*].EFFECT\" #CHROM POS REF ALT ANN[*].EFFECT 22 17071756 T C 3_prime_UTR_variant downstream_gene_variant 22 17072035 C T missense_variant downstream_gene_variant 22 17072258 C A missense_variant downstream_gene_variant 22 17072674 G A missense_variant downstream_gene_variant 22 17072747 T C missense_variant downstream_gene_variant 22 17072781 C T synonymous_variant downstream_gene_variant 22 17073043 C T missense_variant downstream_gene_variant 22 17073066 A G synonymous_variant downstream_gene_variant 22 17073119 C T missense_variant downstream_gene_variant Note that since some variant have more than one effect, there can be more than one \"EFFECT\" column. If we prefer to have one effect per line, then we can use the vcfEffOnePerLine.pl provided with SnpEff distribution $ cat examples/test.chr22.ann.vcf \\ | ./scripts/vcfEffOnePerLine.pl \\ | java -jar SnpSift.jar extractFields - CHROM POS REF ALT \"ANN[*].EFFECT\" \\ #CHROM POS REF ALT ANN[*].EFFECT 22 17071756 T C 3_prime_UTR_variant 22 17071756 T C downstream_gene_variant 22 17072035 C T missense_variant 22 17072035 C T downstream_gene_variant 22 17072258 C A missense_variant 22 17072258 C A downstream_gene_variant 22 17072674 G A missense_variant 22 17072674 G A downstream_gene_variant 22 17072747 T C missense_variant Now we obtain one effect per line, while all other parameters in the line are repeated across mutiple lines (e.g. there are two chr22:17071756 lines, one for each variant annotation). Info Note that in SnpSift, we used - as input file name, which denotes STDIN.","title":"Example 4: Extracting effects, one per line"},{"location":"ss_extractfields/#example-5-extracting-genotype-using-genotype-name-instead-of-genotype-number","text":"As of SnpSift version 4.1A, you can use the genotype name in expressions: $ java -jar SnpSift.jar extractFields examples/1kg.head_chr1.vcf.gz CHROM POS REF ALT \"GEN[HG00096].DS\" \"GEN[HG00097].DS\" #CHROM POS REF ALT GEN[HG00096].DS GEN[HG00097].DS 1 10583 G A 0.2 0.15 1 10611 C G 0.05 0.75 1 13302 C T 0.05 1.0 1 13327 G C 0.0 0.95 1 13957 TC T 0.05 0.65 1 13980 T C 0.05 0.6 1 30923 G T 1.75 0.35 1 46402 C CTGT 0.05 0.15 1 47190 G GA 0.15 0.0","title":"Example 5: Extracting genotype using genotype name instead of genotype number"},{"location":"ss_extractfields/#example-6-extracting-non-alphanumeric-field-names","text":"Warning SnpSift extractFields can get confused if the VCF field has non-alphanumeric charaters in the name (e.g. dbNSFP_GERP++_RS has two \"+\" signs). A quick fix, it so is to change the field names in the VCF file. Here is an example: # Change field names in VCF $ cat kath.vcf | sed \"s/dbNSFP_GERP++/dbNSFP_GERP/g\" > kath.gerp.vcf # Use new names to extract fields $ java -jar SnpSift.jar extractFields kath.gerp.vcf CHROM POS REF ALT dbNSFP_GERP_RS dbNSFP_GERP_NS #CHROM POS REF ALT dbNSFP_GERP_RS 1 142827044 G A 2 132914561 G A 7 151933217 C A 7 151933251 T C 7 151933302 T C 7 151945101 G C -0.892 7 151945167 G T 7 151962176 T A 7 151970672 A T 7 151970856 T A 3.71 18 14183638 G C 18 14183710 A G 18 14542909 G A 18 14543039 T C -0.942","title":"Example 6: Extracting non alphanumeric field names"},{"location":"ss_faq/","text":"SnpSift: Frequently Asked Questions Corrupted database VCF files: ClinVar Some VCF files used as annotation databases can be non-compliant. Most notably, some ClinVar versions have illegal VCF values, which will make downstream analysis tools, such as SnpSift to report the errors. For example, if you look into the file: $ curl -s ftp://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh37/clinvar.vcf.gz | gunzip -c | grep \"&base\" | head -n 1 13 32890543 125955 G A . . ALLELEID=131493;CLNDISDB=MedGen:C2675520,OMIM:612555;CLNDN=Breast-ovarian_cancer,_familial_2;CLNHGVS=NC_000013.10:g.32890543G>A;CLNREVSTAT=no_assertion_criteria_provided;CLNSIG=Uncertain_significance;CLNVC=single_nucleotide_variant;CLNVCSO=SO:0001483;CLNVI=Breast_Cancer_Information_Core__(BRCA2):190-16&base_change=G_to_A;GENEINFO=BRCA2:675;MC=SO:0001627|intron_variant;ORIGIN=1;RS=276174799 As you can see, the \"CLNVI\" is: CLNVI=Breast_Cancer_Information_Core__(BRCA2):190-16&base_change=G_to_A This means that the CLNVI contains an illegal '=' character. The VCF specification clearly states that the equal sign is not allowed: Reference: https://samtools.github.io/hts-specs/VCFv4.3.pdf Section 1.2: \"Character encoding, non-printable characters and characters with special meaning\" Characters with special meaning (such as field delimiters \u2019;\u2019 in INFO or \u2019:\u2019 FORMAT fields) must be represented using the capitalized percent encoding: %3A : (colon) %3B ; (semicolon) %3D = (equal sign) ... Furthermore, section 1.6.1.8 specifies: INFO - additional information: (String, no semi-colons or equals-signs permitted; commas are permitted only as delimiters for lists of values; characters with special meaning can be encoded using the percent encoding, see Section 1.2; space characters are allowed) Finding all ClinVar problems An easy way to find many of the problems in the VCF file is to use the SnpSift checkVcf command: $ java -jar SnpSift.jar vcfCheck clinvar.vcf.gz 2>&1 | head ...WARNING: Malformed VCF entryfile '/home/pcingola/Downloads/clinvar.vcf.gz', line 3655: Entry : 1 25717365 17708 C C . . ALLELEID=32747;CLNDISDB=.;CLNDN=RH_E/e_POLYMORPHISM;CLNHGVS=NC_000001.10:g.25717365C=;CLNREVSTAT=no_assertion_criteria_provided;CLNSIG=Benign;CLNVC=single_nucleotide_variant;CLNVCSO=SO:0001483;CLNVI=OMIM_Allelic_Variant:111700.0001;GENEINFO=RHCE:6006;MC=SO:0001627|intron_variant,SO:0001819|synonymous_variant;ORIGIN=1;RS=609320 Errors : INFO filed 'CLNHGVS' has an invalid value 'NC_000001.10:g.25717365C=' (no spaces, tabs, '=' or ';' are allowed) WARNING: Malformed VCF entryfile '/home/pcingola/Downloads/clinvar.vcf.gz', line 3657: Entry : 1 25735202 242743 G G . . ALLELEID=38411;CLNHGVS=NC_000001.10:g.25735202G=;CLNREVSTAT=no_interpretation_for_the_single_variant;CLNVC=single_nucleotide_variant;CLNVCSO=SO:0001483;CLNVI=OMIM_Allelic_Variant:111700.0002;GENEINFO=RHCE:6006;MC=SO:0001819|synonymous_variant;ORIGIN=1;RS=676785;SSR=1;CLNDISDBINCL=.;CLNDNINCL=RH_C/c_POLYMORPHISM;CLNSIGINCL=17709:Benign Errors : INFO filed 'CLNHGVS' has an invalid value 'NC_000001.10:g.25735202G=' (no spaces, tabs, '=' or ';' are allowed) OK, it looks like there are quite a few problems, let's count them: $ java -jar SnpSift.jar vcfCheck ~/Downloads/clinvar.vcf.gz 2>&1 | grep WARN | wc -l 1793 Well, there seems to be 1793 lines VCF with some sort of problem. Let's see how to fix them. Fixing ClinVar's VCF database So, you need to fix ClinVar by either: Remove the offending fields from the VCF file Fix the character coding for the offending values Option 1: Remove the offending fields This is the easiest way to fix ClinVar's VCF file. First, let's find the corrupted fields: $ java -jar SnpSift.jar vcfCheck clinvar.vcf.gz 2>&1 | grep \"INFO field\" | cut -f 2 -d \"'\" | sort | uniq -c 212 CLNHGVS 1583 CLNVI OK, there are 212 lines with corrupted CLNHGVS fields and 1583 lines with corrupted CLNVI fields. Let's create a new database without those fields $ java -jar SnpSift.jar rmInfo clinvar.vcf.gz CLNHGVS CLNVI > clinvar.fixed_1.vcf 00:00:00 Reading STDIN 00:00:03 Done # Let's also compress and index the new file so we can use it as a database $ bgzip clinvar.fixed_1.vcf $ tabix clinvar.fixed_1.vcf.gz Now we can re-check the new file to make sure it's OK. $ java -jar SnpSift.jar vcfCheck clinvar.fixed_1.vcf.gz .................................................................................................... 100000 .................................................................................................... 200000 .................................................................................................. Everything seems OK. Option 2: Fix the encoding Here we need to fix the encoding of the fields. We know (see previous section) that the problematic fields are CLNVI and CLNHGVS , so what exactly are the problems? $ java -jar SnpSift.jar vcfCheck clinvar.vcf.gz 2>&1 | grep \"INFO field\" | grep CLNVI | head INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):190-16&base_change=G_to_A' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):190-12&base_change=del_TCT' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):190-5&base_change=del_T' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):190-7&base_change=T_to_C' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):195&base_change=T_to_C' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):203&base_change=G_to_A' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):203&base_change=G_to_C' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):203&base_change=G_to_T' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):214&base_change=A_to_C' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):215&base_change=T_to_C' (no spaces, tabs, '=' or ';' are allowed) OK, this one seems easy: All we need to do is change &base_change= to &base_change%3D This can be done with a simple sed command: $ zcat clinvar.vcf.gz | sed 's/\\&base_change=/\\&base_change%3D/g' How about the other field? $ java -jar SnpSift.jar vcfCheck clinvar.vcf.gz 2>&1 | grep \"INFO field\" | grep CLNHGVS | head INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.25717365C=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.25735202G=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.25735306T=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.25735331G=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.94578548T=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.98348885G=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.100672060T=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.114377568A=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.161599571T=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.161599643T=' (no spaces, tabs, '=' or ';' are allowed) This is essentially the same, but we need four sed commands (one for each base): $ zcat clinvar.vcf.gz \\ | sed 's/A=;/A%3D;/' \\ | sed 's/C=;/C%3D;/' \\ | sed 's/G=;/G%3D;/' \\ | sed 's/T=;/T%3D;/' The fix: Now, let's put the two previously explained fixes together: $ zcat clinvar.vcf.gz \\ | sed 's/\\&base_change=/\\&base_change%3D/g' \\ | sed 's/A=;/A%3D;/' \\ | sed 's/C=;/C%3D;/' \\ | sed 's/G=;/G%3D;/' \\ | sed 's/T=;/T%3D;/' \\ > clinvar.fixed.vcf # Let's also compress and index the new file so we can use it as a database $ bgzip clinvar.fixed.vcf $ tabix clinvar.fixed.vcf.gz We re-check the new $ java -jar SnpSift.jar vcfCheck clinvar.fixed.vcf.gz .................................................................................................... 100000 .................................................................................................... 200000 .................................................................................................. OK, we are done.","title":"Frequently asked questions"},{"location":"ss_faq/#snpsift-frequently-asked-questions","text":"","title":"SnpSift: Frequently Asked Questions"},{"location":"ss_faq/#corrupted-database-vcf-files-clinvar","text":"Some VCF files used as annotation databases can be non-compliant. Most notably, some ClinVar versions have illegal VCF values, which will make downstream analysis tools, such as SnpSift to report the errors. For example, if you look into the file: $ curl -s ftp://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh37/clinvar.vcf.gz | gunzip -c | grep \"&base\" | head -n 1 13 32890543 125955 G A . . ALLELEID=131493;CLNDISDB=MedGen:C2675520,OMIM:612555;CLNDN=Breast-ovarian_cancer,_familial_2;CLNHGVS=NC_000013.10:g.32890543G>A;CLNREVSTAT=no_assertion_criteria_provided;CLNSIG=Uncertain_significance;CLNVC=single_nucleotide_variant;CLNVCSO=SO:0001483;CLNVI=Breast_Cancer_Information_Core__(BRCA2):190-16&base_change=G_to_A;GENEINFO=BRCA2:675;MC=SO:0001627|intron_variant;ORIGIN=1;RS=276174799 As you can see, the \"CLNVI\" is: CLNVI=Breast_Cancer_Information_Core__(BRCA2):190-16&base_change=G_to_A This means that the CLNVI contains an illegal '=' character. The VCF specification clearly states that the equal sign is not allowed: Reference: https://samtools.github.io/hts-specs/VCFv4.3.pdf Section 1.2: \"Character encoding, non-printable characters and characters with special meaning\" Characters with special meaning (such as field delimiters \u2019;\u2019 in INFO or \u2019:\u2019 FORMAT fields) must be represented using the capitalized percent encoding: %3A : (colon) %3B ; (semicolon) %3D = (equal sign) ... Furthermore, section 1.6.1.8 specifies: INFO - additional information: (String, no semi-colons or equals-signs permitted; commas are permitted only as delimiters for lists of values; characters with special meaning can be encoded using the percent encoding, see Section 1.2; space characters are allowed)","title":"Corrupted database VCF files: ClinVar"},{"location":"ss_faq/#finding-all-clinvar-problems","text":"An easy way to find many of the problems in the VCF file is to use the SnpSift checkVcf command: $ java -jar SnpSift.jar vcfCheck clinvar.vcf.gz 2>&1 | head ...WARNING: Malformed VCF entryfile '/home/pcingola/Downloads/clinvar.vcf.gz', line 3655: Entry : 1 25717365 17708 C C . . ALLELEID=32747;CLNDISDB=.;CLNDN=RH_E/e_POLYMORPHISM;CLNHGVS=NC_000001.10:g.25717365C=;CLNREVSTAT=no_assertion_criteria_provided;CLNSIG=Benign;CLNVC=single_nucleotide_variant;CLNVCSO=SO:0001483;CLNVI=OMIM_Allelic_Variant:111700.0001;GENEINFO=RHCE:6006;MC=SO:0001627|intron_variant,SO:0001819|synonymous_variant;ORIGIN=1;RS=609320 Errors : INFO filed 'CLNHGVS' has an invalid value 'NC_000001.10:g.25717365C=' (no spaces, tabs, '=' or ';' are allowed) WARNING: Malformed VCF entryfile '/home/pcingola/Downloads/clinvar.vcf.gz', line 3657: Entry : 1 25735202 242743 G G . . ALLELEID=38411;CLNHGVS=NC_000001.10:g.25735202G=;CLNREVSTAT=no_interpretation_for_the_single_variant;CLNVC=single_nucleotide_variant;CLNVCSO=SO:0001483;CLNVI=OMIM_Allelic_Variant:111700.0002;GENEINFO=RHCE:6006;MC=SO:0001819|synonymous_variant;ORIGIN=1;RS=676785;SSR=1;CLNDISDBINCL=.;CLNDNINCL=RH_C/c_POLYMORPHISM;CLNSIGINCL=17709:Benign Errors : INFO filed 'CLNHGVS' has an invalid value 'NC_000001.10:g.25735202G=' (no spaces, tabs, '=' or ';' are allowed) OK, it looks like there are quite a few problems, let's count them: $ java -jar SnpSift.jar vcfCheck ~/Downloads/clinvar.vcf.gz 2>&1 | grep WARN | wc -l 1793 Well, there seems to be 1793 lines VCF with some sort of problem. Let's see how to fix them.","title":"Finding all ClinVar problems"},{"location":"ss_faq/#fixing-clinvars-vcf-database","text":"So, you need to fix ClinVar by either: Remove the offending fields from the VCF file Fix the character coding for the offending values","title":"Fixing ClinVar's VCF database"},{"location":"ss_faq/#option-1-remove-the-offending-fields","text":"This is the easiest way to fix ClinVar's VCF file. First, let's find the corrupted fields: $ java -jar SnpSift.jar vcfCheck clinvar.vcf.gz 2>&1 | grep \"INFO field\" | cut -f 2 -d \"'\" | sort | uniq -c 212 CLNHGVS 1583 CLNVI OK, there are 212 lines with corrupted CLNHGVS fields and 1583 lines with corrupted CLNVI fields. Let's create a new database without those fields $ java -jar SnpSift.jar rmInfo clinvar.vcf.gz CLNHGVS CLNVI > clinvar.fixed_1.vcf 00:00:00 Reading STDIN 00:00:03 Done # Let's also compress and index the new file so we can use it as a database $ bgzip clinvar.fixed_1.vcf $ tabix clinvar.fixed_1.vcf.gz Now we can re-check the new file to make sure it's OK. $ java -jar SnpSift.jar vcfCheck clinvar.fixed_1.vcf.gz .................................................................................................... 100000 .................................................................................................... 200000 .................................................................................................. Everything seems OK.","title":"Option 1: Remove the offending fields"},{"location":"ss_faq/#option-2-fix-the-encoding","text":"Here we need to fix the encoding of the fields. We know (see previous section) that the problematic fields are CLNVI and CLNHGVS , so what exactly are the problems? $ java -jar SnpSift.jar vcfCheck clinvar.vcf.gz 2>&1 | grep \"INFO field\" | grep CLNVI | head INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):190-16&base_change=G_to_A' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):190-12&base_change=del_TCT' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):190-5&base_change=del_T' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):190-7&base_change=T_to_C' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):195&base_change=T_to_C' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):203&base_change=G_to_A' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):203&base_change=G_to_C' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):203&base_change=G_to_T' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):214&base_change=A_to_C' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNVI' has an invalid value 'Breast_Cancer_Information_Core__(BRCA2):215&base_change=T_to_C' (no spaces, tabs, '=' or ';' are allowed) OK, this one seems easy: All we need to do is change &base_change= to &base_change%3D This can be done with a simple sed command: $ zcat clinvar.vcf.gz | sed 's/\\&base_change=/\\&base_change%3D/g' How about the other field? $ java -jar SnpSift.jar vcfCheck clinvar.vcf.gz 2>&1 | grep \"INFO field\" | grep CLNHGVS | head INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.25717365C=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.25735202G=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.25735306T=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.25735331G=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.94578548T=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.98348885G=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.100672060T=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.114377568A=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.161599571T=' (no spaces, tabs, '=' or ';' are allowed) INFO field 'CLNHGVS' has an invalid value 'NC_000001.10:g.161599643T=' (no spaces, tabs, '=' or ';' are allowed) This is essentially the same, but we need four sed commands (one for each base): $ zcat clinvar.vcf.gz \\ | sed 's/A=;/A%3D;/' \\ | sed 's/C=;/C%3D;/' \\ | sed 's/G=;/G%3D;/' \\ | sed 's/T=;/T%3D;/' The fix: Now, let's put the two previously explained fixes together: $ zcat clinvar.vcf.gz \\ | sed 's/\\&base_change=/\\&base_change%3D/g' \\ | sed 's/A=;/A%3D;/' \\ | sed 's/C=;/C%3D;/' \\ | sed 's/G=;/G%3D;/' \\ | sed 's/T=;/T%3D;/' \\ > clinvar.fixed.vcf # Let's also compress and index the new file so we can use it as a database $ bgzip clinvar.fixed.vcf $ tabix clinvar.fixed.vcf.gz We re-check the new $ java -jar SnpSift.jar vcfCheck clinvar.fixed.vcf.gz .................................................................................................... 100000 .................................................................................................... 200000 .................................................................................................. OK, we are done.","title":"Option 2: Fix the encoding"},{"location":"ss_filter/","text":"SnpSift filter SnpSift filter is one of the most useful SnpSift commands. Using SnpSift filter you can filter VCF files using arbitrary expressions, for instance \"(QUAL > 30) | (exists INDEL) | ( countHet() > 2 )\" . The actual expressions can be quite complex, so it allows for a lot of flexibility. Typical usage Some examples for the impatient: I want to filter out samples with quality less than 30: cat variants.vcf | java -jar SnpSift.jar filter \" ( QUAL >= 30 )\" > filtered.vcf ...but we also want InDels that have quality 20 or more: cat variants.vcf | java -jar SnpSift.jar filter \"(( exists INDEL ) & (QUAL >= 20)) | (QUAL >= 30 )\" > filtered.vcf ...or any homozygous variant present in more than 3 samples: cat variants.vcf | java -jar SnpSift.jar filter \"(countHom() > 3) | (( exists INDEL ) & (QUAL >= 20)) | (QUAL >= 30 )\" > filtered.vcf ...or any heterozygous sample with coverage 25 or more: cat variants.vcf | java -jar SnpSift.jar filter \"((countHet() > 0) && (DP >= 25)) | (countHom() > 3) | (( exists INDEL ) & (QUAL >= 20)) | (QUAL >= 30 )\" > filtered.vcf I want to keep samples where the genotype for the first sample is homozygous variant and the genotype for the second sample is reference: cat variants.vcf | java -jar SnpSift.jar filter \"isHom( GEN[0] ) & isVariant( GEN[0] ) & isRef( GEN[1] )\" > filtered.vcf I want to keep samples where the ID matches a set defined in a file: cat variants.vcf | java -jar SnpSift.jar filter --set my_rs.txt \"ID in SET[0]\" > filtered.vcf and the file my_rs.txt has one string per line, e.g.: rs58108140 rs71262674 rs71262673 You can combine any conditions you want using boolean operators. Command line options Usage: java -jar SnpSift.jar filter [options] 'expression' [input.vcf] Options: -a|--addFilter : Add a string to FILTER VCF field if 'expression' is true. Default: '' (none) -e|--exprFile : Read expression from a file -f|--file : VCF input file. Default: STDIN -i|--filterId : ID for this filter (##FILTER tag in header and FILTER VCF field). Default: 'SnpSift' -n|--inverse : Inverse. Show lines that do not match filter expression -p|--pass : Use 'PASS' field instead of filtering out VCF entries -r|--rmFilter : Remove a string from FILTER VCF field if 'expression' is true (and 'str' is in the field). Default: '' (none) -s|--set : Create a SET using 'file' --errMissing : Error is a field is missing. Default: false --format : SnpEff format version: {2, 3}. Default: Auto --galaxy : Used from Galaxy (expressions have been sanitized). Variables All VCF fields can be used as variables names, as long as they are declared in the VCF header OR they are \"standard\" VCF fields (as defined by the VCF 4.1 specification). Fields names: \"CHROM, POS, ID, REF, ALT, QUAL or FILTER\". Examples: Any variant in chromosome 1: \"( CHROM = 'chr1' )\" Variants between two positions: \"( POS > 123456 ) & ( POS < 654321 )\" Has an ID and it matches the regulat expression 'rs': \"(exists ID) & ( ID =~ 'rs' )\" The reference is 'A': \"( REF = 'A' )\" The alternative is 'T': \"( ALT = 'T' )\" Quality over 30: \"( QUAL > 30 )\" Filter value is either 'PASS' or it is missing: \"( na FILTER ) | (FILTER = 'PASS')\" INFO field names in the INFO field. E.g. if the info field has \"DP=48;AF1=0;...\" you can use something like: \"( DP > 10 ) & ( AF1 = 0 )\" Multiple valued fields and variables When variables have multiple values, you can access individual values as if it was an array. Multiple value info fields (comma separated) can be accessed using an index. E.g. If the INFO field has \"CI95=0.04167,0.5417\" you can use an expression such as: \"( CI95[0] > 0.1 ) & (CI95[1] <= 0.3)\" Multiple indexes You may test multiple indexed fields using 'ANY' or 'ALL' as index. In the examples we assume the INFO field has \"CI95=0.04167,0.5417\" ANY or * : If you use 'ANY' as index, the expression will be true if any field satisfies the expression. So, for instance, the following expressions: \"( CI95[ANY] > 0.1 )\" or: \"( CI95[*] > 0.1 )\" are equivalent to (in this case, there are only two values in the array): \"( CI95[0] > 0.1 ) | ( CI95[1] > 0.1 )\" ALL or ? : If you use 'ALL' as index, the expression will be true if all field satisfy the expression. So, for instance, the following expressions: \"( CI95[ALL] > 0.1 )\" \"( CI95[?] > 0.1 )\" are equivalent to (in this case, there are only two values in the array): \"( CI95[0] > 0.1 ) & ( CI95[1] > 0.1 )\" Genotype fields Vcf genotype fields can be accessed individually using array notation. Genotype fields are accessed using an index (sample number) followed by a variable name. E.g. If the genotypes are GT:PL:GQ 1/1:255,66,0:63 0/1:245,0,255:99 You can write something like: \"( GEN[0].GQ > 60 ) & ( GEN[1].GQ > 90 )\" You may use an asterisk to represent 'ANY' field: \"( GEN[*].GQ > 60 )\" Genotype multiple fields are accessed using an index (sample number) followed by a variable name and then another index. E.g. If the genotypes are GT:PL:GQ 1/1:255,66,0:63 0/1:245,0,255:99 You can write something like: \"( GEN[0].PL[2] = 0 )\" You may use an asterisk to represent 'ANY' field: \"( GEN[0].PL[*] = 0 )\" ...or even: \"( GEN[*].PL[*] = 0 )\" Info You can create an expression using sample names instead of genotype numbers. E.g. $ java -jar SnpSift.jar filter \"( GEN[HG00096].DS > 0.2 ) & ( GEN[HG00097].DS > 0.5 )\" examples/1kg.head_chr1.vcf.gz Sets Sets are defined by the '-s' (or '--set') command line option. Each file must have one string per line. They are named based on the order used in the command line (e.g. the first one is SET[0] , the second one is SET[1] , etc.) Example: You can write something like (assuming your command line was \"-s set1.txt -s set2.txt -s set3.txt\"): \"( ID in SET[2] )\" SnpEff 'ANN' fields SnpEff annotations are parsed, so you can access individual sub-fields: Effect fields (from SnpEff) are accessed using an index (effect number) followed by a sub-field name. Available ANN sub-fields are (for details, take a look at the specification ): ALLELE (alias GENOTYPE) EFFECT (alias ANNOTATION): Effect in Sequence ontology terms (e.g. 'missense_variant', 'synonymous_variant', 'stop_gained', etc.) IMPACT: { HIGH, MODERATE, LOW, MODIFIER } GENE: Gene name (e.g. 'PSD3') GENEID: Gene ID FEATURE FEATUREID (alias TRID: Transcript ID) BIOTYPE: Biotype, as described by the annotations (e.g. 'protein_coding') RANK: Exon or Intron rank (i.e. exon number in a transcript) HGVS_C (alias HGVS_DNA, CODON): Variant in HGVS (DNA) notation HGVS_P (alias HGVS, HGVS_PROT, AA): Variant in HGVS (protein) notation CDNA_POS (alias POS_CDNA) CDNA_LEN (alias LEN_CDNA) CDS_POS (alias POS_CDS) CDS_LEN (alias LEN_CDS) AA_POS (alias POS_AA) AA_LEN (alias LEN_AA) DISTANCE ERRORS (alias WARNING, INFOS) For example, you may want only the lines where the first annotation has missense_variant variant: Important According to the specification, there can be more than one EFFECT separated by & (e.g. 'missense_variant&splice_region_variant', thus using has operator is better than using equality operator ( = ). For instance 'missense_variant&splice_region_variant' = 'missense_variant' is false, whereas 'missense_variant&splice_region_variant' has 'missense_variant' is true. $ java -jar SnpSift.jar filter \"ANN[0].EFFECT has 'missense_variant'\" examples/test.chr22.ann.vcf > test.chr22.ann.filter_missense_first.vcf # Output example (edited for readability) $ cat test.chr22.ann.filter_missense_first.vcf 22 17072035 . C T . . ANN=T|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.1406G>A|p.Gly469Glu|1666/2034|1406/1674|469/557||,T|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397G>A|||||3944| 22 17072258 . C A . . ANN=A|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.1183G>T|p.Gly395Cys|1443/2034|1183/1674|395/557||,A|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397G>T|||||3721| 22 17072674 . G A . . ANN=A|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.767C>T|p.Pro256Leu|1027/2034|767/1674|256/557||,A|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397C>T|||||3305| 22 17072747 . T C . . ANN=C|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.694A>G|p.Met232Val|954/2034|694/1674|232/557||,C|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397A>G|||||3232| 22 17073043 . C T . . ANN=T|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.398G>A|p.Arg133Gln|658/2034|398/1674|133/557||,T|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397G>A|||||2936| 22 17073119 . C T . . ANN=T|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.322G>A|p.Val108Met|582/2034|322/1674|108/557||,T|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397G>A|||||2860| ...but this probably doesn't make much sense. What you may really want are lines where ANY effect to be missense_variant : $ java -jar SnpSift.jar filter \"ANN[*].EFFECT has 'missense_variant'\" examples/test.chr22.ann.vcf > test.chr22.ann.filter_missense_any.vcf # Output example (edited for readability) $ cat test.chr22.ann.filter_missense_any.vcf ... 22 24891462 . G A . . ANN=A|stop_gained|HIGH|UPB1|ENSG00000100024|transcript|ENST00000413389|protein_coding|2/10|c.59G>A|p.Trp20*|1652/3418|59/951|20/316|| ,A|missense_variant|MODERATE|UPB1|ENSG00000100024|transcript|ENST00000326010|protein_coding|1/10|c.91G>A|p.Gly31Ser|435/2290|91/1155|31/384|| ,A|missense_variant|MODERATE|UPB1|ENSG00000100024|transcript|ENST00000382760|protein_coding|1/4|c.91G>A|p.Gly31Ser|253/1928|91/561|31/186|| 22 24896158 . A T . . ANN=T|missense_variant|MODERATE|UPB1|ENSG00000100024|transcript|ENST00000326010|protein_coding|2/10|c.188A>T|p.Glu63Val|532/2290|188/1155|63/384|| ,T|missense_variant|MODERATE|UPB1|ENSG00000100024|transcript|ENST00000382760|protein_coding|2/4|c.188A>T|p.Glu63Val|350/1928|188/561|63/186|| May be you want only the ones that affect gene 'TRMT2A' : $ java -jar SnpSift.jar filter \"(ANN[*].EFFECT has 'missense_variant') && (ANN[*].GENE = 'TRMT2A')\" examples/test.chr22.ann.vcf > test.chr22.ann.filter_missense_any_TRMT2A.vcf $ cat test.chr22.ann.filter_missense_any_TRMT2A.vcf 22 20103915 . C T . . ANN=T|stop_gained|HIGH|RANBP1|ENSG00000099901|transcript|ENST00000432879|protein_coding|1/3|c.208C>T|p.Arg70*|455/744|208/497|70/164||WARNING_TRANSCRIPT_INCOMPLETE ,T|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000439169|protein_coding|2/12|c.245G>A|p.Arg82His|561/2473|245/1932|82/643|| ,T|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000252136|protein_coding|2/12|c.245G>A|p.Arg82His|634/2964|245/1878|82/625|| ,T|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000403707|protein_coding|3/13|c.245G>A|p.Arg82His|607/2928|245/1878|82/625|| ,T|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000404751|protein_coding|2/12|c.245G>A|p.Arg82His|584/2498|245/1689|82/562|| ,T|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000445045|protein_coding|2/2|c.209G>A|p.Arg70His|432/582|209/359|70/118||WARNING_TRANSCRIPT_INCOMPLETE ,... 22 20103925 . T C . . ANN=C|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000439169|protein_coding|2/12|c.235A>G|p.Asn79Asp|551/2473|235/1932|79/643|| ,C|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000252136|protein_coding|2/12|c.235A>G|p.Asn79Asp|624/2964|235/1878|79/625|| ,C|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000403707|protein_coding|3/13|c.235A>G|p.Asn79Asp|597/2928|235/1878|79/625|| ,C|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000404751|protein_coding|2/12|c.235A>G|p.Asn79Asp|574/2498|235/1689|79/562|| ,C|missense_variant|MODERATE|RANBP1|ENSG00000099901|transcript|ENST00000432879|protein_coding|1/3|c.218T>C|p.Phe73Ser|465/744|218/497|73/164||WARNING_TRANSCRIPT_INCOMPLETE ,C|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000445045|protein_coding|2/2|c.199A>G|p.Asn67Asp|422/582|199/359|67/118||WARNING_TRANSCRIPT_INCOMPLETE ,C|splice_region_variant&intron_variant|LOW|RANBP1|ENSG00000099901|transcript|ENST00000430524|protein_coding|1/5|c.-374+7T>C|||||| ,... SnpEff 'EFF' fields Warning This section documents older SnpEff/SnpSift which used 'EFF' INFO field (as opposed to 'ANN' field) or files annotated using SnpEff's -classic or -formatEff command line options. SnpEff annotations are parsed, so you can access individual sub-fields: Effect fields (from SnpEff) are accessed using an index (effect number) followed by a sub-field name. Available EFF sub-fields are: EFFECT: Effect (e.g. SYNONYMOUS_CODING, NON_SYNONYMOUS_CODING, FRAME_SHIFT, etc.) IMPACT: { HIGH, MODERATE, LOW, MODIFIER } FUNCLASS: { NONE, SILENT, MISSENSE, NONSENSE } CODON: Codon change (e.g. 'ggT/ggG') AA: Amino acid change (e.g. 'G156') GENE: Gene name (e.g. 'PSD3') BIOTYPE: Gene biotype, as described by the annotations (e.g. 'protein_coding') CODING: Gene is { CODING, NON_CODING } TRID: Transcript ID RANK: Exon or Intron rank (i.e. exon number in a transcript) For example, you may want only the lines where the first effect is a NON_SYNONYMOUS variants: \"( EFF[0].EFFECT = 'NON_SYNONYMOUS_CODING' )\" ...but this probably doesn't make much sense. What you may really want are lines where ANY effect is NON_SYNONYMOUS: \"( EFF[*].EFFECT = 'NON_SYNONYMOUS_CODING' )\" May be you want only the ones that affect gene 'TCF7L2': \"( EFF[*].EFFECT = 'NON_SYNONYMOUS_CODING' ) & ( EFF[*].GENE = 'TCF7L2' )\" SnpEff 'LOF' and 'NMD' fields Similarly LOF and NMD sub-fields are available: LOF.GENE and NMD.GENE LOF.GENEID and NMD.GENEID LOF.NUMTR and NMD.NUMTR LOF.PERC and NMD.PERC For instance, if we want to obtain genes having a Loss of Function effect in more than 90% of the transcripts, you can do this: $cat test.snpeff.vcf | java -Xmx1G -jar SnpSift.jar filter \"(exists LOF[*].PERC) & (LOF[*].PERC > 0.9)\" Warning We assume that 'test.snpeff.vcf' was annotated with SnpEff using '-lof' command line option. Available operands and functions The following operators and functions are interpreted by SnpSift filter : Operand Description Data type Example = Equality test FLOAT, INT or STRING (REF = 'A') > Greater than FLOAT or INT (DP > 20) \u2265 Greater or equal than FLOAT or INT (DP \u2265 20) < Less than FLOAT or INT (DP < 20) \u2264 Less or equal than FLOAT or INT (DP \u2264 20) =~ Match regular expression STRING (REL =~ 'AC') !~ Does not match regular expression STRING (REL !~ 'AC') & AND operator Boolean (DP > 20) & (REF = 'A') | OR operator Boolean (DP > 20) | (REF = 'A') ! NOT operator Boolean ! (DP > 20) exists The variable exists (not missing) Any ( exists INDEL) has The right hand side expression is equalt to any of the items in a list consisting of separating the left hand side expression using delimiters: & , + , ; , , , : , (', ') , [', '] . Example: If the expression is: ANN[*].EFFECT has 'missense_variant'. If left hand side (ANN[*].EFFECT) has value 'missense_variant&splice_region_variant', then it is transformed to a list: ['missense_variant', 'splice_region_variant'] Since the right hand side ('missense_variant') is in the list, the expression evaluates to 'true' Any (ANN[*].EFFECT has 'missense_variant') Function Description Data type Example countHom() Count number of homozygous genotypes No arguments ( countHom() > 0) countHet() Count number of heterozygous genotypes No arguments ( countHet() > 2) countVariant() Count number of genotypes that are variants (i.e. not reference 0/0) No arguments ( countVariant() > 5) countRef() Count number of genotypes that are NOT variants (i.e. reference 0/0) No arguments ( countRef() < 1) Genotype Function Description Data type Example isHom Is homozygous genotype? Genotype isHom( GEN[0] ) isHet Is heterozygous genotype? Genotype isHet( GEN[0] ) isVariant Is genotype a variant? (i.e. not reference 0/0) Genotype isVariant( GEN[0] ) isRef Is genotype a reference? (i.e. 0/0) Genotype isRef( GEN[0] ) Using sample names instead of sample numbers As of version 4.1A, SnpSift allows to use sample names instead of sample numbers. This allows to create more readable expressions. Example: $ cat cancer.vcf | java -jar SnpSift.jar filter \"GEN[Somatic].GT = '2/1'\" #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Germline Somatic 1 69091 . A C,G . PASS AC=1 GT 1/0 2/1 Note that we used GEN[Somatic] instead of GEN[1] .","title":"SnpSift Filter"},{"location":"ss_filter/#snpsift-filter","text":"SnpSift filter is one of the most useful SnpSift commands. Using SnpSift filter you can filter VCF files using arbitrary expressions, for instance \"(QUAL > 30) | (exists INDEL) | ( countHet() > 2 )\" . The actual expressions can be quite complex, so it allows for a lot of flexibility.","title":"SnpSift filter"},{"location":"ss_filter/#typical-usage","text":"Some examples for the impatient: I want to filter out samples with quality less than 30: cat variants.vcf | java -jar SnpSift.jar filter \" ( QUAL >= 30 )\" > filtered.vcf ...but we also want InDels that have quality 20 or more: cat variants.vcf | java -jar SnpSift.jar filter \"(( exists INDEL ) & (QUAL >= 20)) | (QUAL >= 30 )\" > filtered.vcf ...or any homozygous variant present in more than 3 samples: cat variants.vcf | java -jar SnpSift.jar filter \"(countHom() > 3) | (( exists INDEL ) & (QUAL >= 20)) | (QUAL >= 30 )\" > filtered.vcf ...or any heterozygous sample with coverage 25 or more: cat variants.vcf | java -jar SnpSift.jar filter \"((countHet() > 0) && (DP >= 25)) | (countHom() > 3) | (( exists INDEL ) & (QUAL >= 20)) | (QUAL >= 30 )\" > filtered.vcf I want to keep samples where the genotype for the first sample is homozygous variant and the genotype for the second sample is reference: cat variants.vcf | java -jar SnpSift.jar filter \"isHom( GEN[0] ) & isVariant( GEN[0] ) & isRef( GEN[1] )\" > filtered.vcf I want to keep samples where the ID matches a set defined in a file: cat variants.vcf | java -jar SnpSift.jar filter --set my_rs.txt \"ID in SET[0]\" > filtered.vcf and the file my_rs.txt has one string per line, e.g.: rs58108140 rs71262674 rs71262673 You can combine any conditions you want using boolean operators.","title":"Typical usage"},{"location":"ss_filter/#command-line-options","text":"Usage: java -jar SnpSift.jar filter [options] 'expression' [input.vcf] Options: -a|--addFilter : Add a string to FILTER VCF field if 'expression' is true. Default: '' (none) -e|--exprFile : Read expression from a file -f|--file : VCF input file. Default: STDIN -i|--filterId : ID for this filter (##FILTER tag in header and FILTER VCF field). Default: 'SnpSift' -n|--inverse : Inverse. Show lines that do not match filter expression -p|--pass : Use 'PASS' field instead of filtering out VCF entries -r|--rmFilter : Remove a string from FILTER VCF field if 'expression' is true (and 'str' is in the field). Default: '' (none) -s|--set : Create a SET using 'file' --errMissing : Error is a field is missing. Default: false --format : SnpEff format version: {2, 3}. Default: Auto --galaxy : Used from Galaxy (expressions have been sanitized).","title":"Command line options"},{"location":"ss_filter/#variables","text":"All VCF fields can be used as variables names, as long as they are declared in the VCF header OR they are \"standard\" VCF fields (as defined by the VCF 4.1 specification). Fields names: \"CHROM, POS, ID, REF, ALT, QUAL or FILTER\". Examples: Any variant in chromosome 1: \"( CHROM = 'chr1' )\" Variants between two positions: \"( POS > 123456 ) & ( POS < 654321 )\" Has an ID and it matches the regulat expression 'rs': \"(exists ID) & ( ID =~ 'rs' )\" The reference is 'A': \"( REF = 'A' )\" The alternative is 'T': \"( ALT = 'T' )\" Quality over 30: \"( QUAL > 30 )\" Filter value is either 'PASS' or it is missing: \"( na FILTER ) | (FILTER = 'PASS')\" INFO field names in the INFO field. E.g. if the info field has \"DP=48;AF1=0;...\" you can use something like: \"( DP > 10 ) & ( AF1 = 0 )\"","title":"Variables"},{"location":"ss_filter/#multiple-valued-fields-and-variables","text":"When variables have multiple values, you can access individual values as if it was an array. Multiple value info fields (comma separated) can be accessed using an index. E.g. If the INFO field has \"CI95=0.04167,0.5417\" you can use an expression such as: \"( CI95[0] > 0.1 ) & (CI95[1] <= 0.3)\" Multiple indexes You may test multiple indexed fields using 'ANY' or 'ALL' as index. In the examples we assume the INFO field has \"CI95=0.04167,0.5417\" ANY or * : If you use 'ANY' as index, the expression will be true if any field satisfies the expression. So, for instance, the following expressions: \"( CI95[ANY] > 0.1 )\" or: \"( CI95[*] > 0.1 )\" are equivalent to (in this case, there are only two values in the array): \"( CI95[0] > 0.1 ) | ( CI95[1] > 0.1 )\" ALL or ? : If you use 'ALL' as index, the expression will be true if all field satisfy the expression. So, for instance, the following expressions: \"( CI95[ALL] > 0.1 )\" \"( CI95[?] > 0.1 )\" are equivalent to (in this case, there are only two values in the array): \"( CI95[0] > 0.1 ) & ( CI95[1] > 0.1 )\"","title":"Multiple valued fields and variables"},{"location":"ss_filter/#genotype-fields","text":"Vcf genotype fields can be accessed individually using array notation. Genotype fields are accessed using an index (sample number) followed by a variable name. E.g. If the genotypes are GT:PL:GQ 1/1:255,66,0:63 0/1:245,0,255:99 You can write something like: \"( GEN[0].GQ > 60 ) & ( GEN[1].GQ > 90 )\" You may use an asterisk to represent 'ANY' field: \"( GEN[*].GQ > 60 )\" Genotype multiple fields are accessed using an index (sample number) followed by a variable name and then another index. E.g. If the genotypes are GT:PL:GQ 1/1:255,66,0:63 0/1:245,0,255:99 You can write something like: \"( GEN[0].PL[2] = 0 )\" You may use an asterisk to represent 'ANY' field: \"( GEN[0].PL[*] = 0 )\" ...or even: \"( GEN[*].PL[*] = 0 )\" Info You can create an expression using sample names instead of genotype numbers. E.g. $ java -jar SnpSift.jar filter \"( GEN[HG00096].DS > 0.2 ) & ( GEN[HG00097].DS > 0.5 )\" examples/1kg.head_chr1.vcf.gz","title":"Genotype fields"},{"location":"ss_filter/#sets","text":"Sets are defined by the '-s' (or '--set') command line option. Each file must have one string per line. They are named based on the order used in the command line (e.g. the first one is SET[0] , the second one is SET[1] , etc.) Example: You can write something like (assuming your command line was \"-s set1.txt -s set2.txt -s set3.txt\"): \"( ID in SET[2] )\"","title":"Sets"},{"location":"ss_filter/#snpeff-ann-fields","text":"SnpEff annotations are parsed, so you can access individual sub-fields: Effect fields (from SnpEff) are accessed using an index (effect number) followed by a sub-field name. Available ANN sub-fields are (for details, take a look at the specification ): ALLELE (alias GENOTYPE) EFFECT (alias ANNOTATION): Effect in Sequence ontology terms (e.g. 'missense_variant', 'synonymous_variant', 'stop_gained', etc.) IMPACT: { HIGH, MODERATE, LOW, MODIFIER } GENE: Gene name (e.g. 'PSD3') GENEID: Gene ID FEATURE FEATUREID (alias TRID: Transcript ID) BIOTYPE: Biotype, as described by the annotations (e.g. 'protein_coding') RANK: Exon or Intron rank (i.e. exon number in a transcript) HGVS_C (alias HGVS_DNA, CODON): Variant in HGVS (DNA) notation HGVS_P (alias HGVS, HGVS_PROT, AA): Variant in HGVS (protein) notation CDNA_POS (alias POS_CDNA) CDNA_LEN (alias LEN_CDNA) CDS_POS (alias POS_CDS) CDS_LEN (alias LEN_CDS) AA_POS (alias POS_AA) AA_LEN (alias LEN_AA) DISTANCE ERRORS (alias WARNING, INFOS) For example, you may want only the lines where the first annotation has missense_variant variant: Important According to the specification, there can be more than one EFFECT separated by & (e.g. 'missense_variant&splice_region_variant', thus using has operator is better than using equality operator ( = ). For instance 'missense_variant&splice_region_variant' = 'missense_variant' is false, whereas 'missense_variant&splice_region_variant' has 'missense_variant' is true. $ java -jar SnpSift.jar filter \"ANN[0].EFFECT has 'missense_variant'\" examples/test.chr22.ann.vcf > test.chr22.ann.filter_missense_first.vcf # Output example (edited for readability) $ cat test.chr22.ann.filter_missense_first.vcf 22 17072035 . C T . . ANN=T|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.1406G>A|p.Gly469Glu|1666/2034|1406/1674|469/557||,T|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397G>A|||||3944| 22 17072258 . C A . . ANN=A|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.1183G>T|p.Gly395Cys|1443/2034|1183/1674|395/557||,A|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397G>T|||||3721| 22 17072674 . G A . . ANN=A|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.767C>T|p.Pro256Leu|1027/2034|767/1674|256/557||,A|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397C>T|||||3305| 22 17072747 . T C . . ANN=C|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.694A>G|p.Met232Val|954/2034|694/1674|232/557||,C|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397A>G|||||3232| 22 17073043 . C T . . ANN=T|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.398G>A|p.Arg133Gln|658/2034|398/1674|133/557||,T|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397G>A|||||2936| 22 17073119 . C T . . ANN=T|missense_variant|MODERATE|CCT8L2|ENSG00000198445|transcript|ENST00000359963|protein_coding|1/1|c.322G>A|p.Val108Met|582/2034|322/1674|108/557||,T|downstream_gene_variant|MODIFIER|FABP5P11|ENSG00000240122|transcript|ENST00000430910|processed_pseudogene||n.*397G>A|||||2860| ...but this probably doesn't make much sense. What you may really want are lines where ANY effect to be missense_variant : $ java -jar SnpSift.jar filter \"ANN[*].EFFECT has 'missense_variant'\" examples/test.chr22.ann.vcf > test.chr22.ann.filter_missense_any.vcf # Output example (edited for readability) $ cat test.chr22.ann.filter_missense_any.vcf ... 22 24891462 . G A . . ANN=A|stop_gained|HIGH|UPB1|ENSG00000100024|transcript|ENST00000413389|protein_coding|2/10|c.59G>A|p.Trp20*|1652/3418|59/951|20/316|| ,A|missense_variant|MODERATE|UPB1|ENSG00000100024|transcript|ENST00000326010|protein_coding|1/10|c.91G>A|p.Gly31Ser|435/2290|91/1155|31/384|| ,A|missense_variant|MODERATE|UPB1|ENSG00000100024|transcript|ENST00000382760|protein_coding|1/4|c.91G>A|p.Gly31Ser|253/1928|91/561|31/186|| 22 24896158 . A T . . ANN=T|missense_variant|MODERATE|UPB1|ENSG00000100024|transcript|ENST00000326010|protein_coding|2/10|c.188A>T|p.Glu63Val|532/2290|188/1155|63/384|| ,T|missense_variant|MODERATE|UPB1|ENSG00000100024|transcript|ENST00000382760|protein_coding|2/4|c.188A>T|p.Glu63Val|350/1928|188/561|63/186|| May be you want only the ones that affect gene 'TRMT2A' : $ java -jar SnpSift.jar filter \"(ANN[*].EFFECT has 'missense_variant') && (ANN[*].GENE = 'TRMT2A')\" examples/test.chr22.ann.vcf > test.chr22.ann.filter_missense_any_TRMT2A.vcf $ cat test.chr22.ann.filter_missense_any_TRMT2A.vcf 22 20103915 . C T . . ANN=T|stop_gained|HIGH|RANBP1|ENSG00000099901|transcript|ENST00000432879|protein_coding|1/3|c.208C>T|p.Arg70*|455/744|208/497|70/164||WARNING_TRANSCRIPT_INCOMPLETE ,T|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000439169|protein_coding|2/12|c.245G>A|p.Arg82His|561/2473|245/1932|82/643|| ,T|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000252136|protein_coding|2/12|c.245G>A|p.Arg82His|634/2964|245/1878|82/625|| ,T|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000403707|protein_coding|3/13|c.245G>A|p.Arg82His|607/2928|245/1878|82/625|| ,T|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000404751|protein_coding|2/12|c.245G>A|p.Arg82His|584/2498|245/1689|82/562|| ,T|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000445045|protein_coding|2/2|c.209G>A|p.Arg70His|432/582|209/359|70/118||WARNING_TRANSCRIPT_INCOMPLETE ,... 22 20103925 . T C . . ANN=C|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000439169|protein_coding|2/12|c.235A>G|p.Asn79Asp|551/2473|235/1932|79/643|| ,C|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000252136|protein_coding|2/12|c.235A>G|p.Asn79Asp|624/2964|235/1878|79/625|| ,C|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000403707|protein_coding|3/13|c.235A>G|p.Asn79Asp|597/2928|235/1878|79/625|| ,C|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000404751|protein_coding|2/12|c.235A>G|p.Asn79Asp|574/2498|235/1689|79/562|| ,C|missense_variant|MODERATE|RANBP1|ENSG00000099901|transcript|ENST00000432879|protein_coding|1/3|c.218T>C|p.Phe73Ser|465/744|218/497|73/164||WARNING_TRANSCRIPT_INCOMPLETE ,C|missense_variant|MODERATE|TRMT2A|ENSG00000099899|transcript|ENST00000445045|protein_coding|2/2|c.199A>G|p.Asn67Asp|422/582|199/359|67/118||WARNING_TRANSCRIPT_INCOMPLETE ,C|splice_region_variant&intron_variant|LOW|RANBP1|ENSG00000099901|transcript|ENST00000430524|protein_coding|1/5|c.-374+7T>C|||||| ,...","title":"SnpEff 'ANN' fields"},{"location":"ss_filter/#snpeff-eff-fields","text":"Warning This section documents older SnpEff/SnpSift which used 'EFF' INFO field (as opposed to 'ANN' field) or files annotated using SnpEff's -classic or -formatEff command line options. SnpEff annotations are parsed, so you can access individual sub-fields: Effect fields (from SnpEff) are accessed using an index (effect number) followed by a sub-field name. Available EFF sub-fields are: EFFECT: Effect (e.g. SYNONYMOUS_CODING, NON_SYNONYMOUS_CODING, FRAME_SHIFT, etc.) IMPACT: { HIGH, MODERATE, LOW, MODIFIER } FUNCLASS: { NONE, SILENT, MISSENSE, NONSENSE } CODON: Codon change (e.g. 'ggT/ggG') AA: Amino acid change (e.g. 'G156') GENE: Gene name (e.g. 'PSD3') BIOTYPE: Gene biotype, as described by the annotations (e.g. 'protein_coding') CODING: Gene is { CODING, NON_CODING } TRID: Transcript ID RANK: Exon or Intron rank (i.e. exon number in a transcript) For example, you may want only the lines where the first effect is a NON_SYNONYMOUS variants: \"( EFF[0].EFFECT = 'NON_SYNONYMOUS_CODING' )\" ...but this probably doesn't make much sense. What you may really want are lines where ANY effect is NON_SYNONYMOUS: \"( EFF[*].EFFECT = 'NON_SYNONYMOUS_CODING' )\" May be you want only the ones that affect gene 'TCF7L2': \"( EFF[*].EFFECT = 'NON_SYNONYMOUS_CODING' ) & ( EFF[*].GENE = 'TCF7L2' )\"","title":"SnpEff 'EFF' fields"},{"location":"ss_filter/#snpeff-lof-and-nmd-fields","text":"Similarly LOF and NMD sub-fields are available: LOF.GENE and NMD.GENE LOF.GENEID and NMD.GENEID LOF.NUMTR and NMD.NUMTR LOF.PERC and NMD.PERC For instance, if we want to obtain genes having a Loss of Function effect in more than 90% of the transcripts, you can do this: $cat test.snpeff.vcf | java -Xmx1G -jar SnpSift.jar filter \"(exists LOF[*].PERC) & (LOF[*].PERC > 0.9)\" Warning We assume that 'test.snpeff.vcf' was annotated with SnpEff using '-lof' command line option.","title":"SnpEff 'LOF' and 'NMD' fields"},{"location":"ss_filter/#available-operands-and-functions","text":"The following operators and functions are interpreted by SnpSift filter : Operand Description Data type Example = Equality test FLOAT, INT or STRING (REF = 'A') > Greater than FLOAT or INT (DP > 20) \u2265 Greater or equal than FLOAT or INT (DP \u2265 20) < Less than FLOAT or INT (DP < 20) \u2264 Less or equal than FLOAT or INT (DP \u2264 20) =~ Match regular expression STRING (REL =~ 'AC') !~ Does not match regular expression STRING (REL !~ 'AC') & AND operator Boolean (DP > 20) & (REF = 'A') | OR operator Boolean (DP > 20) | (REF = 'A') ! NOT operator Boolean ! (DP > 20) exists The variable exists (not missing) Any ( exists INDEL) has The right hand side expression is equalt to any of the items in a list consisting of separating the left hand side expression using delimiters: & , + , ; , , , : , (', ') , [', '] . Example: If the expression is: ANN[*].EFFECT has 'missense_variant'. If left hand side (ANN[*].EFFECT) has value 'missense_variant&splice_region_variant', then it is transformed to a list: ['missense_variant', 'splice_region_variant'] Since the right hand side ('missense_variant') is in the list, the expression evaluates to 'true' Any (ANN[*].EFFECT has 'missense_variant') Function Description Data type Example countHom() Count number of homozygous genotypes No arguments ( countHom() > 0) countHet() Count number of heterozygous genotypes No arguments ( countHet() > 2) countVariant() Count number of genotypes that are variants (i.e. not reference 0/0) No arguments ( countVariant() > 5) countRef() Count number of genotypes that are NOT variants (i.e. reference 0/0) No arguments ( countRef() < 1) Genotype Function Description Data type Example isHom Is homozygous genotype? Genotype isHom( GEN[0] ) isHet Is heterozygous genotype? Genotype isHet( GEN[0] ) isVariant Is genotype a variant? (i.e. not reference 0/0) Genotype isVariant( GEN[0] ) isRef Is genotype a reference? (i.e. 0/0) Genotype isRef( GEN[0] )","title":"Available operands and functions"},{"location":"ss_filter/#using-sample-names-instead-of-sample-numbers","text":"As of version 4.1A, SnpSift allows to use sample names instead of sample numbers. This allows to create more readable expressions. Example: $ cat cancer.vcf | java -jar SnpSift.jar filter \"GEN[Somatic].GT = '2/1'\" #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Germline Somatic 1 69091 . A C,G . PASS AC=1 GT 1/0 2/1 Note that we used GEN[Somatic] instead of GEN[1] .","title":"Using sample names instead of sample numbers"},{"location":"ss_genesets/","text":"SnpSift GeneSets Annotating GeneSets, such as Gene Ontology (GO), KEGG, Reactome, etc.; can be quite useful to find significant variants. Gene set annotations can be added to a SnpEff annotated file using SnpSift geneSets command. The VCF file must be annotated using SnpEff before performing Gene Sets annotations. This is because we must know which gene the variant affects). Info You can download MSigDb from Broad Institute Usage example: $ java -jar SnpSift.jar geneSets -v db/msigDb/msigdb.v3.1.symbols.gmt test.ann.vcf > test.eff.geneSets.vcf 00:00:00.000 Reading MSigDb from file: 'db/msigDb/msigdb.v3.1.symbols.gmt' 00:00:01.168 Done. Total: 8513 gene sets 31847 genes 00:00:01.168 Annotating variants from: 'test.ann.vcf' 00:00:01.298 Done. # Summary # gene_set gene_set_size variants # ACEVEDO_METHYLATED_IN_LIVER_CANCER_DN 940 8 # CHR1P36 504 281 # KEGG_OLFACTORY_TRANSDUCTION 389 8 # REACTOME_GPCR_DOWNSTREAM_SIGNALING 805 8 # REACTOME_OLFACTORY_SIGNALING_PATHWAY 328 8 ... # REACTOME_SIGNALING_BY_GPCR 920 8 $ cat test.eff.geneSets.vcf ## INFO=<ID=MSigDb,Number=.,Type=String,Description=\"Gene set from MSigDB database (GSEA)\"> 1 69849 . G A 454.73 PASS AC=33;EFF=STOP_GAINED(HIGH|NONSENSE|tgG/tgA|W253*|305|OR4F5|protein_coding|CODING|ENST00000335137|1|1);MSigDb=ACEVEDO_METHYLATED_IN_LIVER_CANCER_DN,CHR1P36,KEGG_OLFACTORY_TRANSDUCTION,REACTOME_GPCR_DOWNSTREAM_SIGNALING,REACTOME_OLFACTORY_SIGNALING_PATHWAY,REACTOME_SIGNALING_BY_GPCR","title":"SnpSift GeneSets"},{"location":"ss_genesets/#snpsift-genesets","text":"Annotating GeneSets, such as Gene Ontology (GO), KEGG, Reactome, etc.; can be quite useful to find significant variants. Gene set annotations can be added to a SnpEff annotated file using SnpSift geneSets command. The VCF file must be annotated using SnpEff before performing Gene Sets annotations. This is because we must know which gene the variant affects). Info You can download MSigDb from Broad Institute Usage example: $ java -jar SnpSift.jar geneSets -v db/msigDb/msigdb.v3.1.symbols.gmt test.ann.vcf > test.eff.geneSets.vcf 00:00:00.000 Reading MSigDb from file: 'db/msigDb/msigdb.v3.1.symbols.gmt' 00:00:01.168 Done. Total: 8513 gene sets 31847 genes 00:00:01.168 Annotating variants from: 'test.ann.vcf' 00:00:01.298 Done. # Summary # gene_set gene_set_size variants # ACEVEDO_METHYLATED_IN_LIVER_CANCER_DN 940 8 # CHR1P36 504 281 # KEGG_OLFACTORY_TRANSDUCTION 389 8 # REACTOME_GPCR_DOWNSTREAM_SIGNALING 805 8 # REACTOME_OLFACTORY_SIGNALING_PATHWAY 328 8 ... # REACTOME_SIGNALING_BY_GPCR 920 8 $ cat test.eff.geneSets.vcf ## INFO=<ID=MSigDb,Number=.,Type=String,Description=\"Gene set from MSigDB database (GSEA)\"> 1 69849 . G A 454.73 PASS AC=33;EFF=STOP_GAINED(HIGH|NONSENSE|tgG/tgA|W253*|305|OR4F5|protein_coding|CODING|ENST00000335137|1|1);MSigDb=ACEVEDO_METHYLATED_IN_LIVER_CANCER_DN,CHR1P36,KEGG_OLFACTORY_TRANSDUCTION,REACTOME_GPCR_DOWNSTREAM_SIGNALING,REACTOME_OLFACTORY_SIGNALING_PATHWAY,REACTOME_SIGNALING_BY_GPCR","title":"SnpSift GeneSets"},{"location":"ss_gt/","text":"SnpSift GT Compress genotype calls, reducing the overall size of the VCF file. This is intended for compressing very large VCF in very large sequencing projects (e.g. thousands of samples). Info For instance, we've reduced 1Tb (1,000 Gb) VCF file to roughly 1Gb in a project that has over 10,000 samples. The underlying idea is quite simple. In large re-sequencing projects most of the variants are singletons. This means that most variants are present in only one of the samples. For those variants, you have thousands of samples that are homozygous reference (i.e. genotype entry is \"0/0\") and one that is a variant (e.g. '0/1' or '1/1'). A trivial way to compress these VCF entries is just to state which sample has non-reference information. Intuitively, this is similar to the way used to represent sparse matrices (only store non-zero elements). SnpSift gt creates three INFO fields. These three files are composed of comma separated indexes of samples having: HE: Indicated heterozygous variants (i.e. '0/1'). HO: Indicated homozygous variants (i.e. '1/1'). NA: Indicated missing genotype data (i.e. './.'). You can use -u command line option to uncompress. E.g.: $ cat test.vcf #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Sample_1 Sample_2 Sample_3 Sample_4 Sample_5 Sample_6 Sample_7 Sample_8 Sample_9 Sample_10 Sample_11 Sample_12 Sample_13 Sample_14 Sample_15 1 861276 . A G . PASS AC=1 GT 0/0 1/1 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 #--- # Compress genotypes #--- $ java -jar SnpSift.jar gt test.vcf | tee test.gt.vcf ##INFO=<ID=HO,Number=.,Type=Integer,Description=\"List of sample indexes having homozygous ALT genotypes\"> ##INFO=<ID=HE,Number=.,Type=Integer,Description=\"List of sample indexes having heterozygous ALT genotypes\"> ##INFO=<ID=NA,Number=.,Type=Integer,Description=\"List of sample indexes having missing genotypes\"> #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Sample_1 Sample_2 Sample_3 Sample_4 Sample_5 Sample_6 Sample_7 Sample_8 Sample_9 Sample_10 Sample_11 Sample_12 Sample_13 Sample_14 Sample_15 1 861276 . A G . PASS AC=1;HO=1 #--- # Uncompress genotypes (command line option '-u') #--- $ java -jar SnpSift.jar gt -u test.gt.vcf #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Sample_1 Sample_2 Sample_3 Sample_4 Sample_5 Sample_6 Sample_7 Sample_8 Sample_9 Sample_10 Sample_11 Sample_12 Sample_13 Sample_14 Sample_15 1 861276 . A G . PASS AC=1 GT 0/0 1/1 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 Warning This is lossy compression. Note that only GT informations is compressed, all other information in genotype field is lost.","title":"SnpSift GT"},{"location":"ss_gt/#snpsift-gt","text":"Compress genotype calls, reducing the overall size of the VCF file. This is intended for compressing very large VCF in very large sequencing projects (e.g. thousands of samples). Info For instance, we've reduced 1Tb (1,000 Gb) VCF file to roughly 1Gb in a project that has over 10,000 samples. The underlying idea is quite simple. In large re-sequencing projects most of the variants are singletons. This means that most variants are present in only one of the samples. For those variants, you have thousands of samples that are homozygous reference (i.e. genotype entry is \"0/0\") and one that is a variant (e.g. '0/1' or '1/1'). A trivial way to compress these VCF entries is just to state which sample has non-reference information. Intuitively, this is similar to the way used to represent sparse matrices (only store non-zero elements). SnpSift gt creates three INFO fields. These three files are composed of comma separated indexes of samples having: HE: Indicated heterozygous variants (i.e. '0/1'). HO: Indicated homozygous variants (i.e. '1/1'). NA: Indicated missing genotype data (i.e. './.'). You can use -u command line option to uncompress. E.g.: $ cat test.vcf #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Sample_1 Sample_2 Sample_3 Sample_4 Sample_5 Sample_6 Sample_7 Sample_8 Sample_9 Sample_10 Sample_11 Sample_12 Sample_13 Sample_14 Sample_15 1 861276 . A G . PASS AC=1 GT 0/0 1/1 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 #--- # Compress genotypes #--- $ java -jar SnpSift.jar gt test.vcf | tee test.gt.vcf ##INFO=<ID=HO,Number=.,Type=Integer,Description=\"List of sample indexes having homozygous ALT genotypes\"> ##INFO=<ID=HE,Number=.,Type=Integer,Description=\"List of sample indexes having heterozygous ALT genotypes\"> ##INFO=<ID=NA,Number=.,Type=Integer,Description=\"List of sample indexes having missing genotypes\"> #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Sample_1 Sample_2 Sample_3 Sample_4 Sample_5 Sample_6 Sample_7 Sample_8 Sample_9 Sample_10 Sample_11 Sample_12 Sample_13 Sample_14 Sample_15 1 861276 . A G . PASS AC=1;HO=1 #--- # Uncompress genotypes (command line option '-u') #--- $ java -jar SnpSift.jar gt -u test.gt.vcf #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Sample_1 Sample_2 Sample_3 Sample_4 Sample_5 Sample_6 Sample_7 Sample_8 Sample_9 Sample_10 Sample_11 Sample_12 Sample_13 Sample_14 Sample_15 1 861276 . A G . PASS AC=1 GT 0/0 1/1 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 Warning This is lossy compression. Note that only GT informations is compressed, all other information in genotype field is lost.","title":"SnpSift GT"},{"location":"ss_gwascatalog/","text":"SnpSift GWAS Catalog Annotate using GWAS catalog . You need the GWAS catalog file (in TXT format), which can be downloaded here . $ java -jar SnpSift.jar gwasCat gwascatalog.txt test.vcf | tee test.gwas.vcf 1 1005806 rs3934834 C T . PASS AF=0.091;GWASCAT=Body_mass_index 1 2069172 rs425277 C T . PASS AF=0.400;GWASCAT=Height 1 2069681 rs3753242 C T . PASS AF=0.211;GWASCAT=Reasoning 1 2392648 rs2477686 G C . PASS AF=0.745;GWASCAT=Non_obstructive_azoospermia 1 2513216 rs734999 C T . PASS AF=0.547;GWASCAT=Ulcerative_colitis 1 2526746 rs3748816 A G . PASS AF=0.489;GWASCAT=Celiac_disease 1 3083712 rs2651899 T C . PASS AF=0.467;GWASCAT=Migraine 1 3280253 rs6658356 G A . PASS AF=0.070;GWASCAT=Response_to_statin_therapy 1 4315204 rs966321 G T . PASS AF=0.522;GWASCAT=Factor_VII 1 5170712 rs7513590 A G . PASS AF=0.256;GWASCAT=Anthropometric_traits 1 6279370 rs846111 G C . PASS AF=0.153;GWASCAT=QT_interval,QT_interval 1 6631431 rs11587438 C T . PASS AF=0.906;GWASCAT=White_blood_cell_types 1 7879063 rs2797685 C T . PASS AF=0.186;GWASCAT=Crohn_s_disease 1 8021973 rs35675666 G T . PASS AF=0.093;GWASCAT=Ulcerative_colitis 1 8046672 rs12727642 C A . PASS AF=0.101;GWASCAT=Celiac_disease 1 8422676 rs2252865 T C . PASS AF=0.771;GWASCAT=Schizophrenia 1 8526142 rs4908760 G A . PASS AF=0.630;GWASCAT=Vitiligo","title":"SnpSift GWAS Catalog"},{"location":"ss_gwascatalog/#snpsift-gwas-catalog","text":"Annotate using GWAS catalog . You need the GWAS catalog file (in TXT format), which can be downloaded here . $ java -jar SnpSift.jar gwasCat gwascatalog.txt test.vcf | tee test.gwas.vcf 1 1005806 rs3934834 C T . PASS AF=0.091;GWASCAT=Body_mass_index 1 2069172 rs425277 C T . PASS AF=0.400;GWASCAT=Height 1 2069681 rs3753242 C T . PASS AF=0.211;GWASCAT=Reasoning 1 2392648 rs2477686 G C . PASS AF=0.745;GWASCAT=Non_obstructive_azoospermia 1 2513216 rs734999 C T . PASS AF=0.547;GWASCAT=Ulcerative_colitis 1 2526746 rs3748816 A G . PASS AF=0.489;GWASCAT=Celiac_disease 1 3083712 rs2651899 T C . PASS AF=0.467;GWASCAT=Migraine 1 3280253 rs6658356 G A . PASS AF=0.070;GWASCAT=Response_to_statin_therapy 1 4315204 rs966321 G T . PASS AF=0.522;GWASCAT=Factor_VII 1 5170712 rs7513590 A G . PASS AF=0.256;GWASCAT=Anthropometric_traits 1 6279370 rs846111 G C . PASS AF=0.153;GWASCAT=QT_interval,QT_interval 1 6631431 rs11587438 C T . PASS AF=0.906;GWASCAT=White_blood_cell_types 1 7879063 rs2797685 C T . PASS AF=0.186;GWASCAT=Crohn_s_disease 1 8021973 rs35675666 G T . PASS AF=0.093;GWASCAT=Ulcerative_colitis 1 8046672 rs12727642 C A . PASS AF=0.101;GWASCAT=Celiac_disease 1 8422676 rs2252865 T C . PASS AF=0.771;GWASCAT=Schizophrenia 1 8526142 rs4908760 G A . PASS AF=0.630;GWASCAT=Vitiligo","title":"SnpSift GWAS Catalog"},{"location":"ss_intersect/","text":"SnpSift Intersect This command intersects several intervals files (e.g. BED, BigBed, TXT) and produces a result of all intersections. A typical usage example is to create a consensus of peaks from several Chip-Seq experiments. Algorithm: This command creates one interval forest for each input file. For every interval in all input files, finds all intervals that intersect at least minOverlap bases (default 1 base). If there are at least cluster number of intersecting intervals it creates a consensus interval from the intersections (or union ) of all intervals found. The consensus interval, if any, is shown as result. Command line options: $ java -jar SnpSift.jar intersect SnpSift version 1.9d (build 2013-04-26), by Pablo Cingolani Usage: java -jar SnpSift.jar [options] file_1.bed file_2.bed ... file_N.bed Options: -minOverlap <num> : Minimum number of bases that two intervals have to overlap. Default : 0 -cluster <num> : An interval has to intersect at least 'num' intervals (from other files) to be considered. Default: 0 -intersect : Report the intersection of all intervals. Default: false -union : Report the union of all intervals. Default: true","title":"SnpSift Intersect"},{"location":"ss_intersect/#snpsift-intersect","text":"This command intersects several intervals files (e.g. BED, BigBed, TXT) and produces a result of all intersections. A typical usage example is to create a consensus of peaks from several Chip-Seq experiments. Algorithm: This command creates one interval forest for each input file. For every interval in all input files, finds all intervals that intersect at least minOverlap bases (default 1 base). If there are at least cluster number of intersecting intervals it creates a consensus interval from the intersections (or union ) of all intervals found. The consensus interval, if any, is shown as result. Command line options: $ java -jar SnpSift.jar intersect SnpSift version 1.9d (build 2013-04-26), by Pablo Cingolani Usage: java -jar SnpSift.jar [options] file_1.bed file_2.bed ... file_N.bed Options: -minOverlap <num> : Minimum number of bases that two intervals have to overlap. Default : 0 -cluster <num> : An interval has to intersect at least 'num' intervals (from other files) to be considered. Default: 0 -intersect : Report the intersection of all intervals. Default: false -union : Report the union of all intervals. Default: true","title":"SnpSift Intersect"},{"location":"ss_intervals/","text":"SnpSift Intervals This is used to extract variants that intersect any interval. You must provide intervals as BED files. Command line options: '-x' : Filter out (exclude) VCF entries that match any interval in the BED files. '-i file.vcf' : Specify the input VCF file (default is STDIN). E.g.: cat variants.vcf | java -jar SnpSift.jar intervals my_intervals.bed > variants_intersecting_intervals.vcf Warning BED file format is tab separated zero-based coordinates \"chr \\t start \\t end \" (for this application, all other fields in the BED file are ignored). Warning If BED file has header lines, they must start with a '#'","title":"SnpSift Intervals"},{"location":"ss_intervals/#snpsift-intervals","text":"This is used to extract variants that intersect any interval. You must provide intervals as BED files. Command line options: '-x' : Filter out (exclude) VCF entries that match any interval in the BED files. '-i file.vcf' : Specify the input VCF file (default is STDIN). E.g.: cat variants.vcf | java -jar SnpSift.jar intervals my_intervals.bed > variants_intersecting_intervals.vcf Warning BED file format is tab separated zero-based coordinates \"chr \\t start \\t end \" (for this application, all other fields in the BED file are ignored). Warning If BED file has header lines, they must start with a '#'","title":"SnpSift Intervals"},{"location":"ss_intervalsindex/","text":"SnpSift Intervals Index This is used to extract variants that intersect any interval. Warning This is similar to \"SnpSift intervals\", but intended for huge VCF files, and relatively small number of intervals. This command indexes the VCF file, thus is optimized for huge VCF files. You must provide intervals as BED files. BED format is tab separated zero-based coordinates \"chr \\t start \\t end \" (for this application, all other fields in the BED file are ignored). You can use command line option '-if 1' if you want one-based coordinates. E.g.: java -jar SnpSift.jar intidx variants.vcf my_intervals.bed > variants_intersecting_intervals.vcf You can also have genomic coordinate in the command line. Note that in this case, coordinates are assumed to be one-based (instead of zero-based, like in BED files): java -jar SnpSift.jar intidx -c variants.vcf chr1:12345-23456 chr2:3456789-4567890 > variants_intersecting_intervals.vcf Warning BED file format is tab separated zero-based coordinates \"chr \\t start \\t end \" (for this application, all other fields in the BED file are ignored). Warning If BED file has header lines, they must start with a '#'","title":"SnpSift Intervals Index"},{"location":"ss_intervalsindex/#snpsift-intervals-index","text":"This is used to extract variants that intersect any interval. Warning This is similar to \"SnpSift intervals\", but intended for huge VCF files, and relatively small number of intervals. This command indexes the VCF file, thus is optimized for huge VCF files. You must provide intervals as BED files. BED format is tab separated zero-based coordinates \"chr \\t start \\t end \" (for this application, all other fields in the BED file are ignored). You can use command line option '-if 1' if you want one-based coordinates. E.g.: java -jar SnpSift.jar intidx variants.vcf my_intervals.bed > variants_intersecting_intervals.vcf You can also have genomic coordinate in the command line. Note that in this case, coordinates are assumed to be one-based (instead of zero-based, like in BED files): java -jar SnpSift.jar intidx -c variants.vcf chr1:12345-23456 chr2:3456789-4567890 > variants_intersecting_intervals.vcf Warning BED file format is tab separated zero-based coordinates \"chr \\t start \\t end \" (for this application, all other fields in the BED file are ignored). Warning If BED file has header lines, they must start with a '#'","title":"SnpSift Intervals Index"},{"location":"ss_introduction/","text":"SnpSift SnpSift is a toolbox that allows you to filter and manipulate annotated files. Once your genomic variants have been annotated, you need to filter them out in order to find the \"interesting / relevant variants\". Given the large data files, this is not a trivial task (e.g. you cannot load all the variants into XLS spreadsheet). SnpSift helps to perform this VCF file manipulation and filtering required at this stage in data processing pipelines. Download and install SnpSift is part of SnpEff main distribution, so please click on here and follow the instructions on how to download and install SnpEff. SnpSift utilities SnpSift is a collection of tools to manipulate VCF (variant call format) files. Some examples of what you can do: Operation Meaning Filter You can filter using arbitrary expressions, for instance \"(QUAL > 30) | (exists INDEL) | ( countHet() < 2 )\" . The actual expressions can be quite complex, so it allows for a lot of flexibility. Annotate You can add 'ID' and INFO fields from another \"VCF database\" (e.g. typically dbSnp database in VCF format). CaseControl You can compare how many variants are in 'case' and in 'control' groups. Also calculates p-values (Fisher exact test). Intervals Filter variants that intersect with intervals. Intervals (intidx) Filter variants that intersect with intervals. Index the VCF file using memory mapped I/O to speed up the search. This is intended for huge VCF files and a small number of intervals to retrieve. Join Join by generic genomic regions (intersecting or closest). RmRefGen Remove reference genotype (i.e. replace '0/0' genotypes by '.') TsTv Calculate transition to transversion ratio. Extract fields Extract fields from a VCF file to a TXT (tab separated) format. Variant type Adds SNP/MNP/INS/DEL to info field. It also adds \"HOM/HET\" if there is only one sample. GWAS Catalog Annotate using GWAS Catalog. DbNSFP Annotate using dbNSFP: The dbNSFP is an integrated database of functional predictions from multiple algorithms (SIFT, Polyphen2, LRT and MutationTaster, PhyloP and GERP++, etc.) SplitChr Split a VCF file by chromosome Citing SnpSift In order to cite SnpSift, please use the following example . Source code The project is hosted at GitHub .","title":"Introduction"},{"location":"ss_introduction/#snpsift","text":"SnpSift is a toolbox that allows you to filter and manipulate annotated files. Once your genomic variants have been annotated, you need to filter them out in order to find the \"interesting / relevant variants\". Given the large data files, this is not a trivial task (e.g. you cannot load all the variants into XLS spreadsheet). SnpSift helps to perform this VCF file manipulation and filtering required at this stage in data processing pipelines.","title":"SnpSift"},{"location":"ss_introduction/#download-and-install","text":"SnpSift is part of SnpEff main distribution, so please click on here and follow the instructions on how to download and install SnpEff.","title":"Download and install"},{"location":"ss_introduction/#snpsift-utilities","text":"SnpSift is a collection of tools to manipulate VCF (variant call format) files. Some examples of what you can do: Operation Meaning Filter You can filter using arbitrary expressions, for instance \"(QUAL > 30) | (exists INDEL) | ( countHet() < 2 )\" . The actual expressions can be quite complex, so it allows for a lot of flexibility. Annotate You can add 'ID' and INFO fields from another \"VCF database\" (e.g. typically dbSnp database in VCF format). CaseControl You can compare how many variants are in 'case' and in 'control' groups. Also calculates p-values (Fisher exact test). Intervals Filter variants that intersect with intervals. Intervals (intidx) Filter variants that intersect with intervals. Index the VCF file using memory mapped I/O to speed up the search. This is intended for huge VCF files and a small number of intervals to retrieve. Join Join by generic genomic regions (intersecting or closest). RmRefGen Remove reference genotype (i.e. replace '0/0' genotypes by '.') TsTv Calculate transition to transversion ratio. Extract fields Extract fields from a VCF file to a TXT (tab separated) format. Variant type Adds SNP/MNP/INS/DEL to info field. It also adds \"HOM/HET\" if there is only one sample. GWAS Catalog Annotate using GWAS Catalog. DbNSFP Annotate using dbNSFP: The dbNSFP is an integrated database of functional predictions from multiple algorithms (SIFT, Polyphen2, LRT and MutationTaster, PhyloP and GERP++, etc.) SplitChr Split a VCF file by chromosome","title":"SnpSift utilities"},{"location":"ss_introduction/#citing-snpsift","text":"In order to cite SnpSift, please use the following example .","title":"Citing SnpSift"},{"location":"ss_introduction/#source-code","text":"The project is hosted at GitHub .","title":"Source code"},{"location":"ss_join/","text":"SnpSift Join Join files by genomic regions (i.e. chr:start-end). Files can be generic TXT (tab separated), VCF or BED. Usage example: Usage: java -jar SnpSift.jar join [options] file1 file2 Note: It is assumed that both files fit in memory. Options: -if1 <num> : Offset for file1 (e.g. 1 if coordinates are one-based. Default: 1 -if2 <num> : Offset for file2 (e.g. 2 if coordinates are one-based. Default: 1 -cols1 <colDef> : Column definition for file 1. Format: chrCol,startCol,endCol (e.g. '1,2,3'). Shortcuts 'bed' or 'vcf' are allowed. Default: 'vcf -cols2 <colDef> : Column definition for file 2. Format: chrCol,startCol,endCol (e.g. '1,2,3'). Shortcuts 'bed' or 'vcf' are allowed. Default: 'vcf -all : For each interval, show all intersecting. Default: show only one (the largest intersection) -closest : Show closest intervals in file2 if none intersect. Default: off -empty : Show intervals in file1 even if they do not intersect with any other interval. Default: off Example: Join two bed files, showing intersecting or closest intervals java -Xmx2G -jar SnpSift.jar join -v -cols1 bed -cols2 bed -closest file1.bed file2.bed Example: Join one bed file and another file having chr:start-end in columns 7,8 and 9 respectively. Showing intervals form file1 that do not intersect any interval from file2 java -Xmx2G -jar SnpSift.jar join -v -cols1 bed -cols2 7,8,9 -empty file.bed my_weird_file.txt","title":"SnpSift Join"},{"location":"ss_join/#snpsift-join","text":"Join files by genomic regions (i.e. chr:start-end). Files can be generic TXT (tab separated), VCF or BED. Usage example: Usage: java -jar SnpSift.jar join [options] file1 file2 Note: It is assumed that both files fit in memory. Options: -if1 <num> : Offset for file1 (e.g. 1 if coordinates are one-based. Default: 1 -if2 <num> : Offset for file2 (e.g. 2 if coordinates are one-based. Default: 1 -cols1 <colDef> : Column definition for file 1. Format: chrCol,startCol,endCol (e.g. '1,2,3'). Shortcuts 'bed' or 'vcf' are allowed. Default: 'vcf -cols2 <colDef> : Column definition for file 2. Format: chrCol,startCol,endCol (e.g. '1,2,3'). Shortcuts 'bed' or 'vcf' are allowed. Default: 'vcf -all : For each interval, show all intersecting. Default: show only one (the largest intersection) -closest : Show closest intervals in file2 if none intersect. Default: off -empty : Show intervals in file1 even if they do not intersect with any other interval. Default: off Example: Join two bed files, showing intersecting or closest intervals java -Xmx2G -jar SnpSift.jar join -v -cols1 bed -cols2 bed -closest file1.bed file2.bed Example: Join one bed file and another file having chr:start-end in columns 7,8 and 9 respectively. Showing intervals form file1 that do not intersect any interval from file2 java -Xmx2G -jar SnpSift.jar join -v -cols1 bed -cols2 7,8,9 -empty file.bed my_weird_file.txt","title":"SnpSift Join"},{"location":"ss_phastcons/","text":"SnpSift phastCons Annotate using PhastCons conservation scores. Info You must download PhastCons files here . Info You also need a chromosome size file, which can be created using samtools faidx , or you can download it from here . Full example. Most of the example deals with downloading and installing PhastCons database, which is done only once. The real annotation process is done in the last line. # Create a dir for PhastCons database cd ~/snpEff mkdir -p db/phastCons/ # Download all PhastCons files cd db/phastCons/ wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr1.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr2.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr3.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr4.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr5.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr6.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr7.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr8.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr9.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr10.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr11.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr12.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr13.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr14.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr15.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr16.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr17.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr18.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr19.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr20.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr21.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr22.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chrM.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chrX.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chrY.phastCons100way.wigFix.gz # Create a chromosome size file and name it \"genome.fai\" samtools faidx path/to/genome/hg19.fa.gz cp path/to/genome/hg19.fa.gz.fai ./genome.fai # Now we are ready to annotate java -Xmx8g -jar SnpSift.jar phastCons ~/snpEff/db/phastCons file.vcf > file.phastCons.vcf You can annotate intervals using BED files and -bed command line option. In the output BED formatted intervals, the score column (fifth column), is the average conservation score of all bases within the interval. It is possible to extract sub-intervals having at least 'minScore' conservation score and 'len' length by using -minScore score and -extract len command line options. For instance, the following command: java -jar SnpSift.jar phastCons -minScore 0.8 -extract 10 -bed path/to/phastCons/dir input.bed extracts all subintervals from each line in input.bed , that has at least 10 bases length and a conservation score of 0.8","title":"SnpSift PhastCons"},{"location":"ss_phastcons/#snpsift-phastcons","text":"Annotate using PhastCons conservation scores. Info You must download PhastCons files here . Info You also need a chromosome size file, which can be created using samtools faidx , or you can download it from here . Full example. Most of the example deals with downloading and installing PhastCons database, which is done only once. The real annotation process is done in the last line. # Create a dir for PhastCons database cd ~/snpEff mkdir -p db/phastCons/ # Download all PhastCons files cd db/phastCons/ wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr1.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr2.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr3.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr4.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr5.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr6.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr7.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr8.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr9.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr10.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr11.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr12.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr13.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr14.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr15.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr16.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr17.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr18.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr19.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr20.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr21.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chr22.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chrM.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chrX.phastCons100way.wigFix.gz wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/phastCons100way/hg19.100way.phastCons/chrY.phastCons100way.wigFix.gz # Create a chromosome size file and name it \"genome.fai\" samtools faidx path/to/genome/hg19.fa.gz cp path/to/genome/hg19.fa.gz.fai ./genome.fai # Now we are ready to annotate java -Xmx8g -jar SnpSift.jar phastCons ~/snpEff/db/phastCons file.vcf > file.phastCons.vcf You can annotate intervals using BED files and -bed command line option. In the output BED formatted intervals, the score column (fifth column), is the average conservation score of all bases within the interval. It is possible to extract sub-intervals having at least 'minScore' conservation score and 'len' length by using -minScore score and -extract len command line options. For instance, the following command: java -jar SnpSift.jar phastCons -minScore 0.8 -extract 10 -bed path/to/phastCons/dir input.bed extracts all subintervals from each line in input.bed , that has at least 10 bases length and a conservation score of 0.8","title":"SnpSift phastCons"},{"location":"ss_private/","text":"SnpSift Private Annotate if a variant is private to a family. A Private=Family_ID is added to a variant's INFO field, if the variant is only found in one family. A TFAM file (see PLINK's documentation) specifies a mapping from sample IDs to family IDs. E.g.: $ java -jar SnpSift.jar private pheotypes.tfam imp.ann.vcf > imp.ann.private.vcf An annotated variant may look like this: 1 1005806 rs3934834 C T . PASS AF=0.091;..;Private=Family_47 This indicates that the variant is only found in members of Family_47 , according to the definitions in pheotypes.tfam .","title":"SnpSift Private"},{"location":"ss_private/#snpsift-private","text":"Annotate if a variant is private to a family. A Private=Family_ID is added to a variant's INFO field, if the variant is only found in one family. A TFAM file (see PLINK's documentation) specifies a mapping from sample IDs to family IDs. E.g.: $ java -jar SnpSift.jar private pheotypes.tfam imp.ann.vcf > imp.ann.private.vcf An annotated variant may look like this: 1 1005806 rs3934834 C T . PASS AF=0.091;..;Private=Family_47 This indicates that the variant is only found in members of Family_47 , according to the definitions in pheotypes.tfam .","title":"SnpSift Private"},{"location":"ss_rminfo/","text":"SnpSift RmInfo This command removes INFO fields from a VCF file (i.e. removes annotations) Removing INFO fields is usually done because you want to re-annotate the VCF file, thus removing old INFO fields in order to add new ones later. SnpEff SnpSift only add annotations and do not change current ones. So, in order to re-annotate a file, you should first remove the old annotations and then re-annotate. The reason for this behavior is simply because replacing annotation values is considered a bad practice. Imagine that you have a VCF entry in your re-annotated file having the value \"AA=1\": How do you know if this is from the old annotations or from the new ones? This confusion often leads to problems in downstream steps of your pipelines, so it's better to avoid the problem by first removing all the previous annotations and then adding the new ones. Usage example: $ cat test.snpeff.vcf #CHROM POS ID REF ALT QUAL FILTER INFO 1 734462 1032 G A . s50 AC=348;EFF=DOWNSTREAM(MODIFIER|||||RP11-206L10.8|processed_transcript|NON_CODING|ENST00000447500||1),INTRON(MODIFIER|||||RP11-206L10.6|processed_transcript|NON_CODING|ENST00000429505|1|1) $ java -jar SnpSift.jar rmInfo test.snpeff.vcf EFF #CHROM POS ID REF ALT QUAL FILTER INFO 1 734462 1032 G A . s50 AC=348","title":"SnpSift RmInfo"},{"location":"ss_rminfo/#snpsift-rminfo","text":"This command removes INFO fields from a VCF file (i.e. removes annotations) Removing INFO fields is usually done because you want to re-annotate the VCF file, thus removing old INFO fields in order to add new ones later. SnpEff SnpSift only add annotations and do not change current ones. So, in order to re-annotate a file, you should first remove the old annotations and then re-annotate. The reason for this behavior is simply because replacing annotation values is considered a bad practice. Imagine that you have a VCF entry in your re-annotated file having the value \"AA=1\": How do you know if this is from the old annotations or from the new ones? This confusion often leads to problems in downstream steps of your pipelines, so it's better to avoid the problem by first removing all the previous annotations and then adding the new ones. Usage example: $ cat test.snpeff.vcf #CHROM POS ID REF ALT QUAL FILTER INFO 1 734462 1032 G A . s50 AC=348;EFF=DOWNSTREAM(MODIFIER|||||RP11-206L10.8|processed_transcript|NON_CODING|ENST00000447500||1),INTRON(MODIFIER|||||RP11-206L10.6|processed_transcript|NON_CODING|ENST00000429505|1|1) $ java -jar SnpSift.jar rmInfo test.snpeff.vcf EFF #CHROM POS ID REF ALT QUAL FILTER INFO 1 734462 1032 G A . s50 AC=348","title":"SnpSift RmInfo"},{"location":"ss_rmrefgen/","text":"SnpSift RmRefGen Remove reference genotypes. Replaces genotype information for non-variant samples. E.g. If you have this file: #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT M1 M2 X1 X2 2L 426906 . C G 53.30 . DP=169 GT:PL:GQ 0/1:7,0,255:4 0/1:7,0,255:4 0/0:0,0,0:6 0/0:0,30,255:35 2L 601171 . C A 999.00 . DP=154 GT:PL:GQ 0/1:81,0,141:78 0/1:42,0,251:39 0/0:0,0,0:4 0/0:0,33,255:36 2L 648611 . A T 999.00 . DP=225 GT:PL:GQ 0/1:52,0,42:47 1/1:75,21,0:14 0/0:0,0,0:3 0/0:0,60,255:61 2L 807373 . A G 106.00 . DP=349 GT:PL:GQ 0/1:14,0,65:12 0/1:60,0,42:50 0/0:0,0,0:4 0/0:0,69,255:72 2L 816766 . G T 999.00 . DP=411 GT:PL:GQ 0/1:108,0,45:53 0/1:7,0,255:6 0/0:0,0,0:4 0/0:0,57,255:59 You can run: cat file.vcf | java -jar SnpSift.jar rmRefGen > file_noref.vcf and you get this (notice the last two columns, that had '0/0' genotype): #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT M1 M2 X1 X2 2L 426906 . C G 53.30 . DP=169 GT:PL:GQ 0/1:7,0,255:4 0/1:7,0,255:4 . . 2L 601171 . C A 999.00 . DP=154 GT:PL:GQ 0/1:81,0,141:78 0/1:42,0,251:39 . . 2L 648611 . A T 999.00 . DP=225 GT:PL:GQ 0/1:52,0,42:47 1/1:75,21,0:14 . . 2L 807373 . A G 106.00 . DP=349 GT:PL:GQ 0/1:14,0,65:12 0/1:60,0,42:50 . . 2L 816766 . G T 999.00 . DP=411 GT:PL:GQ 0/1:108,0,45:53 0/1:7,0,255:6 . .","title":"SnpSift RmRefGen"},{"location":"ss_rmrefgen/#snpsift-rmrefgen","text":"Remove reference genotypes. Replaces genotype information for non-variant samples. E.g. If you have this file: #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT M1 M2 X1 X2 2L 426906 . C G 53.30 . DP=169 GT:PL:GQ 0/1:7,0,255:4 0/1:7,0,255:4 0/0:0,0,0:6 0/0:0,30,255:35 2L 601171 . C A 999.00 . DP=154 GT:PL:GQ 0/1:81,0,141:78 0/1:42,0,251:39 0/0:0,0,0:4 0/0:0,33,255:36 2L 648611 . A T 999.00 . DP=225 GT:PL:GQ 0/1:52,0,42:47 1/1:75,21,0:14 0/0:0,0,0:3 0/0:0,60,255:61 2L 807373 . A G 106.00 . DP=349 GT:PL:GQ 0/1:14,0,65:12 0/1:60,0,42:50 0/0:0,0,0:4 0/0:0,69,255:72 2L 816766 . G T 999.00 . DP=411 GT:PL:GQ 0/1:108,0,45:53 0/1:7,0,255:6 0/0:0,0,0:4 0/0:0,57,255:59 You can run: cat file.vcf | java -jar SnpSift.jar rmRefGen > file_noref.vcf and you get this (notice the last two columns, that had '0/0' genotype): #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT M1 M2 X1 X2 2L 426906 . C G 53.30 . DP=169 GT:PL:GQ 0/1:7,0,255:4 0/1:7,0,255:4 . . 2L 601171 . C A 999.00 . DP=154 GT:PL:GQ 0/1:81,0,141:78 0/1:42,0,251:39 . . 2L 648611 . A T 999.00 . DP=225 GT:PL:GQ 0/1:52,0,42:47 1/1:75,21,0:14 . . 2L 807373 . A G 106.00 . DP=349 GT:PL:GQ 0/1:14,0,65:12 0/1:60,0,42:50 . . 2L 816766 . G T 999.00 . DP=411 GT:PL:GQ 0/1:108,0,45:53 0/1:7,0,255:6 . .","title":"SnpSift RmRefGen"},{"location":"ss_split/","text":"SnpSift Split Simply split (or join) VCF files. Allows to create one file per chromosome or one file every N lines. A typical usage for this command is to: Split very large VCF files SnpSift split huge.vcf Perform some CPU intensive processing in parallel using several computers or cores Join the resulting VCF files SnpSift split -j huge.000.vcf huge.001.vcf huge.002.vcf ... > huge.out.vcf . E.g.: Splitting a VCF having human variants: java -jar SnpSift.jar split myHugeVcf.vcf.gz Will create files myHugeVcf.1.vcf, myHugeVcf.2.vcf, ... , myHugeVcf.22.vcf, myHugeVcf.X.vcf, myHugeVcf.Y.vcf You can also specify '-l' command line option to split the file every N lines. E.g.: Split a VCF file every 10,000 lines: java -jar SnpSift.jar split -l 10000 myHugeVcf.vcf.gz Will create files myHugeVcf.001.vcf, myHugeVcf.002.vcf, ... Info VCF header will be added to each file, so resulting files will be more than 10,000 lines. You can use -j (join) command line option to join a set of VCF files. java -jar SnpSift.jar split -j huge.000.vcf huge.001.vcf huge.002.vcf ... > huge.out.vcf","title":"SnpSift Split"},{"location":"ss_split/#snpsift-split","text":"Simply split (or join) VCF files. Allows to create one file per chromosome or one file every N lines. A typical usage for this command is to: Split very large VCF files SnpSift split huge.vcf Perform some CPU intensive processing in parallel using several computers or cores Join the resulting VCF files SnpSift split -j huge.000.vcf huge.001.vcf huge.002.vcf ... > huge.out.vcf . E.g.: Splitting a VCF having human variants: java -jar SnpSift.jar split myHugeVcf.vcf.gz Will create files myHugeVcf.1.vcf, myHugeVcf.2.vcf, ... , myHugeVcf.22.vcf, myHugeVcf.X.vcf, myHugeVcf.Y.vcf You can also specify '-l' command line option to split the file every N lines. E.g.: Split a VCF file every 10,000 lines: java -jar SnpSift.jar split -l 10000 myHugeVcf.vcf.gz Will create files myHugeVcf.001.vcf, myHugeVcf.002.vcf, ... Info VCF header will be added to each file, so resulting files will be more than 10,000 lines. You can use -j (join) command line option to join a set of VCF files. java -jar SnpSift.jar split -j huge.000.vcf huge.001.vcf huge.002.vcf ... > huge.out.vcf","title":"SnpSift Split"},{"location":"ss_tstv/","text":"SnpSift TsTv Calculate transition vs transversion ratios for each sample. Usage example: $ java -jar SnpSift.jar tstv hom s.vcf Sample : 1 2 3 4 5 6 7 8 9 10 11 12 Total Transitions : 150488 150464 158752 156674 152936 160356 152276 155314 156484 149276 151182 153468 1847670 Transversions : 70878 70358 73688 72434 70828 76150 72030 71958 72960 69348 70180 71688 862500 Ts/Tv : 2.123 2.139 2.154 2.163 2.159 2.106 2.114 2.158 2.145 2.153 2.154 2.141 2.142","title":"SnpSift TsTv"},{"location":"ss_tstv/#snpsift-tstv","text":"Calculate transition vs transversion ratios for each sample. Usage example: $ java -jar SnpSift.jar tstv hom s.vcf Sample : 1 2 3 4 5 6 7 8 9 10 11 12 Total Transitions : 150488 150464 158752 156674 152936 160356 152276 155314 156484 149276 151182 153468 1847670 Transversions : 70878 70358 73688 72434 70828 76150 72030 71958 72960 69348 70180 71688 862500 Ts/Tv : 2.123 2.139 2.154 2.163 2.159 2.106 2.114 2.158 2.145 2.153 2.154 2.141 2.142","title":"SnpSift TsTv"},{"location":"ss_varianttype/","text":"SnpSift Variant type Adds an INFO field denoting variant type. It adds \"SNP/MNP/INS/DEL/MIXED\" in the INFO field. It also adds \"HOM/HET\", but this last one works if there is only one sample (otherwise it doesn't make any sense). $ java -jar SnpSift.jar varType test.vcf | grep -v \"^#\" | head 20 10469 . C G 100.0 PASS SNP;HOM GT:AP 0|0:0.075,0.060 20 10492 . C T 100.0 PASS SNP;HET GT:AP 0|1:0.180,0.345 20 10575 . C CG 100.0 PASS DEL;HET GT:AP 0|1:0.000,0.000 20 10611 . CG C 100.0 PASS INS;HET GT:AP 0|1:0.000,0.010 20 10618 . GT TA 100.0 PASS MNP;HET GT:AP 0|1:0.020,0.030","title":"SnpSift Variant Type"},{"location":"ss_varianttype/#snpsift-variant-type","text":"Adds an INFO field denoting variant type. It adds \"SNP/MNP/INS/DEL/MIXED\" in the INFO field. It also adds \"HOM/HET\", but this last one works if there is only one sample (otherwise it doesn't make any sense). $ java -jar SnpSift.jar varType test.vcf | grep -v \"^#\" | head 20 10469 . C G 100.0 PASS SNP;HOM GT:AP 0|0:0.075,0.060 20 10492 . C T 100.0 PASS SNP;HET GT:AP 0|1:0.180,0.345 20 10575 . C CG 100.0 PASS DEL;HET GT:AP 0|1:0.000,0.000 20 10611 . CG C 100.0 PASS INS;HET GT:AP 0|1:0.000,0.010 20 10618 . GT TA 100.0 PASS MNP;HET GT:AP 0|1:0.020,0.030","title":"SnpSift Variant type"},{"location":"ss_vcf2ped/","text":"SnpSift Vcf2Tped Convert from VCF to PLINK's TPED file format. The vcf2tped command uses a VCF and a TFAP file as input, creating a TPED and a consolidated TFAM as outputs. Command line options are: $ java -jar SnpSift.jar vcf2tped SnpSift version 1.9d (build 2013-04-26), by Pablo Cingolani Usage: java -jar SnpSift.jar vcf2tped [options] file.tfam file.vcf outputName Options: -f : Force. Overwrite new files if they exist. Default: false -onlySnp : Use only SNPs when converting VCF to TPED. Default: false -onlyBiAllelic : Use only bi-allelic variants. Default: false -useMissing : Use entries with missing genotypes (otherwise they are filtered out). Default: false -useMissingRef : Use entries with missing genotypes marking them as 'reference' instead of 'missing'. Default: false Parameters: file.tfam : File with genotypes and groups information (in PLINK's TFAM format) file.vcf : A VCF file (variants and genotype data) outputName : Base name for the new TPED and TFAM files. vcf2tped command supports the following features: Output a TPED file: Only samples present in both the input TFAM and the input VCF files are in the output TPED. Bi-allelic filter: -onlyBiAllelic option filters out non bi-allelic variants. Non SNP variants (InDels, MNPs, etc): InDels and other non-SNP variants are converted for \"fake\" SNPs (some programs have problems handling non-SNP variants). -onlySnp option filters out non SNP variants. Missing variants: Variants having missing data are filtered out by default. -useMissing uses missing variants in TPED file. -useMissingRef Converts missing variants to reference genotype. Output TFAM file: Only samples present in both the input TFAM and the input VCF files are in the output TFAM. Samples are re-ordered to have the same order as the VCF file","title":"SnpSift Vcf2Tped"},{"location":"ss_vcf2ped/#snpsift-vcf2tped","text":"Convert from VCF to PLINK's TPED file format. The vcf2tped command uses a VCF and a TFAP file as input, creating a TPED and a consolidated TFAM as outputs. Command line options are: $ java -jar SnpSift.jar vcf2tped SnpSift version 1.9d (build 2013-04-26), by Pablo Cingolani Usage: java -jar SnpSift.jar vcf2tped [options] file.tfam file.vcf outputName Options: -f : Force. Overwrite new files if they exist. Default: false -onlySnp : Use only SNPs when converting VCF to TPED. Default: false -onlyBiAllelic : Use only bi-allelic variants. Default: false -useMissing : Use entries with missing genotypes (otherwise they are filtered out). Default: false -useMissingRef : Use entries with missing genotypes marking them as 'reference' instead of 'missing'. Default: false Parameters: file.tfam : File with genotypes and groups information (in PLINK's TFAM format) file.vcf : A VCF file (variants and genotype data) outputName : Base name for the new TPED and TFAM files. vcf2tped command supports the following features: Output a TPED file: Only samples present in both the input TFAM and the input VCF files are in the output TPED. Bi-allelic filter: -onlyBiAllelic option filters out non bi-allelic variants. Non SNP variants (InDels, MNPs, etc): InDels and other non-SNP variants are converted for \"fake\" SNPs (some programs have problems handling non-SNP variants). -onlySnp option filters out non SNP variants. Missing variants: Variants having missing data are filtered out by default. -useMissing uses missing variants in TPED file. -useMissingRef Converts missing variants to reference genotype. Output TFAM file: Only samples present in both the input TFAM and the input VCF files are in the output TFAM. Samples are re-ordered to have the same order as the VCF file","title":"SnpSift Vcf2Tped"},{"location":"ss_vcfcheck/","text":"SnpSift VcfCheck Perform some basic check ups on VCF files to spot common problems. SnpSift vcfCheck checks for some common problems where VCF files are not following the specification. Given that many common VCF problems cause analysis tools and pipelines to behave unexpectedly, this command is intended as a simple debugging tool. E.g.: $ java -jar SnpSift.jar vcfCheck bad.vcf WARNING: Malformed VCF entryfile 'bad.vcf', line 7: Entry : 3 148885779 . A ATT,AT 999.0 PASS UK10KWES_AC=0,0;MDV=94 Errors : INFO filed 'UK10KWES_AC' has 'Number=1' in header, but it contains '2' elements. Cannot find header for INFO field 'MDV' WARNING: Malformed VCF entryfile 'bad.vcf', line 14: Entry : 3 148890104 . TCA T . . . Errors : File is not sorted: Position '3:148890104' after position '3:148890105'","title":"SnpSift VcfCheck"},{"location":"ss_vcfcheck/#snpsift-vcfcheck","text":"Perform some basic check ups on VCF files to spot common problems. SnpSift vcfCheck checks for some common problems where VCF files are not following the specification. Given that many common VCF problems cause analysis tools and pipelines to behave unexpectedly, this command is intended as a simple debugging tool. E.g.: $ java -jar SnpSift.jar vcfCheck bad.vcf WARNING: Malformed VCF entryfile 'bad.vcf', line 7: Entry : 3 148885779 . A ATT,AT 999.0 PASS UK10KWES_AC=0,0;MDV=94 Errors : INFO filed 'UK10KWES_AC' has 'Number=1' in header, but it contains '2' elements. Cannot find header for INFO field 'MDV' WARNING: Malformed VCF entryfile 'bad.vcf', line 14: Entry : 3 148890104 . TCA T . . . Errors : File is not sorted: Position '3:148890104' after position '3:148890105'","title":"SnpSift VcfCheck"},{"location":"tests/","text":"SnpEff and SnpSift: Test cases SnpEff and SnpSift have a comprehensive set of unit and integration test cases. Some of these test cases require genome databases or other large files, see instructions below on how to download and install the test files. Nomenclature In this document we assume you have the following variables properly set in your environment # Change this to where you installed the SnpEff project from GitHub export SNPEFF_PROJECT_DIR=\"$HOME/workspace/SnpEff\" # Change this to your SnpEff install dir export SNPEFF_DIR=\"$HOME/snpEff\" Install test datasets Note that the download link includes a SnpEff version, so it might change in future releases Download the test dataset here Untar and move the files to your SnpEff's data directory # Here we assume that your 'data' directory is in '$SNPEFF_DIR/data' cd $SNPEFF_DIR/data tar -cvf path/to/data_test.5.0.tar mv data_test/* . SnpEff Unit tests To run unit test suite, you can run the following commands: cd $SNPEFF_PROJECT_DIR java -Xmx4g \\ -cp $SNPEFF_DIR/snpEff.jar \\ org.junit.runner.JUnitCore \\ org.snpeff.snpEffect.testCases.TestSuiteUnity \\ 2>&1 \\ | tee testcases.snpeff.unity.txt SnpEff integration tests To run integration test suite, you can run the following commands: cd $SNPEFF_PROJECT_DIR java -Xmx4g \\ -cp $SNPEFF_DIR/snpEff.jar \\ org.junit.runner.JUnitCore \\ org.snpeff.snpEffect.testCases.TestSuiteUnity \\ 2>&1 \\ | tee testcases.snpeff.unity.txt SnpSift tests To run SnpSift test suite, you can run the following commands: cd $SNPEFF_PROJECT_DIR java -Xmx4g \\ -cp $SNPEFF_DIR/SnpSift.jar \\ org.junit.runner.JUnitCore \\ org.snpsift.testCases.TestSuiteAll \\ 2>&1 \\ | tee testcases.snpsift.all.txt","title":"Test cases"},{"location":"tests/#snpeff-and-snpsift-test-cases","text":"SnpEff and SnpSift have a comprehensive set of unit and integration test cases. Some of these test cases require genome databases or other large files, see instructions below on how to download and install the test files.","title":"SnpEff and SnpSift: Test cases"},{"location":"tests/#nomenclature","text":"In this document we assume you have the following variables properly set in your environment # Change this to where you installed the SnpEff project from GitHub export SNPEFF_PROJECT_DIR=\"$HOME/workspace/SnpEff\" # Change this to your SnpEff install dir export SNPEFF_DIR=\"$HOME/snpEff\"","title":"Nomenclature"},{"location":"tests/#install-test-datasets","text":"Note that the download link includes a SnpEff version, so it might change in future releases Download the test dataset here Untar and move the files to your SnpEff's data directory # Here we assume that your 'data' directory is in '$SNPEFF_DIR/data' cd $SNPEFF_DIR/data tar -cvf path/to/data_test.5.0.tar mv data_test/* .","title":"Install test datasets"},{"location":"tests/#snpeff-unit-tests","text":"To run unit test suite, you can run the following commands: cd $SNPEFF_PROJECT_DIR java -Xmx4g \\ -cp $SNPEFF_DIR/snpEff.jar \\ org.junit.runner.JUnitCore \\ org.snpeff.snpEffect.testCases.TestSuiteUnity \\ 2>&1 \\ | tee testcases.snpeff.unity.txt","title":"SnpEff Unit tests"},{"location":"tests/#snpeff-integration-tests","text":"To run integration test suite, you can run the following commands: cd $SNPEFF_PROJECT_DIR java -Xmx4g \\ -cp $SNPEFF_DIR/snpEff.jar \\ org.junit.runner.JUnitCore \\ org.snpeff.snpEffect.testCases.TestSuiteUnity \\ 2>&1 \\ | tee testcases.snpeff.unity.txt","title":"SnpEff integration tests"},{"location":"tests/#snpsift-tests","text":"To run SnpSift test suite, you can run the following commands: cd $SNPEFF_PROJECT_DIR java -Xmx4g \\ -cp $SNPEFF_DIR/SnpSift.jar \\ org.junit.runner.JUnitCore \\ org.snpsift.testCases.TestSuiteAll \\ 2>&1 \\ | tee testcases.snpsift.all.txt","title":"SnpSift tests"},{"location":"users_of_snpeff/","text":"Users of SnpEff include most major research and academic institutions, as well as pharmaceutical companies and clinical sequencing projects. Some Academic & Research institutions using SnpEff: Broad Institute (MIT & Harvard) NIH (US) Harvard University Princeton University BGI (China) Massachusetts General Hospital Whitehead Institute, MIT Wellcome Trust Sanger Institute (UK) UC Berkeley Wellcome Trust Centre for Human Genetics (UK) University of Cambridge (UK) Duke University Max Planck (Germany) Cold Spring Harbor Laboratory (CSHL) Institut Pasteur (France) NCI / NIH (National Cancer Institute, US) McGill University (Canada) EMBL (Cambridge, UK) University of Toronto (Canada) University of Cambridge (UK) Yale University Columbia University Stanford University Brown University Genome Quebec (Canada) Centre national de la recherche scientifique (CNRS, France) University of Michigan Kyoto University (Japan) Institut National de la Recherche Agronomique (INRA, France) University of Wisconsin-Madison UT Southwestern Medical Center University of Southern California Bologna University (Italy) Casa Sollievo della Sofferenza - Mendel (Italy) Universitat Wien (Vienna, Austria) Ottawa University (Canada) Peter MacCallum Cancer Centre (Australia) University of Alabama Birmigham University of Bristol (UK) UC-Davis (California) Winsconsin University TUM University (Germany) The Translational Genomics Institute (Tgen) Rutgers University (New Jersey) Nagasaki University (Japan) Washington University Netherlands Cancer Institute (NKI) Centro Nacional de Biotecnolog\u00eda, (National Center for Biotecnology) CNB-CSIC, Madrid, Spain University of California-Riverside Carleton University (Canada) Memorial Sloan-Kettering Cancer Center Boston University University of California, San Francisco (UCSF) Institute of Cancer Research (ICR), UK University of Virginia University of British Columbia (Canada) Seoul National University (Korea) University of Southern California (USC) Arizona State University (ASU) NeuroTexas Institute at St. David's HealthCare University of Otago (New Zealand) Queensland Institute of Medical Research (Australia) National University of Singapore (NUS) Children's Hospital of Philadelphia Technion (Israel) Queensland UNiversity (Australia) Vall d'Hebron Research Institute: VHIR (Barcelona. Catalonia. Spain) University of Pretoria (South Africa). Centrum Wiskunde & Informatica (Amsterdam, Netherlands) Technical University of Denmark: DTU (Denmark) Spanish National Research Council (CSIC, Spain) Swedish University of Agricultural Sciences: SLU (Sweden) University of Iowa Bilkent University (Turkey) The Hebrew University of Jerusalem (Israel) Laboratory of Malaria and Vector Research NIH/NIAID Max F. Perutz Laboratories: MFPL (Vienna, Austria) Animal Health Trust: AHT (UK) BC Cancer Agency (Canada) University of California, Irvine University College London (London, UK) Centro Nacional de An\u00e1lisis Gen\u00f3mico: CNAG (Barcelona, Spain) Advanced Genomics and Bioinformatic Research Center (Turkey) Some private Companies & Corporations users of SnpEff: Bayer Novartis Illumina Johnson & Johnson AstraZeneca Novocraft Sanofi (France) Accelrys DnaNexus Bio-Prodict (Netherlands) Spiral Genetics Covance Eisai (Japan) EdgeBio BioBase Counsyl Note These are not by any means comprehensive lists.","title":"Who uses SnpEff?"},{"location":"xiangyi_lu_donate/","text":"Xiangyi Lu Donate In memory of Dr. Xiangyi Lu: Click here to donate On October 22, 2017, Xiangyi Lu, a co-author on the SnpEff and SnpSift papers, died of ovarian cancer after a three year struggle. Douglas Ruden, Xiangyi's husband and senior author on the papers, has requested that a non-mandatory gift of at least $10 for using SnpEff or SnpSift be donated to WSU to honor Xiangyi Lu. All gifts will go to a newly named fund, the \"Xiangyi Lu Graduate Student Fellowship in Bioinformatics Fund.\" with the goal of raising $1 million, in order to permanently endow one graduate student research position in bioinformatics every year. How to donate Visit Wayne State University donation site Choose the amount that you would like to donate Click on the designation box and click on the option \"Other\" In the next box, enter: IMO Dr. Xiangyi Lu At the bottom of the page, click on \"Give Now.\" Donation page example:","title":"In Memory"},{"location":"xiangyi_lu_donate/#xiangyi-lu-donate","text":"","title":"Xiangyi Lu Donate"},{"location":"xiangyi_lu_donate/#in-memory-of-dr-xiangyi-lu-click-here-to-donate","text":"On October 22, 2017, Xiangyi Lu, a co-author on the SnpEff and SnpSift papers, died of ovarian cancer after a three year struggle. Douglas Ruden, Xiangyi's husband and senior author on the papers, has requested that a non-mandatory gift of at least $10 for using SnpEff or SnpSift be donated to WSU to honor Xiangyi Lu. All gifts will go to a newly named fund, the \"Xiangyi Lu Graduate Student Fellowship in Bioinformatics Fund.\" with the goal of raising $1 million, in order to permanently endow one graduate student research position in bioinformatics every year.","title":"In memory of Dr. Xiangyi Lu: Click here to donate"},{"location":"xiangyi_lu_donate/#how-to-donate","text":"Visit Wayne State University donation site Choose the amount that you would like to donate Click on the designation box and click on the option \"Other\" In the next box, enter: IMO Dr. Xiangyi Lu At the bottom of the page, click on \"Give Now.\" Donation page example:","title":"How to donate"}]}